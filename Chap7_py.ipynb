{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 畳み込みネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Convolution / Poolingレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 4次元配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28) # ランダムにデータを生成\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape # 1つ目のデータにアクセス. (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape # 2つ目のデータにアクセス. (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.09533270e-01, 8.09421798e-01, 3.67715211e-01, 8.43121053e-01,\n",
       "        1.65410966e-01, 1.98924997e-01, 6.69771689e-02, 9.80503040e-01,\n",
       "        8.39359767e-01, 2.90888511e-01, 6.90995193e-01, 9.00180955e-01,\n",
       "        4.42173913e-01, 9.89440957e-01, 5.33291895e-01, 1.11394262e-01,\n",
       "        5.02437656e-01, 6.58743070e-01, 5.95350528e-01, 1.18760188e-01,\n",
       "        4.80033409e-01, 9.47073188e-01, 5.24927120e-01, 7.45977328e-01,\n",
       "        7.96999603e-01, 8.13555410e-01, 5.29074731e-01, 9.27013751e-01],\n",
       "       [5.96400844e-01, 5.09407595e-01, 7.86139941e-01, 2.66238013e-01,\n",
       "        5.84571995e-01, 9.33653911e-01, 4.64017680e-01, 6.20670629e-01,\n",
       "        3.11434258e-01, 6.34439835e-01, 1.56386857e-01, 3.48615106e-01,\n",
       "        2.18069723e-01, 1.90251637e-01, 6.95315993e-01, 1.15854373e-01,\n",
       "        5.94298426e-01, 5.46264508e-01, 4.65233517e-01, 7.78536091e-01,\n",
       "        7.11713022e-02, 7.23768902e-01, 6.15601161e-01, 3.52527359e-02,\n",
       "        6.93806944e-01, 9.62420876e-01, 7.59628067e-01, 9.80796939e-01],\n",
       "       [7.41843293e-02, 7.34647316e-01, 5.64457163e-01, 5.09195747e-01,\n",
       "        1.46394881e-01, 7.64171132e-01, 1.98631282e-01, 5.26135475e-01,\n",
       "        9.68200521e-01, 8.04210598e-01, 4.56670057e-01, 7.68658996e-01,\n",
       "        9.42990287e-01, 6.46554668e-01, 3.80796083e-02, 8.88620512e-01,\n",
       "        6.25321802e-01, 3.36985193e-01, 9.36583419e-01, 9.60033948e-01,\n",
       "        8.21039795e-01, 9.26400184e-01, 6.72887827e-01, 2.94466050e-01,\n",
       "        4.18200305e-01, 8.09414238e-01, 7.86629204e-01, 3.38923028e-01],\n",
       "       [5.35437819e-01, 2.02348173e-01, 6.77610186e-02, 7.76088559e-01,\n",
       "        6.20889336e-01, 3.38787555e-01, 8.82355674e-01, 9.41067475e-01,\n",
       "        8.75623499e-01, 9.68313951e-01, 6.23449949e-01, 2.55043345e-02,\n",
       "        6.85140493e-03, 8.41896909e-01, 2.82065363e-01, 5.15852696e-01,\n",
       "        2.62129827e-01, 8.71370373e-01, 1.66099851e-01, 6.38037221e-01,\n",
       "        5.87133757e-01, 3.49005602e-01, 7.93834196e-01, 3.17225940e-02,\n",
       "        7.18543909e-01, 5.52436765e-01, 4.03422985e-01, 6.32494482e-01],\n",
       "       [7.89303289e-01, 5.89074645e-01, 4.05036918e-01, 6.48579095e-01,\n",
       "        5.70925060e-01, 2.88753494e-01, 5.13206148e-01, 8.05419413e-01,\n",
       "        9.17960022e-01, 8.02616977e-02, 4.10298576e-01, 7.56490997e-01,\n",
       "        4.13683495e-01, 4.58798666e-01, 8.46104530e-01, 7.39229612e-01,\n",
       "        1.94742257e-01, 7.94076499e-01, 8.41459118e-01, 8.51964477e-01,\n",
       "        8.22680020e-01, 6.90157951e-01, 9.76296000e-01, 5.47385345e-01,\n",
       "        5.18869353e-01, 3.70204854e-02, 4.29637228e-02, 5.63785123e-01],\n",
       "       [7.96533808e-01, 1.72759208e-01, 4.32994340e-01, 2.83595937e-01,\n",
       "        8.68319538e-01, 5.84657027e-01, 8.88437161e-01, 8.86426776e-01,\n",
       "        9.94833270e-01, 7.83560774e-01, 4.00470428e-01, 9.45560346e-03,\n",
       "        8.86110544e-01, 6.82805182e-01, 4.64525117e-01, 1.49267197e-01,\n",
       "        4.51538808e-01, 4.86978748e-01, 3.93673768e-01, 2.81128344e-01,\n",
       "        6.02886123e-01, 2.42774386e-01, 1.83095804e-01, 5.01475073e-02,\n",
       "        4.29399033e-01, 7.14022409e-01, 7.09208113e-01, 4.08995427e-01],\n",
       "       [7.02212697e-01, 3.58364435e-01, 7.27473881e-01, 4.56027012e-01,\n",
       "        7.10816969e-01, 6.75229838e-01, 6.20042973e-02, 1.65418612e-01,\n",
       "        5.82726732e-01, 5.53059129e-01, 1.82808964e-01, 2.31081637e-02,\n",
       "        7.72922196e-01, 2.38639937e-02, 5.24407597e-01, 9.06989561e-01,\n",
       "        6.90637196e-01, 2.18250540e-01, 2.74899337e-01, 2.35388961e-01,\n",
       "        6.18362419e-01, 2.01056513e-02, 4.37900557e-01, 3.35075281e-01,\n",
       "        2.01816672e-01, 2.54271697e-01, 1.94033337e-01, 5.73419282e-02],\n",
       "       [9.66177270e-01, 4.33622459e-02, 2.38690453e-01, 8.49934666e-01,\n",
       "        7.09789399e-01, 2.54350044e-01, 1.49958572e-01, 9.61833458e-01,\n",
       "        8.95263287e-01, 3.96604879e-01, 8.91864694e-02, 6.24474715e-01,\n",
       "        8.52581887e-02, 1.23403951e-01, 1.69209603e-01, 7.28578839e-01,\n",
       "        8.62995346e-01, 7.33030049e-01, 4.51480758e-01, 9.53982921e-01,\n",
       "        5.22760396e-01, 2.13111039e-02, 7.54470042e-02, 4.16215630e-01,\n",
       "        5.40356011e-01, 8.50477674e-01, 3.25426387e-01, 1.32615879e-01],\n",
       "       [4.70277674e-01, 3.96705948e-01, 5.18629927e-01, 6.65084361e-01,\n",
       "        4.07354080e-01, 5.47281712e-01, 1.33050369e-01, 5.63540965e-02,\n",
       "        8.96651672e-01, 2.56059197e-01, 5.46981046e-01, 5.88174150e-01,\n",
       "        4.92647574e-03, 4.89084365e-01, 6.77519735e-01, 6.48982145e-01,\n",
       "        5.95452951e-01, 9.98725902e-01, 5.68010870e-01, 2.99489044e-01,\n",
       "        8.56710594e-01, 6.74945597e-01, 4.85580203e-01, 8.56977929e-01,\n",
       "        9.45108521e-01, 8.89449523e-01, 7.46514422e-01, 7.60867195e-01],\n",
       "       [1.37704292e-01, 6.44046785e-01, 9.79392746e-01, 5.53091832e-01,\n",
       "        1.62930098e-01, 4.13277681e-01, 3.97956944e-01, 3.89315304e-01,\n",
       "        2.55426029e-01, 6.89975763e-01, 4.79886155e-01, 3.54253019e-02,\n",
       "        1.95596130e-02, 2.20594344e-01, 5.16881794e-01, 9.35717468e-02,\n",
       "        3.60861160e-01, 4.12724565e-01, 5.85884850e-01, 4.61091908e-01,\n",
       "        5.39969903e-01, 6.34459659e-01, 7.84043169e-01, 3.68124869e-01,\n",
       "        4.71596100e-01, 8.71634424e-01, 5.86696070e-01, 5.34688942e-03],\n",
       "       [8.05686320e-01, 7.02778054e-01, 9.18334290e-02, 2.58019215e-01,\n",
       "        1.19302432e-01, 9.73594487e-01, 3.76266973e-01, 7.13680329e-01,\n",
       "        8.54069804e-01, 2.19245591e-01, 3.61228551e-01, 2.38901474e-02,\n",
       "        6.49325991e-01, 8.62718387e-01, 5.63323851e-01, 1.09002001e-01,\n",
       "        4.83521666e-01, 7.69726775e-01, 6.36878123e-01, 3.38829388e-01,\n",
       "        2.80810934e-01, 7.86360291e-01, 2.18636693e-01, 2.40441566e-01,\n",
       "        6.28567528e-02, 5.90633876e-01, 8.41771444e-01, 1.77673229e-01],\n",
       "       [5.62351246e-02, 7.81868061e-01, 1.28901544e-01, 5.18430077e-01,\n",
       "        3.34468841e-01, 1.48873004e-01, 6.72895932e-01, 3.73563460e-01,\n",
       "        2.81925433e-01, 2.24158499e-01, 8.93269374e-01, 2.69237734e-01,\n",
       "        7.83518445e-01, 6.43069156e-02, 2.59031888e-02, 5.27434270e-01,\n",
       "        9.83229903e-01, 2.63404133e-02, 6.07853616e-01, 6.50099196e-01,\n",
       "        1.82732579e-02, 9.75407177e-02, 6.51934452e-01, 6.51085814e-01,\n",
       "        3.68511497e-01, 5.12524389e-03, 5.31710246e-01, 3.94484098e-01],\n",
       "       [6.31490754e-01, 7.98743632e-01, 8.74068721e-01, 8.12039163e-01,\n",
       "        5.00389589e-01, 9.15549377e-01, 7.03153356e-01, 2.90345591e-01,\n",
       "        8.70126223e-01, 2.00781947e-01, 2.38160967e-01, 9.27891238e-01,\n",
       "        8.17799531e-01, 9.30803483e-01, 9.05200667e-01, 2.31800416e-01,\n",
       "        5.78172419e-01, 4.42940360e-01, 2.33917643e-01, 5.87725378e-01,\n",
       "        1.88786148e-01, 1.97631749e-01, 9.25107199e-01, 3.20740379e-01,\n",
       "        2.87399373e-01, 2.37460692e-01, 3.79521024e-01, 1.36592119e-01],\n",
       "       [4.81136840e-01, 1.55532733e-01, 5.92738051e-01, 1.77547754e-01,\n",
       "        9.30365162e-01, 7.46342399e-01, 3.62916269e-01, 2.09802174e-01,\n",
       "        2.76900249e-01, 7.19667658e-01, 1.03301812e-01, 1.84623239e-01,\n",
       "        3.34348669e-01, 2.20191387e-01, 7.74666451e-01, 8.57834048e-01,\n",
       "        1.77267553e-01, 6.23255527e-02, 5.24237258e-01, 6.06023590e-01,\n",
       "        5.16327090e-01, 2.56204397e-01, 7.52870907e-01, 5.92237005e-01,\n",
       "        1.89573969e-01, 7.58605523e-02, 9.42472299e-01, 2.15298520e-01],\n",
       "       [8.62503117e-01, 5.74820694e-01, 6.00698495e-01, 8.73121889e-01,\n",
       "        6.17210146e-01, 2.50626747e-01, 2.86783267e-01, 1.36389157e-01,\n",
       "        5.04546022e-01, 5.83975536e-03, 8.98261705e-02, 2.79076585e-01,\n",
       "        3.79602604e-01, 2.32894063e-01, 8.64113167e-01, 5.55884974e-01,\n",
       "        4.72303146e-01, 8.99658476e-01, 3.73834941e-01, 7.29566588e-01,\n",
       "        4.78448118e-01, 8.77180443e-01, 7.87131029e-01, 5.08837138e-01,\n",
       "        6.81193994e-01, 1.37000263e-01, 4.76590464e-02, 9.31455493e-01],\n",
       "       [9.90948805e-01, 6.15595151e-01, 4.35421127e-01, 3.70231038e-01,\n",
       "        1.85813277e-01, 9.27726019e-01, 7.85210547e-01, 5.77410416e-01,\n",
       "        9.98521179e-02, 5.16149958e-01, 1.48445779e-01, 8.49620700e-01,\n",
       "        6.52547861e-01, 5.01990237e-01, 9.89361287e-01, 8.95712552e-01,\n",
       "        5.15370452e-01, 8.41679992e-01, 4.68081019e-01, 7.28676979e-01,\n",
       "        8.79091929e-01, 9.77697023e-01, 9.02005051e-01, 1.34483873e-01,\n",
       "        9.40270998e-01, 7.46369564e-01, 3.85522945e-01, 8.05540462e-01],\n",
       "       [2.91400430e-01, 4.36733435e-01, 6.70657262e-01, 7.00560433e-01,\n",
       "        8.09773488e-01, 5.73601331e-01, 8.81855005e-01, 6.48868431e-01,\n",
       "        5.62680418e-01, 7.88229342e-01, 8.39785495e-01, 5.98335926e-01,\n",
       "        7.96668800e-01, 8.77918681e-01, 8.13050835e-01, 8.05490380e-04,\n",
       "        7.72570154e-01, 5.44588495e-01, 9.02332161e-01, 3.85112670e-01,\n",
       "        2.02440944e-01, 1.81460374e-01, 1.72724244e-01, 2.30098740e-01,\n",
       "        3.74691208e-01, 5.35620535e-01, 9.89791113e-01, 3.63784506e-01],\n",
       "       [9.78302247e-01, 8.15483326e-01, 9.64364063e-02, 5.97918646e-01,\n",
       "        1.75576477e-01, 9.57598563e-01, 9.81030285e-02, 5.21963952e-01,\n",
       "        3.18689503e-01, 5.35126436e-01, 9.91905200e-01, 8.33316874e-03,\n",
       "        5.92320379e-01, 1.94978274e-01, 4.84627446e-01, 6.26178195e-01,\n",
       "        9.16741519e-01, 6.61160692e-01, 8.82936721e-01, 1.51527456e-02,\n",
       "        5.33813792e-01, 2.67209805e-01, 8.18759642e-02, 4.55258775e-01,\n",
       "        7.32777515e-02, 3.23701762e-01, 8.29633733e-01, 5.66001504e-01],\n",
       "       [8.90497183e-01, 2.93742767e-01, 8.28263227e-01, 8.33665247e-02,\n",
       "        4.52016504e-01, 5.79342186e-01, 6.72331067e-01, 7.28972009e-01,\n",
       "        3.36507948e-01, 3.44053919e-01, 7.41536899e-02, 9.85774315e-01,\n",
       "        9.75273124e-02, 3.84780502e-02, 9.92369830e-01, 3.30581273e-01,\n",
       "        1.64248352e-01, 6.34427402e-01, 4.91535187e-01, 3.90672546e-01,\n",
       "        6.44895107e-01, 3.50358544e-01, 3.97101130e-01, 6.79068037e-01,\n",
       "        9.04694460e-01, 4.29763013e-01, 6.19389855e-01, 8.17051786e-01],\n",
       "       [8.52475602e-01, 6.01094371e-01, 6.86253453e-01, 7.13297198e-01,\n",
       "        4.34028517e-01, 8.49373138e-01, 7.40240972e-01, 7.31516226e-01,\n",
       "        1.35918646e-01, 7.58585611e-01, 9.71244118e-01, 2.37424433e-01,\n",
       "        6.65642375e-01, 2.71935796e-01, 5.39119440e-01, 9.37936689e-02,\n",
       "        4.32514642e-01, 9.50908923e-01, 6.90879420e-01, 2.16618938e-01,\n",
       "        8.05088807e-01, 4.85869490e-02, 6.23385015e-01, 7.93757254e-01,\n",
       "        1.79246822e-01, 8.99600278e-01, 1.69151765e-01, 9.33262539e-02],\n",
       "       [5.30773648e-03, 7.82474098e-01, 8.04488257e-01, 3.16872419e-01,\n",
       "        8.04952878e-01, 2.07766931e-01, 1.27459020e-01, 4.35832322e-01,\n",
       "        8.67655621e-01, 6.25385353e-01, 7.26921715e-01, 1.73074444e-01,\n",
       "        5.68532952e-01, 4.68419119e-01, 8.67132119e-01, 2.87999305e-01,\n",
       "        2.93915814e-01, 8.80768205e-01, 2.67584798e-01, 7.03458969e-01,\n",
       "        8.83642265e-01, 7.50828340e-02, 6.15129114e-02, 5.17447017e-03,\n",
       "        9.15448342e-01, 1.40430966e-01, 4.19897450e-01, 7.94679435e-01],\n",
       "       [6.67191984e-01, 3.40534511e-01, 8.95124758e-01, 5.16907606e-01,\n",
       "        7.35342080e-01, 1.92128262e-01, 1.72596533e-01, 4.82153362e-01,\n",
       "        8.09935178e-01, 5.76942882e-01, 4.92269621e-01, 4.42377274e-01,\n",
       "        5.82496702e-01, 6.53201833e-01, 8.43793436e-01, 6.38735753e-01,\n",
       "        2.57803773e-01, 9.89966600e-02, 8.06769283e-01, 5.38372081e-01,\n",
       "        6.77226288e-02, 4.08293400e-01, 3.88773075e-02, 4.07309926e-01,\n",
       "        3.98687095e-01, 3.40124434e-01, 9.48570433e-01, 9.28851904e-01],\n",
       "       [8.80824186e-01, 4.71127511e-01, 1.99477386e-01, 6.82634410e-02,\n",
       "        7.03002894e-01, 9.21592730e-01, 8.92448403e-01, 4.93481056e-01,\n",
       "        7.02648148e-01, 6.77352449e-02, 1.25126030e-01, 4.15051782e-01,\n",
       "        3.33660972e-01, 2.87109565e-01, 8.52485277e-01, 4.05261472e-02,\n",
       "        6.65469755e-01, 8.05191435e-01, 8.77012546e-01, 1.56571288e-01,\n",
       "        4.11543922e-01, 1.96465814e-01, 4.96258336e-01, 1.59542001e-01,\n",
       "        9.26771394e-01, 1.99526091e-01, 2.32818655e-01, 7.72159311e-01],\n",
       "       [1.98904941e-01, 8.07108608e-01, 1.88849959e-01, 2.27123104e-01,\n",
       "        7.84472337e-01, 9.61459919e-01, 2.85550665e-01, 7.94252822e-01,\n",
       "        5.32041193e-01, 9.53972254e-01, 8.93374305e-01, 2.69025214e-01,\n",
       "        3.51160951e-01, 2.59086212e-01, 9.14763071e-01, 1.33824645e-01,\n",
       "        2.25223164e-01, 5.98585132e-01, 3.37409593e-01, 8.76915555e-01,\n",
       "        2.26996198e-01, 8.76629330e-01, 1.85616631e-01, 1.53422322e-01,\n",
       "        7.77174162e-01, 8.92417158e-01, 7.61359119e-01, 8.55091159e-01],\n",
       "       [1.51231001e-01, 8.91411138e-01, 7.31691392e-01, 2.48212635e-02,\n",
       "        9.55168867e-01, 1.97810393e-01, 5.54012339e-01, 7.68821643e-01,\n",
       "        3.00160731e-01, 3.39940952e-01, 4.83077825e-01, 9.19137905e-01,\n",
       "        6.89309815e-01, 8.06013118e-01, 3.18665201e-01, 4.33760288e-01,\n",
       "        8.84113221e-01, 3.54711953e-01, 4.08827376e-01, 2.25192215e-01,\n",
       "        8.44632335e-01, 4.78239519e-01, 3.23812032e-01, 5.58591714e-01,\n",
       "        8.04987084e-01, 5.99634871e-01, 8.23339278e-01, 1.88383670e-01],\n",
       "       [4.35603784e-01, 2.09665133e-01, 7.76185238e-01, 2.53351637e-01,\n",
       "        9.17932972e-01, 1.73109132e-01, 5.83738149e-01, 5.78185029e-01,\n",
       "        2.39963649e-01, 6.75137944e-01, 4.89863111e-01, 6.09004139e-01,\n",
       "        1.25030704e-01, 8.91798889e-01, 7.12654977e-01, 1.78925806e-01,\n",
       "        6.57393133e-01, 9.38974499e-01, 1.70837714e-01, 6.47540301e-02,\n",
       "        2.43752723e-01, 6.91938413e-01, 9.51030337e-02, 5.67328301e-01,\n",
       "        2.43015841e-01, 7.61392358e-01, 3.74230334e-01, 1.91735990e-02],\n",
       "       [6.10550000e-02, 4.98294694e-01, 1.79064951e-01, 7.18300413e-01,\n",
       "        2.79506383e-01, 2.55813822e-01, 8.00239056e-01, 7.51416264e-01,\n",
       "        6.73324554e-01, 9.87906959e-01, 3.82320432e-02, 7.09714276e-01,\n",
       "        6.21557929e-01, 6.62282196e-01, 8.38879876e-01, 7.02410027e-01,\n",
       "        4.44868926e-01, 9.75452164e-01, 9.74855242e-01, 4.00607905e-01,\n",
       "        3.05794914e-01, 2.37164287e-01, 4.34284765e-01, 8.34651646e-01,\n",
       "        3.40822704e-01, 7.56479423e-01, 3.32532613e-01, 1.77829439e-01],\n",
       "       [2.38685077e-01, 4.96125111e-01, 5.14672546e-01, 7.93348137e-02,\n",
       "        5.26192191e-01, 5.35871506e-01, 6.87147852e-01, 8.81021508e-01,\n",
       "        4.03646168e-01, 4.11982690e-01, 2.06915139e-01, 1.43749878e-01,\n",
       "        6.73025814e-01, 7.17511006e-01, 3.09939096e-01, 5.85690089e-01,\n",
       "        6.45923387e-01, 5.36437974e-01, 2.19409208e-02, 3.82164017e-01,\n",
       "        5.99239571e-01, 9.61597341e-01, 6.02904491e-01, 9.46591097e-01,\n",
       "        1.31806933e-01, 7.26125373e-01, 3.30129097e-01, 4.56424005e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0] # 1チャンネル目の空間データにアクセス, もしくはx[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 Convolutionレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "coll = im2col(x1, 5, 5, stride = 1, pad = 0)\n",
    "print(coll.shape) # (9, 75)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) # 10個のデータ\n",
    "col2 = im2col(x2, 5, 5, stride = 1, pad = 0)\n",
    "print(col2.shape) #(90, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution: \n",
    "    def __init__(self, W, b, stride = 1, pad = 0): \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x): \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # フィルターの展開\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(o, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 Poolingレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "#        self.x = None\n",
    "#        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 展開(1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "#        arg_max = np.argmax(col, axis=1)\n",
    "        # 最大値(2)\n",
    "        out = np.max(col, axis=1)\n",
    "        # 最大値(3)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "#        self.x = x\n",
    "#        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 CNNの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"単純なConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "        引数のxは入力データ、tは教師ラベル\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300005312929278\n",
      "=== epoch:1, train acc:0.257, test acc:0.285 ===\n",
      "train loss:2.296678731892683\n",
      "train loss:2.29290595798487\n",
      "train loss:2.290394054500223\n",
      "train loss:2.2842584927819782\n",
      "train loss:2.269266615764272\n",
      "train loss:2.247128573200765\n",
      "train loss:2.247672921910246\n",
      "train loss:2.2075937303316184\n",
      "train loss:2.187165566014709\n",
      "train loss:2.1699177307928896\n",
      "train loss:2.1607234528215153\n",
      "train loss:2.1091515055504524\n",
      "train loss:2.02225017724931\n",
      "train loss:2.0252288248824812\n",
      "train loss:1.9102570556228426\n",
      "train loss:1.872834731891836\n",
      "train loss:1.8055677775924752\n",
      "train loss:1.7790325897736563\n",
      "train loss:1.6710509981184318\n",
      "train loss:1.6262022319927265\n",
      "train loss:1.6100279723377953\n",
      "train loss:1.4289200815925227\n",
      "train loss:1.3807725442873846\n",
      "train loss:1.34477786691045\n",
      "train loss:1.2168328086965619\n",
      "train loss:1.1098422660769012\n",
      "train loss:1.0109694572017134\n",
      "train loss:1.0770415565190692\n",
      "train loss:0.8848260828948145\n",
      "train loss:0.8855315825343717\n",
      "train loss:0.98165109015833\n",
      "train loss:0.901808082617451\n",
      "train loss:0.8500992825730631\n",
      "train loss:0.8113177508988864\n",
      "train loss:0.7852040605656225\n",
      "train loss:1.0217572936193993\n",
      "train loss:0.6031382327291513\n",
      "train loss:0.6217408333241358\n",
      "train loss:0.6915293422242492\n",
      "train loss:0.6762663883553628\n",
      "train loss:0.6675593193749984\n",
      "train loss:0.6038373466173936\n",
      "train loss:0.6589483133059388\n",
      "train loss:0.8485130112641517\n",
      "train loss:0.5414904214913381\n",
      "train loss:0.6472447608287821\n",
      "train loss:0.6706157877155114\n",
      "train loss:0.5056566260242819\n",
      "train loss:0.5048379799119662\n",
      "train loss:0.6461181292112852\n",
      "train loss:0.5863509514213353\n",
      "train loss:0.5828254218667654\n",
      "train loss:0.5727380059476697\n",
      "train loss:0.5251841572972923\n",
      "train loss:0.4833316583596893\n",
      "train loss:0.48954348477034154\n",
      "train loss:0.47774750728280885\n",
      "train loss:0.496192760251435\n",
      "train loss:0.5383833811647676\n",
      "train loss:0.5561949387819515\n",
      "train loss:0.6023206641422173\n",
      "train loss:0.5308524924648903\n",
      "train loss:0.5334517741925651\n",
      "train loss:0.4018636894114311\n",
      "train loss:0.5896428705087677\n",
      "train loss:0.36194743031973514\n",
      "train loss:0.36678775388834295\n",
      "train loss:0.3121039401018308\n",
      "train loss:0.512845452090793\n",
      "train loss:0.5097034136756453\n",
      "train loss:0.5598931949829619\n",
      "train loss:0.4222515664311125\n",
      "train loss:0.47741022515041176\n",
      "train loss:0.5550882233806442\n",
      "train loss:0.42325661757016664\n",
      "train loss:0.49444257983034545\n",
      "train loss:0.3568652275829605\n",
      "train loss:0.2900241848254923\n",
      "train loss:0.4434767454804839\n",
      "train loss:0.5081737285994685\n",
      "train loss:0.4472585200660756\n",
      "train loss:0.47314240929366913\n",
      "train loss:0.43367575569319355\n",
      "train loss:0.4037767319435509\n",
      "train loss:0.4331223417249204\n",
      "train loss:0.330010313017717\n",
      "train loss:0.5230920202830845\n",
      "train loss:0.7043485703174323\n",
      "train loss:0.4027980852713229\n",
      "train loss:0.3346716937109983\n",
      "train loss:0.48105065916578055\n",
      "train loss:0.5013472131224479\n",
      "train loss:0.2426462042331483\n",
      "train loss:0.37773183171123925\n",
      "train loss:0.4875802207343803\n",
      "train loss:0.39634688358784737\n",
      "train loss:0.5084829993040945\n",
      "train loss:0.42146623604933753\n",
      "train loss:0.4245951491540637\n",
      "train loss:0.37825207105398073\n",
      "train loss:0.5388948016198166\n",
      "train loss:0.42669165854432656\n",
      "train loss:0.5558559433749755\n",
      "train loss:0.4666426488553306\n",
      "train loss:0.3377944464171641\n",
      "train loss:0.3401956244152257\n",
      "train loss:0.2814007247651735\n",
      "train loss:0.4391115282777262\n",
      "train loss:0.39265821634434667\n",
      "train loss:0.39301230402110154\n",
      "train loss:0.4686121879240065\n",
      "train loss:0.39609377082937586\n",
      "train loss:0.30550420385349136\n",
      "train loss:0.29363174565937\n",
      "train loss:0.238130576327872\n",
      "train loss:0.3443940113239477\n",
      "train loss:0.2541417287537435\n",
      "train loss:0.28380840283826375\n",
      "train loss:0.4394797837377808\n",
      "train loss:0.29641385197391146\n",
      "train loss:0.37520441743187816\n",
      "train loss:0.3977712596126803\n",
      "train loss:0.26352490303773246\n",
      "train loss:0.37575242576240725\n",
      "train loss:0.4005572357426266\n",
      "train loss:0.24999573822356505\n",
      "train loss:0.4248850323768732\n",
      "train loss:0.3947552307050616\n",
      "train loss:0.2601984337332956\n",
      "train loss:0.23139726533587932\n",
      "train loss:0.10576630262079031\n",
      "train loss:0.21826040075950742\n",
      "train loss:0.3713174473275959\n",
      "train loss:0.39730952504264844\n",
      "train loss:0.2066085875316498\n",
      "train loss:0.3323154891813887\n",
      "train loss:0.37546841448052753\n",
      "train loss:0.2624062259299624\n",
      "train loss:0.33253619380565475\n",
      "train loss:0.34085614237066525\n",
      "train loss:0.2878425377213476\n",
      "train loss:0.2273973064280963\n",
      "train loss:0.23075181388314484\n",
      "train loss:0.2593140836876522\n",
      "train loss:0.42383694721161935\n",
      "train loss:0.3143240457929174\n",
      "train loss:0.2165920544756993\n",
      "train loss:0.2855439399441487\n",
      "train loss:0.20485892357730212\n",
      "train loss:0.2810060138920446\n",
      "train loss:0.34503087227995055\n",
      "train loss:0.3270640970712671\n",
      "train loss:0.2196308118667366\n",
      "train loss:0.2802853889446652\n",
      "train loss:0.21065796312213014\n",
      "train loss:0.5268089266421468\n",
      "train loss:0.29490694720658384\n",
      "train loss:0.3588432792591996\n",
      "train loss:0.2931676599507528\n",
      "train loss:0.28319242580791465\n",
      "train loss:0.32836594465405183\n",
      "train loss:0.26093780721386084\n",
      "train loss:0.3139011153037253\n",
      "train loss:0.19373262811318742\n",
      "train loss:0.21766406688395018\n",
      "train loss:0.3614964495523452\n",
      "train loss:0.22789170350268134\n",
      "train loss:0.19400797763793304\n",
      "train loss:0.28749496330414703\n",
      "train loss:0.2570198018015041\n",
      "train loss:0.21844874460242777\n",
      "train loss:0.39271612108173776\n",
      "train loss:0.4990966987591429\n",
      "train loss:0.3370592491616245\n",
      "train loss:0.29088646769028065\n",
      "train loss:0.23093992366815058\n",
      "train loss:0.24002260680239618\n",
      "train loss:0.2500356619839852\n",
      "train loss:0.2618387555547857\n",
      "train loss:0.25409712947389457\n",
      "train loss:0.30522359198738597\n",
      "train loss:0.20765691655325746\n",
      "train loss:0.2613870540119778\n",
      "train loss:0.2447163591060842\n",
      "train loss:0.23604165037923097\n",
      "train loss:0.264423186814156\n",
      "train loss:0.2037373714419915\n",
      "train loss:0.2220438251341989\n",
      "train loss:0.4349727407990251\n",
      "train loss:0.3252253093162559\n",
      "train loss:0.3091931794304787\n",
      "train loss:0.27859727969247805\n",
      "train loss:0.3033581141761242\n",
      "train loss:0.1866764338922103\n",
      "train loss:0.37327760101317176\n",
      "train loss:0.2564930512768525\n",
      "train loss:0.2187504124849829\n",
      "train loss:0.23353521999055604\n",
      "train loss:0.26741833310766305\n",
      "train loss:0.32174862765465173\n",
      "train loss:0.16509795609567893\n",
      "train loss:0.2520088507184843\n",
      "train loss:0.5587928107392305\n",
      "train loss:0.39349632599991324\n",
      "train loss:0.31058481770477053\n",
      "train loss:0.24799844751801398\n",
      "train loss:0.214894775083661\n",
      "train loss:0.23793112667925165\n",
      "train loss:0.1458887107057005\n",
      "train loss:0.16640233454670558\n",
      "train loss:0.2648969770841947\n",
      "train loss:0.2645991966378649\n",
      "train loss:0.2130701969803604\n",
      "train loss:0.2936655425030296\n",
      "train loss:0.159265025207533\n",
      "train loss:0.262265510119468\n",
      "train loss:0.20009797511008348\n",
      "train loss:0.33749285507723975\n",
      "train loss:0.18891467672092382\n",
      "train loss:0.20025330592288895\n",
      "train loss:0.21246595281113645\n",
      "train loss:0.14852974712347303\n",
      "train loss:0.20807281246335488\n",
      "train loss:0.16355645791642726\n",
      "train loss:0.3158235188209309\n",
      "train loss:0.21672852500194584\n",
      "train loss:0.271702973725118\n",
      "train loss:0.3772354190764748\n",
      "train loss:0.10690362866614217\n",
      "train loss:0.20660344029907754\n",
      "train loss:0.25009677966003596\n",
      "train loss:0.18943670123387812\n",
      "train loss:0.30686138695466364\n",
      "train loss:0.19567686560115885\n",
      "train loss:0.3061591913407432\n",
      "train loss:0.3824307205400207\n",
      "train loss:0.19986564842017557\n",
      "train loss:0.20119526791243036\n",
      "train loss:0.30247817366392904\n",
      "train loss:0.2586540961753766\n",
      "train loss:0.21595481918125475\n",
      "train loss:0.2518760908578942\n",
      "train loss:0.20926669523653335\n",
      "train loss:0.2765013934046106\n",
      "train loss:0.1897413469924001\n",
      "train loss:0.2769226163859136\n",
      "train loss:0.2989005903561206\n",
      "train loss:0.2730592913957992\n",
      "train loss:0.09601439628378534\n",
      "train loss:0.22553731061526253\n",
      "train loss:0.1423992904903149\n",
      "train loss:0.22801477961904365\n",
      "train loss:0.2409626470660062\n",
      "train loss:0.1751397009543517\n",
      "train loss:0.19929286682704586\n",
      "train loss:0.1972287119153827\n",
      "train loss:0.3052572471172029\n",
      "train loss:0.2580315582702712\n",
      "train loss:0.21319933064973803\n",
      "train loss:0.1330424463312818\n",
      "train loss:0.18919917173791068\n",
      "train loss:0.28783335455559833\n",
      "train loss:0.12517638741786968\n",
      "train loss:0.2091130182127009\n",
      "train loss:0.31673729715319593\n",
      "train loss:0.33958987761622333\n",
      "train loss:0.20482362228557519\n",
      "train loss:0.14944239658665015\n",
      "train loss:0.2501999850201237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.29978911770812483\n",
      "train loss:0.22373372982301729\n",
      "train loss:0.14968593320419757\n",
      "train loss:0.2500912550211662\n",
      "train loss:0.2133191896131088\n",
      "train loss:0.18340317349686586\n",
      "train loss:0.3583172858491196\n",
      "train loss:0.11526926744133348\n",
      "train loss:0.17599750128099648\n",
      "train loss:0.17170815457673652\n",
      "train loss:0.08965712552511249\n",
      "train loss:0.2428448808523237\n",
      "train loss:0.2579318051152876\n",
      "train loss:0.24815440217418822\n",
      "train loss:0.21666868036016473\n",
      "train loss:0.08207033277251106\n",
      "train loss:0.1134731225133214\n",
      "train loss:0.17521225956858785\n",
      "train loss:0.22247408576372532\n",
      "train loss:0.3340966075799312\n",
      "train loss:0.17970134006884927\n",
      "train loss:0.19762711147268186\n",
      "train loss:0.18869859898544025\n",
      "train loss:0.22745630771777922\n",
      "train loss:0.18958532232283715\n",
      "train loss:0.15389169579546372\n",
      "train loss:0.16194560643932512\n",
      "train loss:0.17953256406630433\n",
      "train loss:0.09338224717873642\n",
      "train loss:0.09482710480726858\n",
      "train loss:0.34926265616459157\n",
      "train loss:0.2616861180996197\n",
      "train loss:0.16249750532654264\n",
      "train loss:0.3300437925728408\n",
      "train loss:0.13153077508626843\n",
      "train loss:0.13069481931423843\n",
      "train loss:0.11149638302128351\n",
      "train loss:0.22197016205140382\n",
      "train loss:0.3683417541359853\n",
      "train loss:0.17059921208125156\n",
      "train loss:0.35270542974858793\n",
      "train loss:0.12694435772732582\n",
      "train loss:0.19831925543760762\n",
      "train loss:0.24008939422208195\n",
      "train loss:0.19465373089090987\n",
      "train loss:0.16227176198132237\n",
      "train loss:0.0922243749625591\n",
      "train loss:0.23207142686437635\n",
      "train loss:0.11473557791042648\n",
      "train loss:0.2812859044387788\n",
      "train loss:0.14486813175662897\n",
      "train loss:0.25669287195520885\n",
      "train loss:0.1629586357687651\n",
      "train loss:0.2209172331323224\n",
      "train loss:0.25833253884182555\n",
      "train loss:0.18739936758707537\n",
      "train loss:0.09709733919751068\n",
      "train loss:0.20754296396826888\n",
      "train loss:0.2524128436623393\n",
      "train loss:0.2251265878329691\n",
      "train loss:0.18894362749608426\n",
      "train loss:0.2071969784986425\n",
      "train loss:0.2574781366998124\n",
      "train loss:0.13772566382203863\n",
      "train loss:0.2964460728283243\n",
      "train loss:0.12899568314646542\n",
      "train loss:0.2775739804877342\n",
      "train loss:0.1930665452906381\n",
      "train loss:0.2824461638603521\n",
      "train loss:0.18671354441800322\n",
      "train loss:0.1268246557312875\n",
      "train loss:0.16707105806970812\n",
      "train loss:0.1506811534471705\n",
      "train loss:0.30208591232596194\n",
      "train loss:0.1444987732615848\n",
      "train loss:0.12489721585750191\n",
      "train loss:0.09490344297376688\n",
      "train loss:0.21366827367363808\n",
      "train loss:0.19227803459003986\n",
      "train loss:0.17927940619508612\n",
      "train loss:0.23272082429061963\n",
      "train loss:0.13338312038387634\n",
      "train loss:0.24804071634216662\n",
      "train loss:0.11721614840297515\n",
      "train loss:0.16910254463204197\n",
      "train loss:0.08166295162605784\n",
      "train loss:0.32724346782330904\n",
      "train loss:0.10009407372938174\n",
      "train loss:0.14769681196302867\n",
      "train loss:0.1549517934968836\n",
      "train loss:0.15991393746745622\n",
      "train loss:0.163151605759105\n",
      "train loss:0.183161761119487\n",
      "train loss:0.18432591882207144\n",
      "train loss:0.19892146793152413\n",
      "train loss:0.1862147858781713\n",
      "train loss:0.1666130362452872\n",
      "train loss:0.14475236786935092\n",
      "train loss:0.18859894248808218\n",
      "train loss:0.1593698169961983\n",
      "train loss:0.07091626669384256\n",
      "train loss:0.11178935661613405\n",
      "train loss:0.12152690173942973\n",
      "train loss:0.2621183750976709\n",
      "train loss:0.23795209144959426\n",
      "train loss:0.17035556871280563\n",
      "train loss:0.18421548566098944\n",
      "train loss:0.12133856969398574\n",
      "train loss:0.1394154581726255\n",
      "train loss:0.16125406656728572\n",
      "train loss:0.12402151034231085\n",
      "train loss:0.16824583280772326\n",
      "train loss:0.11152414330890621\n",
      "train loss:0.1166204854320227\n",
      "train loss:0.17818042891407587\n",
      "train loss:0.1949820794988661\n",
      "train loss:0.1795282509353959\n",
      "train loss:0.2149366954487019\n",
      "train loss:0.11482440970840671\n",
      "train loss:0.14391466796832028\n",
      "train loss:0.08042727332167447\n",
      "train loss:0.15877876938393848\n",
      "train loss:0.21158799417050125\n",
      "train loss:0.14078907890688414\n",
      "train loss:0.1245842333574567\n",
      "train loss:0.12699496239111302\n",
      "train loss:0.16002591453746498\n",
      "train loss:0.1385398924321401\n",
      "train loss:0.1440283078258051\n",
      "train loss:0.08511112528635931\n",
      "train loss:0.1620985976760167\n",
      "train loss:0.07167218362917095\n",
      "train loss:0.14800410608936632\n",
      "train loss:0.08048946648910028\n",
      "train loss:0.17085796794797578\n",
      "train loss:0.08305973289456413\n",
      "train loss:0.0805969782762613\n",
      "train loss:0.12045319422975695\n",
      "train loss:0.12298182084048394\n",
      "train loss:0.14776106546654152\n",
      "train loss:0.19544163989844532\n",
      "train loss:0.12892632260778358\n",
      "train loss:0.1097317971481212\n",
      "train loss:0.15228594389669398\n",
      "train loss:0.10257315805209144\n",
      "train loss:0.1713241491172153\n",
      "train loss:0.18238896644045177\n",
      "train loss:0.11363587919741937\n",
      "train loss:0.15592441214896813\n",
      "train loss:0.1441182021027454\n",
      "train loss:0.12941180631275517\n",
      "train loss:0.15627414265749587\n",
      "train loss:0.09566742933453233\n",
      "train loss:0.1575534812950965\n",
      "train loss:0.1648268064937397\n",
      "train loss:0.13935294593340275\n",
      "train loss:0.1302611836441649\n",
      "train loss:0.12285754522816555\n",
      "train loss:0.17303388552542864\n",
      "train loss:0.10739270442274756\n",
      "train loss:0.17952285147389194\n",
      "train loss:0.10849224286323723\n",
      "train loss:0.11777809878069387\n",
      "train loss:0.13647914470300676\n",
      "train loss:0.1353675709727199\n",
      "train loss:0.14838438029146855\n",
      "train loss:0.07861604345053418\n",
      "train loss:0.10388016741865862\n",
      "train loss:0.14265701782395593\n",
      "train loss:0.13797655594200148\n",
      "train loss:0.09790734445997426\n",
      "train loss:0.056863845900526726\n",
      "train loss:0.1138710240151255\n",
      "train loss:0.12788470951978625\n",
      "train loss:0.1473047985661685\n",
      "train loss:0.1387046043739242\n",
      "train loss:0.17215308909757548\n",
      "train loss:0.15398946965897442\n",
      "train loss:0.06730409244036165\n",
      "train loss:0.15777435424523437\n",
      "train loss:0.1196811406765672\n",
      "train loss:0.1308924218840162\n",
      "train loss:0.1573989984114628\n",
      "train loss:0.2053963549274267\n",
      "train loss:0.11788580014452615\n",
      "train loss:0.1534942453174578\n",
      "train loss:0.13664028919116875\n",
      "train loss:0.12778643391927147\n",
      "train loss:0.23302486961096736\n",
      "train loss:0.1358046042194246\n",
      "train loss:0.14813725937184713\n",
      "train loss:0.1638047164358154\n",
      "train loss:0.10296350282634056\n",
      "train loss:0.2249063186334877\n",
      "train loss:0.1550970359802593\n",
      "train loss:0.09663517274441359\n",
      "train loss:0.08615743653222693\n",
      "train loss:0.16960314082412997\n",
      "train loss:0.11155969070426006\n",
      "train loss:0.11664532529805405\n",
      "train loss:0.10653738531373806\n",
      "train loss:0.11592963580753995\n",
      "train loss:0.2477536284502786\n",
      "train loss:0.2964865917099062\n",
      "train loss:0.2734294081032431\n",
      "train loss:0.09145027470605953\n",
      "train loss:0.1547053292612489\n",
      "train loss:0.13223424658934319\n",
      "train loss:0.11978774634668567\n",
      "train loss:0.10013119788255366\n",
      "train loss:0.11971628746473562\n",
      "train loss:0.07330762039691545\n",
      "train loss:0.13234293680060885\n",
      "train loss:0.14228347817670775\n",
      "train loss:0.09657009532388253\n",
      "train loss:0.07506748505087431\n",
      "train loss:0.3094713941219215\n",
      "train loss:0.09581248288560858\n",
      "train loss:0.10324175706069662\n",
      "train loss:0.09065575104628493\n",
      "train loss:0.07976380450570743\n",
      "train loss:0.13334459893396103\n",
      "train loss:0.10207176371899694\n",
      "train loss:0.10152405306299749\n",
      "train loss:0.07321153716895405\n",
      "train loss:0.08262712894691152\n",
      "train loss:0.20512326328904387\n",
      "train loss:0.1633050466155096\n",
      "train loss:0.3169079355616995\n",
      "train loss:0.09565175212403425\n",
      "train loss:0.16074782701390994\n",
      "train loss:0.1354550526147525\n",
      "train loss:0.06568817069617766\n",
      "train loss:0.10499110810598877\n",
      "train loss:0.11667155958968489\n",
      "train loss:0.09640477534186058\n",
      "train loss:0.05984198733359032\n",
      "train loss:0.05143463905682125\n",
      "train loss:0.0863534155245985\n",
      "train loss:0.11312507757480454\n",
      "train loss:0.08540522690366202\n",
      "train loss:0.1377385981249759\n",
      "train loss:0.11387090018690772\n",
      "train loss:0.14162635823484115\n",
      "train loss:0.13689812186454225\n",
      "train loss:0.1507955286803464\n",
      "train loss:0.17861250270491077\n",
      "train loss:0.2280308034116877\n",
      "train loss:0.06874273811424443\n",
      "train loss:0.2707448785106966\n",
      "train loss:0.09463877409784205\n",
      "train loss:0.14012884508572082\n",
      "train loss:0.13339982573487208\n",
      "train loss:0.09680206070997516\n",
      "train loss:0.15027909069585474\n",
      "train loss:0.12701144646239027\n",
      "train loss:0.08099195039530976\n",
      "train loss:0.07197995549979355\n",
      "train loss:0.14415625012167724\n",
      "train loss:0.18057521158612186\n",
      "train loss:0.17049878097722465\n",
      "train loss:0.08910827481048197\n",
      "train loss:0.07686551424087175\n",
      "train loss:0.08791556104485489\n",
      "train loss:0.17734341940789924\n",
      "train loss:0.10677253682395647\n",
      "train loss:0.13246774941317235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04311841583398583\n",
      "train loss:0.08887208071861742\n",
      "train loss:0.0652833601311166\n",
      "train loss:0.1031747772023815\n",
      "train loss:0.11439054723386613\n",
      "train loss:0.20678034083133312\n",
      "train loss:0.15402057219595505\n",
      "train loss:0.10978328679655748\n",
      "train loss:0.13137664692172968\n",
      "train loss:0.06619800032501741\n",
      "train loss:0.12142320832407957\n",
      "train loss:0.13087170221941474\n",
      "train loss:0.0979480513651402\n",
      "train loss:0.1403736924427386\n",
      "train loss:0.08106345412061153\n",
      "train loss:0.09048486520935191\n",
      "train loss:0.09851056806667179\n",
      "train loss:0.04975651857608062\n",
      "train loss:0.15294040874315867\n",
      "train loss:0.0661590908902223\n",
      "train loss:0.06461742694178786\n",
      "train loss:0.09199320277004176\n",
      "train loss:0.05666362333177379\n",
      "train loss:0.08035178100840458\n",
      "train loss:0.0810392562648621\n",
      "train loss:0.11379554373090132\n",
      "train loss:0.2630595482164033\n",
      "train loss:0.09981094452886725\n",
      "train loss:0.22241517514907913\n",
      "train loss:0.11500299568537066\n",
      "train loss:0.08422591843088006\n",
      "train loss:0.12745703873455078\n",
      "train loss:0.14525343161328896\n",
      "train loss:0.15685018125988562\n",
      "train loss:0.14673622509635673\n",
      "train loss:0.13115146948433598\n",
      "train loss:0.1347504918904269\n",
      "train loss:0.16107560005588722\n",
      "train loss:0.06011825147505328\n",
      "train loss:0.1503929972149548\n",
      "train loss:0.1684590922353443\n",
      "train loss:0.056506680758808\n",
      "train loss:0.2750558552636401\n",
      "train loss:0.10712478272708781\n",
      "train loss:0.1454869822660812\n",
      "train loss:0.06560104949780864\n",
      "train loss:0.045240078302869274\n",
      "train loss:0.025749424714011857\n",
      "train loss:0.12873607956235444\n",
      "train loss:0.07454993184309254\n",
      "train loss:0.09029534866914084\n",
      "train loss:0.06233333654286089\n",
      "train loss:0.14544927440562172\n",
      "train loss:0.053720399107927495\n",
      "train loss:0.054435556434990866\n",
      "train loss:0.15762833263888573\n",
      "train loss:0.08086459136216986\n",
      "train loss:0.05433642695828066\n",
      "train loss:0.14907321042071975\n",
      "train loss:0.11099003597649687\n",
      "train loss:0.18253129117096162\n",
      "train loss:0.10807698102723147\n",
      "train loss:0.17183392486661947\n",
      "train loss:0.08480279208087994\n",
      "=== epoch:2, train acc:0.972, test acc:0.965 ===\n",
      "train loss:0.09093815847833321\n",
      "train loss:0.13853619051570853\n",
      "train loss:0.03849547806830303\n",
      "train loss:0.12934260333263256\n",
      "train loss:0.06201570400838606\n",
      "train loss:0.12442112500961862\n",
      "train loss:0.14503647315575818\n",
      "train loss:0.08693242781018712\n",
      "train loss:0.07038018514762479\n",
      "train loss:0.0972082868835177\n",
      "train loss:0.11593928170597952\n",
      "train loss:0.09592272859259302\n",
      "train loss:0.09211776726183407\n",
      "train loss:0.12379689852832712\n",
      "train loss:0.12374788079380286\n",
      "train loss:0.06982118166667775\n",
      "train loss:0.056729386513209384\n",
      "train loss:0.13348543597446785\n",
      "train loss:0.046829185859282266\n",
      "train loss:0.10775381780129376\n",
      "train loss:0.043815590259830096\n",
      "train loss:0.08665676622869897\n",
      "train loss:0.19980092984646247\n",
      "train loss:0.10492970816942217\n",
      "train loss:0.0662478986520275\n",
      "train loss:0.041156997478469376\n",
      "train loss:0.05589787050823545\n",
      "train loss:0.08496237926417285\n",
      "train loss:0.11984153179110012\n",
      "train loss:0.16638862894715933\n",
      "train loss:0.05406473456917796\n",
      "train loss:0.08257123233624744\n",
      "train loss:0.09013648046257\n",
      "train loss:0.14070471761417028\n",
      "train loss:0.0954424628095574\n",
      "train loss:0.1083440462030727\n",
      "train loss:0.05316218709022635\n",
      "train loss:0.06678997487496645\n",
      "train loss:0.03137616818725452\n",
      "train loss:0.07243537415080152\n",
      "train loss:0.045478395095246066\n",
      "train loss:0.12059549106433812\n",
      "train loss:0.07147560644223122\n",
      "train loss:0.022297873458989256\n",
      "train loss:0.19286653652380029\n",
      "train loss:0.14174392550088208\n",
      "train loss:0.10391638615354286\n",
      "train loss:0.061137066688033447\n",
      "train loss:0.07762808356424641\n",
      "train loss:0.06900563941800913\n",
      "train loss:0.07450991250030806\n",
      "train loss:0.24235617867525933\n",
      "train loss:0.19387451398406927\n",
      "train loss:0.08261873786298496\n",
      "train loss:0.09646464739711767\n",
      "train loss:0.12396095431285203\n",
      "train loss:0.1705580761657998\n",
      "train loss:0.11920291309715786\n",
      "train loss:0.02427909718521291\n",
      "train loss:0.14375001700334622\n",
      "train loss:0.08471414592689692\n",
      "train loss:0.13051969543341874\n",
      "train loss:0.06794274909567755\n",
      "train loss:0.08346801193389557\n",
      "train loss:0.09819815377807335\n",
      "train loss:0.042990030404219316\n",
      "train loss:0.1025394795985409\n",
      "train loss:0.03132238698665864\n",
      "train loss:0.03867683505414331\n",
      "train loss:0.13104600150873308\n",
      "train loss:0.0900264641539899\n",
      "train loss:0.031385972626177205\n",
      "train loss:0.08710170923225206\n",
      "train loss:0.10470352932078304\n",
      "train loss:0.0508246898046937\n",
      "train loss:0.06264840720877492\n",
      "train loss:0.048977247900643214\n",
      "train loss:0.09106479248032202\n",
      "train loss:0.10395772583766175\n",
      "train loss:0.12444159416254282\n",
      "train loss:0.14495558999944655\n",
      "train loss:0.12917932792650358\n",
      "train loss:0.10488506417013682\n",
      "train loss:0.1503396096040643\n",
      "train loss:0.0434366165244671\n",
      "train loss:0.09704817451194846\n",
      "train loss:0.03437447560612622\n",
      "train loss:0.05869804527151143\n",
      "train loss:0.15061507047394998\n",
      "train loss:0.04565981791323667\n",
      "train loss:0.12699353628808688\n",
      "train loss:0.12068124090098459\n",
      "train loss:0.12441385965307618\n",
      "train loss:0.13721893936942117\n",
      "train loss:0.0653062551069632\n",
      "train loss:0.09191197121534414\n",
      "train loss:0.16521449086281476\n",
      "train loss:0.18601384623822856\n",
      "train loss:0.10818967646372864\n",
      "train loss:0.1171934495387874\n",
      "train loss:0.0593163319651683\n",
      "train loss:0.0704281990157418\n",
      "train loss:0.08677287492259744\n",
      "train loss:0.11747471677962454\n",
      "train loss:0.09379146825639659\n",
      "train loss:0.0710763568897985\n",
      "train loss:0.09375271864539268\n",
      "train loss:0.048149032508297704\n",
      "train loss:0.08487824342083285\n",
      "train loss:0.10890320436700568\n",
      "train loss:0.10022929199087295\n",
      "train loss:0.11194149068926579\n",
      "train loss:0.19867606048896674\n",
      "train loss:0.051781822806344684\n",
      "train loss:0.12191189380148276\n",
      "train loss:0.15955770407164727\n",
      "train loss:0.15019636246064144\n",
      "train loss:0.08215878807420465\n",
      "train loss:0.11837934725048684\n",
      "train loss:0.04536616331258356\n",
      "train loss:0.09941724321895543\n",
      "train loss:0.026186478079139278\n",
      "train loss:0.2037015337860384\n",
      "train loss:0.2328411975506834\n",
      "train loss:0.0996233523478659\n",
      "train loss:0.09923897771576096\n",
      "train loss:0.041414929872188935\n",
      "train loss:0.15894341571809145\n",
      "train loss:0.055926800427803486\n",
      "train loss:0.0752732071173258\n",
      "train loss:0.049166960686705306\n",
      "train loss:0.08732181549446295\n",
      "train loss:0.12907117771140805\n",
      "train loss:0.12069922781386909\n",
      "train loss:0.09373207878902332\n",
      "train loss:0.039558743890800906\n",
      "train loss:0.13548588553133936\n",
      "train loss:0.07911789328943854\n",
      "train loss:0.0457438000555715\n",
      "train loss:0.0743304600270264\n",
      "train loss:0.08741925449156102\n",
      "train loss:0.12227467371315111\n",
      "train loss:0.10273801229050063\n",
      "train loss:0.06299089824254424\n",
      "train loss:0.09973379934490603\n",
      "train loss:0.050172268958906675\n",
      "train loss:0.05937282193649826\n",
      "train loss:0.1017555714114512\n",
      "train loss:0.02901484957062609\n",
      "train loss:0.04508417429040949\n",
      "train loss:0.15522428108623196\n",
      "train loss:0.08371897540413054\n",
      "train loss:0.061802978404803935\n",
      "train loss:0.0730975238755464\n",
      "train loss:0.05748058910979377\n",
      "train loss:0.07879705656419878\n",
      "train loss:0.0529747441797695\n",
      "train loss:0.08592068068247069\n",
      "train loss:0.1197589679471015\n",
      "train loss:0.12371709768073458\n",
      "train loss:0.05850277123535335\n",
      "train loss:0.08643623561657574\n",
      "train loss:0.15348541195097842\n",
      "train loss:0.0751277502111721\n",
      "train loss:0.047486705569232096\n",
      "train loss:0.05616171954064041\n",
      "train loss:0.04928372106290573\n",
      "train loss:0.08139917154435708\n",
      "train loss:0.06064986158705579\n",
      "train loss:0.09849334650193754\n",
      "train loss:0.07400581247333776\n",
      "train loss:0.0781897367778723\n",
      "train loss:0.13497557472504637\n",
      "train loss:0.14536452120706014\n",
      "train loss:0.07223670706340989\n",
      "train loss:0.08347310739682859\n",
      "train loss:0.11535648610883702\n",
      "train loss:0.15702381004946278\n",
      "train loss:0.1261244030891531\n",
      "train loss:0.04288203341116202\n",
      "train loss:0.07088077673782382\n",
      "train loss:0.04634835844091839\n",
      "train loss:0.10133703477676857\n",
      "train loss:0.061342767353474346\n",
      "train loss:0.0914559807674634\n",
      "train loss:0.06102895688106107\n",
      "train loss:0.06883139101501942\n",
      "train loss:0.01974623990310253\n",
      "train loss:0.15550254065216534\n",
      "train loss:0.13178611124972858\n",
      "train loss:0.045048452159202175\n",
      "train loss:0.09609567256229175\n",
      "train loss:0.07299809659280308\n",
      "train loss:0.05987945645270244\n",
      "train loss:0.1365227389331599\n",
      "train loss:0.06174671886536792\n",
      "train loss:0.08955796997021126\n",
      "train loss:0.04171642967998127\n",
      "train loss:0.05599020608890793\n",
      "train loss:0.1588272030458762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10616213697558177\n",
      "train loss:0.14422622335161464\n",
      "train loss:0.043921909537028354\n",
      "train loss:0.011174947294442412\n",
      "train loss:0.07920548914475152\n",
      "train loss:0.05822687475285646\n",
      "train loss:0.09105947470183744\n",
      "train loss:0.10372828944742027\n",
      "train loss:0.14734902816666046\n",
      "train loss:0.10364914487718019\n",
      "train loss:0.14685864271605453\n",
      "train loss:0.16052048997873164\n",
      "train loss:0.12369756282245908\n",
      "train loss:0.10361609783874329\n",
      "train loss:0.09962433924374377\n",
      "train loss:0.04560022044231138\n",
      "train loss:0.051007471135592085\n",
      "train loss:0.03279982741515665\n",
      "train loss:0.1623630524945129\n",
      "train loss:0.09459625797806458\n",
      "train loss:0.08224368539758775\n",
      "train loss:0.06052825377041608\n",
      "train loss:0.15333639469130433\n",
      "train loss:0.03307275936141146\n",
      "train loss:0.057711195585005336\n",
      "train loss:0.15765636821088105\n",
      "train loss:0.13366454977834544\n",
      "train loss:0.019017895640027614\n",
      "train loss:0.13489169193726375\n",
      "train loss:0.053250288269895224\n",
      "train loss:0.07623711790581407\n",
      "train loss:0.03956000461371614\n",
      "train loss:0.06932407724190355\n",
      "train loss:0.028882379524652734\n",
      "train loss:0.1239063270166849\n",
      "train loss:0.037770953250891325\n",
      "train loss:0.08908783487904426\n",
      "train loss:0.03732131446721569\n",
      "train loss:0.04774240135759165\n",
      "train loss:0.07814191884228053\n",
      "train loss:0.1595164506340455\n",
      "train loss:0.05347300791079513\n",
      "train loss:0.1650215908325221\n",
      "train loss:0.08524553461640166\n",
      "train loss:0.07875048954681987\n",
      "train loss:0.10880387550288377\n",
      "train loss:0.04467549183307016\n",
      "train loss:0.13358979138800728\n",
      "train loss:0.06528207710001831\n",
      "train loss:0.07270170336026474\n",
      "train loss:0.17459810903534506\n",
      "train loss:0.08681921489119311\n",
      "train loss:0.11237920019532671\n",
      "train loss:0.09989431944685129\n",
      "train loss:0.11043587708132105\n",
      "train loss:0.05397197843719474\n",
      "train loss:0.07874471267672348\n",
      "train loss:0.10343918290083648\n",
      "train loss:0.09561407349480035\n",
      "train loss:0.04782400330443449\n",
      "train loss:0.12497028046653183\n",
      "train loss:0.08558782971344554\n",
      "train loss:0.0510525860110115\n",
      "train loss:0.08354269393042052\n",
      "train loss:0.055630826225197216\n",
      "train loss:0.07623549386269696\n",
      "train loss:0.0698458511550313\n",
      "train loss:0.0582018714933197\n",
      "train loss:0.05525218808278499\n",
      "train loss:0.07129724177599059\n",
      "train loss:0.09812531772094209\n",
      "train loss:0.0749977081398681\n",
      "train loss:0.06339467817811961\n",
      "train loss:0.03316488609630789\n",
      "train loss:0.10130123951263742\n",
      "train loss:0.08262947909201675\n",
      "train loss:0.160352418092343\n",
      "train loss:0.04971580544395036\n",
      "train loss:0.06726212967207439\n",
      "train loss:0.145267078603385\n",
      "train loss:0.11443045346280342\n",
      "train loss:0.07488353598607789\n",
      "train loss:0.08525231631008935\n",
      "train loss:0.032729580644007834\n",
      "train loss:0.04506596456652475\n",
      "train loss:0.0733213215283565\n",
      "train loss:0.09911073166442114\n",
      "train loss:0.048126960827378495\n",
      "train loss:0.06260405905860457\n",
      "train loss:0.0795410173901121\n",
      "train loss:0.11094463562826588\n",
      "train loss:0.18922570757747517\n",
      "train loss:0.07124333673652423\n",
      "train loss:0.06591653390195437\n",
      "train loss:0.047314788652519965\n",
      "train loss:0.09305904338893224\n",
      "train loss:0.07661518337257667\n",
      "train loss:0.07606338062553625\n",
      "train loss:0.08135440903266179\n",
      "train loss:0.0815288472454875\n",
      "train loss:0.033393413712078476\n",
      "train loss:0.11133351667553695\n",
      "train loss:0.08181944436453742\n",
      "train loss:0.06330960951828124\n",
      "train loss:0.028487520035752754\n",
      "train loss:0.09233125862235267\n",
      "train loss:0.06762265303376366\n",
      "train loss:0.13025502535467004\n",
      "train loss:0.06573970823293628\n",
      "train loss:0.06445620571608769\n",
      "train loss:0.07517002022948309\n",
      "train loss:0.07408428023573982\n",
      "train loss:0.08727043871020351\n",
      "train loss:0.04638193640815313\n",
      "train loss:0.08358628508282022\n",
      "train loss:0.04744749939239882\n",
      "train loss:0.04460238031693699\n",
      "train loss:0.044932321904062274\n",
      "train loss:0.07815965510646344\n",
      "train loss:0.04343068239804809\n",
      "train loss:0.07987657111920565\n",
      "train loss:0.09138736013205634\n",
      "train loss:0.042052688216797855\n",
      "train loss:0.09465736395056203\n",
      "train loss:0.06858989160674989\n",
      "train loss:0.04353403427524841\n",
      "train loss:0.09073924243007049\n",
      "train loss:0.06158759652272571\n",
      "train loss:0.06635573172570643\n",
      "train loss:0.0798637225394594\n",
      "train loss:0.0243868117719502\n",
      "train loss:0.043573119763613326\n",
      "train loss:0.04588155805710138\n",
      "train loss:0.11645759781658765\n",
      "train loss:0.035988653565765506\n",
      "train loss:0.06176573672358807\n",
      "train loss:0.058612326069865016\n",
      "train loss:0.05057731721443793\n",
      "train loss:0.04450983253838665\n",
      "train loss:0.06002198914782915\n",
      "train loss:0.05076662402611745\n",
      "train loss:0.03682788566469373\n",
      "train loss:0.0965327167673682\n",
      "train loss:0.025058544630233503\n",
      "train loss:0.1138785646232851\n",
      "train loss:0.1818380220949496\n",
      "train loss:0.060888574674659905\n",
      "train loss:0.029494758400052272\n",
      "train loss:0.045041039292830855\n",
      "train loss:0.07652654859400307\n",
      "train loss:0.018044019426557076\n",
      "train loss:0.09030212636789817\n",
      "train loss:0.10374956208131074\n",
      "train loss:0.08027641297458815\n",
      "train loss:0.03181637107213482\n",
      "train loss:0.032175029817015297\n",
      "train loss:0.06706103505591511\n",
      "train loss:0.05257843192139796\n",
      "train loss:0.025394697915385636\n",
      "train loss:0.09960059339793839\n",
      "train loss:0.05227992868353128\n",
      "train loss:0.15938444059692317\n",
      "train loss:0.08571095994793344\n",
      "train loss:0.04703763961249503\n",
      "train loss:0.06673178096268628\n",
      "train loss:0.06689445809343825\n",
      "train loss:0.06718651379057024\n",
      "train loss:0.04765372548027573\n",
      "train loss:0.1046085563242287\n",
      "train loss:0.048681732442543375\n",
      "train loss:0.042345155264579847\n",
      "train loss:0.04839630652969774\n",
      "train loss:0.023563447665721955\n",
      "train loss:0.09949967829884221\n",
      "train loss:0.09547648126381131\n",
      "train loss:0.08973292465608461\n",
      "train loss:0.07040285037199269\n",
      "train loss:0.06093502500869457\n",
      "train loss:0.08121883121497302\n",
      "train loss:0.13389241677319508\n",
      "train loss:0.08469551547502635\n",
      "train loss:0.1049303010529674\n",
      "train loss:0.060408025013030234\n",
      "train loss:0.09647538290743712\n",
      "train loss:0.1631116739106466\n",
      "train loss:0.10150951968533274\n",
      "train loss:0.027572412273272562\n",
      "train loss:0.027011810786019642\n",
      "train loss:0.14905162980929926\n",
      "train loss:0.04569988030530479\n",
      "train loss:0.04778614816110095\n",
      "train loss:0.05215536699172693\n",
      "train loss:0.08997454256522558\n",
      "train loss:0.05330173468103863\n",
      "train loss:0.16210767203903043\n",
      "train loss:0.04478347960423419\n",
      "train loss:0.010002796898027579\n",
      "train loss:0.04968766651233629\n",
      "train loss:0.06864493179116947\n",
      "train loss:0.02756544349121732\n",
      "train loss:0.05715719659951211\n",
      "train loss:0.02003067837570613\n",
      "train loss:0.05946000064696433\n",
      "train loss:0.07775641351695087\n",
      "train loss:0.08593595670379817\n",
      "train loss:0.09816914994711404\n",
      "train loss:0.01410008057578529\n",
      "train loss:0.13156941537756997\n",
      "train loss:0.10691304337610029\n",
      "train loss:0.02698959061420286\n",
      "train loss:0.05184142350472979\n",
      "train loss:0.10619927624342289\n",
      "train loss:0.028143155253155663\n",
      "train loss:0.06807783735819703\n",
      "train loss:0.03583341080286704\n",
      "train loss:0.14118955619435553\n",
      "train loss:0.0948874236091296\n",
      "train loss:0.1860326324913421\n",
      "train loss:0.11386355344178822\n",
      "train loss:0.06057370174192122\n",
      "train loss:0.021395226059473096\n",
      "train loss:0.04229193603874512\n",
      "train loss:0.0738558856277438\n",
      "train loss:0.07889874147824344\n",
      "train loss:0.0861324357834606\n",
      "train loss:0.09237878841629187\n",
      "train loss:0.06254781469868008\n",
      "train loss:0.08651841452143785\n",
      "train loss:0.20939889277979598\n",
      "train loss:0.0868329883471964\n",
      "train loss:0.015034859435539465\n",
      "train loss:0.07827108164348334\n",
      "train loss:0.07522131667422832\n",
      "train loss:0.06869451163963544\n",
      "train loss:0.04212014653878594\n",
      "train loss:0.05408073238443141\n",
      "train loss:0.06660266105234097\n",
      "train loss:0.19292183553813605\n",
      "train loss:0.13766123838587907\n",
      "train loss:0.012207664767853652\n",
      "train loss:0.04502395588186992\n",
      "train loss:0.01886188523818278\n",
      "train loss:0.0760257263192024\n",
      "train loss:0.08646446662446036\n",
      "train loss:0.13800972660389507\n",
      "train loss:0.0913445646549468\n",
      "train loss:0.0660326315695612\n",
      "train loss:0.023473912500636254\n",
      "train loss:0.10710962037952776\n",
      "train loss:0.0762151171578696\n",
      "train loss:0.1151199946677552\n",
      "train loss:0.051322818119184606\n",
      "train loss:0.0688652556114277\n",
      "train loss:0.046557349254280754\n",
      "train loss:0.0202115053886452\n",
      "train loss:0.15511058052624102\n",
      "train loss:0.06532889972076109\n",
      "train loss:0.026704074625716712\n",
      "train loss:0.023696786381500776\n",
      "train loss:0.12553813496769006\n",
      "train loss:0.06846112313116953\n",
      "train loss:0.0695821382184469\n",
      "train loss:0.052932290079345815\n",
      "train loss:0.07932283420630895\n",
      "train loss:0.1292541363595504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0918434150850777\n",
      "train loss:0.07165894322152376\n",
      "train loss:0.041411542281776244\n",
      "train loss:0.04498302003553178\n",
      "train loss:0.038857593629854276\n",
      "train loss:0.07509559653819511\n",
      "train loss:0.08417193488389177\n",
      "train loss:0.063749411646883\n",
      "train loss:0.08356217581217808\n",
      "train loss:0.15528109685396763\n",
      "train loss:0.1412860784969866\n",
      "train loss:0.041937518707993726\n",
      "train loss:0.033903670262770504\n",
      "train loss:0.10841787583671599\n",
      "train loss:0.04871626156850738\n",
      "train loss:0.04195078884684821\n",
      "train loss:0.029451763380779775\n",
      "train loss:0.13391988428154952\n",
      "train loss:0.09650525076587463\n",
      "train loss:0.1039424026597629\n",
      "train loss:0.08779580492608949\n",
      "train loss:0.05467887558466646\n",
      "train loss:0.026202715078874506\n",
      "train loss:0.07614291593760654\n",
      "train loss:0.055208627059525284\n",
      "train loss:0.031535725215592274\n",
      "train loss:0.04637125608336937\n",
      "train loss:0.047836971978230336\n",
      "train loss:0.039683111391314196\n",
      "train loss:0.09860485009707841\n",
      "train loss:0.038632003159354694\n",
      "train loss:0.0284996792678577\n",
      "train loss:0.15300108909443072\n",
      "train loss:0.047002398525038895\n",
      "train loss:0.08524804511493021\n",
      "train loss:0.04731204309850478\n",
      "train loss:0.13883633847432023\n",
      "train loss:0.10056362732611338\n",
      "train loss:0.05198738263316848\n",
      "train loss:0.035364369056456804\n",
      "train loss:0.052030660450367805\n",
      "train loss:0.06350590356757464\n",
      "train loss:0.06873778034781738\n",
      "train loss:0.050568409151201185\n",
      "train loss:0.0685706325777302\n",
      "train loss:0.15090557882300298\n",
      "train loss:0.10096624503137111\n",
      "train loss:0.10761406950116159\n",
      "train loss:0.04747375234105507\n",
      "train loss:0.037471511189387255\n",
      "train loss:0.06590610240861641\n",
      "train loss:0.024475984304927784\n",
      "train loss:0.11760705006335755\n",
      "train loss:0.08904826970817613\n",
      "train loss:0.10005449158573558\n",
      "train loss:0.0902565083550879\n",
      "train loss:0.06498658691519817\n",
      "train loss:0.0711053156968074\n",
      "train loss:0.07795796100383028\n",
      "train loss:0.07752724011309386\n",
      "train loss:0.04685048228868581\n",
      "train loss:0.11988094798334664\n",
      "train loss:0.029064543938954954\n",
      "train loss:0.03427620631495306\n",
      "train loss:0.05028745322821746\n",
      "train loss:0.030461396815011733\n",
      "train loss:0.06801049685028436\n",
      "train loss:0.125331019541683\n",
      "train loss:0.08584389595491732\n",
      "train loss:0.03526676060373349\n",
      "train loss:0.11687132636831186\n",
      "train loss:0.12410942640624023\n",
      "train loss:0.04430792692704043\n",
      "train loss:0.08108556026407304\n",
      "train loss:0.07314750242742091\n",
      "train loss:0.17108774368390023\n",
      "train loss:0.06921286733704334\n",
      "train loss:0.09652933019032348\n",
      "train loss:0.03645387620474378\n",
      "train loss:0.08794785460050562\n",
      "train loss:0.035364675763886404\n",
      "train loss:0.07504428256452718\n",
      "train loss:0.025862424708868938\n",
      "train loss:0.10726021504200368\n",
      "train loss:0.08362118235837297\n",
      "train loss:0.09348441818657277\n",
      "train loss:0.0624808059133513\n",
      "train loss:0.06038062056214522\n",
      "train loss:0.06213330977073091\n",
      "train loss:0.038343895939137305\n",
      "train loss:0.07476042638999292\n",
      "train loss:0.022478839529024564\n",
      "train loss:0.029064399100468256\n",
      "train loss:0.030983185775906884\n",
      "train loss:0.043487978234343895\n",
      "train loss:0.10347398786729041\n",
      "train loss:0.044686593657177746\n",
      "train loss:0.03714931898456268\n",
      "train loss:0.04693377000001666\n",
      "train loss:0.06486932481522457\n",
      "train loss:0.01427236028282828\n",
      "train loss:0.024797879400749286\n",
      "train loss:0.0626327290484455\n",
      "train loss:0.0401106232039217\n",
      "train loss:0.01857162253367169\n",
      "train loss:0.025165415790329736\n",
      "train loss:0.03677584855689957\n",
      "train loss:0.037552318206115265\n",
      "train loss:0.04529139598842913\n",
      "train loss:0.05178783218460278\n",
      "train loss:0.036013172698115145\n",
      "train loss:0.09431145763095541\n",
      "train loss:0.10860953438122299\n",
      "train loss:0.08462157038600944\n",
      "train loss:0.02147062071535182\n",
      "train loss:0.04367532277369638\n",
      "train loss:0.12103424055139474\n",
      "train loss:0.07673999399025241\n",
      "train loss:0.062043940790635604\n",
      "train loss:0.029836049364804405\n",
      "train loss:0.0566543622095125\n",
      "train loss:0.05157867576067224\n",
      "train loss:0.03394042170643729\n",
      "train loss:0.08106535877963354\n",
      "train loss:0.06411143951173041\n",
      "train loss:0.11015961608613997\n",
      "train loss:0.055357402461337954\n",
      "train loss:0.050295031148223465\n",
      "train loss:0.06436176789999369\n",
      "train loss:0.15576591665787223\n",
      "train loss:0.21366896371089347\n",
      "train loss:0.057204420074374936\n",
      "train loss:0.015069136976950219\n",
      "train loss:0.06828741454454555\n",
      "train loss:0.12557788351993845\n",
      "=== epoch:3, train acc:0.976, test acc:0.98 ===\n",
      "train loss:0.04957400588748095\n",
      "train loss:0.0582287299042261\n",
      "train loss:0.1016274320309313\n",
      "train loss:0.04950517467899343\n",
      "train loss:0.06901284157822614\n",
      "train loss:0.05508377779715718\n",
      "train loss:0.026669220012183394\n",
      "train loss:0.03833401130598411\n",
      "train loss:0.04439346845420961\n",
      "train loss:0.04039732466255694\n",
      "train loss:0.06765672965248103\n",
      "train loss:0.0740397486862607\n",
      "train loss:0.033230655839876985\n",
      "train loss:0.16111573537902746\n",
      "train loss:0.020476040198467462\n",
      "train loss:0.03192112566243744\n",
      "train loss:0.027287526768356045\n",
      "train loss:0.029778262826854928\n",
      "train loss:0.041767366729877145\n",
      "train loss:0.027110152007738742\n",
      "train loss:0.057887237156954735\n",
      "train loss:0.2114049979602269\n",
      "train loss:0.03500490701403107\n",
      "train loss:0.01708254381876095\n",
      "train loss:0.1389498635713666\n",
      "train loss:0.02108975809696905\n",
      "train loss:0.18147959490467355\n",
      "train loss:0.019850831597717226\n",
      "train loss:0.047843306318404256\n",
      "train loss:0.08282366563391895\n",
      "train loss:0.035761388022080814\n",
      "train loss:0.07626303674573187\n",
      "train loss:0.03179042714105321\n",
      "train loss:0.035716383160091576\n",
      "train loss:0.043042948983282654\n",
      "train loss:0.07521304117790215\n",
      "train loss:0.04122067363268412\n",
      "train loss:0.05909845081996465\n",
      "train loss:0.03688232195489318\n",
      "train loss:0.05116389272975504\n",
      "train loss:0.05686375456235401\n",
      "train loss:0.05591472838241592\n",
      "train loss:0.04832542437584476\n",
      "train loss:0.07543780813603033\n",
      "train loss:0.04552498792304574\n",
      "train loss:0.06469601630910665\n",
      "train loss:0.03256889878020926\n",
      "train loss:0.04237361529478483\n",
      "train loss:0.054239767559732144\n",
      "train loss:0.06961310491428656\n",
      "train loss:0.0924123598979576\n",
      "train loss:0.13675337287013525\n",
      "train loss:0.09767750395783331\n",
      "train loss:0.016833163646602936\n",
      "train loss:0.017683957662261003\n",
      "train loss:0.056569786445553966\n",
      "train loss:0.04610917578006531\n",
      "train loss:0.032420708423919\n",
      "train loss:0.08368240896428521\n",
      "train loss:0.03716189083238312\n",
      "train loss:0.16663684350425373\n",
      "train loss:0.024620267354904714\n",
      "train loss:0.023172061200743575\n",
      "train loss:0.025584836661354794\n",
      "train loss:0.050107178598907794\n",
      "train loss:0.10977242000944445\n",
      "train loss:0.05613506978207292\n",
      "train loss:0.11875087848759894\n",
      "train loss:0.08745939510761129\n",
      "train loss:0.10346391982084457\n",
      "train loss:0.07922810932644282\n",
      "train loss:0.015511291901400113\n",
      "train loss:0.04230791171429252\n",
      "train loss:0.1865794942059844\n",
      "train loss:0.087362873429436\n",
      "train loss:0.1071070817969026\n",
      "train loss:0.05972141854341025\n",
      "train loss:0.09822295652958464\n",
      "train loss:0.08178969161566536\n",
      "train loss:0.08232187981795987\n",
      "train loss:0.052744017304585764\n",
      "train loss:0.03270439525747749\n",
      "train loss:0.05864576582295521\n",
      "train loss:0.041465733196699654\n",
      "train loss:0.09804584958614353\n",
      "train loss:0.07234074082440144\n",
      "train loss:0.07828325198187223\n",
      "train loss:0.05983456565759057\n",
      "train loss:0.13277308792983253\n",
      "train loss:0.04457714510934574\n",
      "train loss:0.011410143094580622\n",
      "train loss:0.05612625300183001\n",
      "train loss:0.028877367614719835\n",
      "train loss:0.07677168803340861\n",
      "train loss:0.05521495382860141\n",
      "train loss:0.04282556793203071\n",
      "train loss:0.047957499920411276\n",
      "train loss:0.03412312930410035\n",
      "train loss:0.052816481680336674\n",
      "train loss:0.05003704496317157\n",
      "train loss:0.023749397105562845\n",
      "train loss:0.03678457507735994\n",
      "train loss:0.03454399855784741\n",
      "train loss:0.061158629436999935\n",
      "train loss:0.03606371822784131\n",
      "train loss:0.04765814679752253\n",
      "train loss:0.05325901351738487\n",
      "train loss:0.1683765430206185\n",
      "train loss:0.029789729274926447\n",
      "train loss:0.08093485304945133\n",
      "train loss:0.053184336676514975\n",
      "train loss:0.03701267282272932\n",
      "train loss:0.07353993086321681\n",
      "train loss:0.04649618839437651\n",
      "train loss:0.03554638919407309\n",
      "train loss:0.13120735081119128\n",
      "train loss:0.028142182399324964\n",
      "train loss:0.01807141770148928\n",
      "train loss:0.05468233989727254\n",
      "train loss:0.017195542367067537\n",
      "train loss:0.07367430296411209\n",
      "train loss:0.01901601451896608\n",
      "train loss:0.04804539504228482\n",
      "train loss:0.1138462137766087\n",
      "train loss:0.0692613889069448\n",
      "train loss:0.08079389125120474\n",
      "train loss:0.031886542368042614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06508639219517603\n",
      "train loss:0.07919403587386323\n",
      "train loss:0.02588616569025678\n",
      "train loss:0.058778164145370564\n",
      "train loss:0.060300054511214576\n",
      "train loss:0.05393048607534534\n",
      "train loss:0.031386443098867234\n",
      "train loss:0.0836710510682813\n",
      "train loss:0.05504555947811615\n",
      "train loss:0.08278248561653394\n",
      "train loss:0.05605778806758651\n",
      "train loss:0.0718767713034025\n",
      "train loss:0.021632740235454473\n",
      "train loss:0.06769212581547819\n",
      "train loss:0.10532271210200445\n",
      "train loss:0.037933598504775706\n",
      "train loss:0.05916216036335653\n",
      "train loss:0.052962650783159884\n",
      "train loss:0.04352187041151849\n",
      "train loss:0.028405439925074404\n",
      "train loss:0.0472568052876661\n",
      "train loss:0.09079478739274689\n",
      "train loss:0.04723662250029908\n",
      "train loss:0.14966202847691978\n",
      "train loss:0.058961501201722194\n",
      "train loss:0.0680383589425446\n",
      "train loss:0.05228139577727484\n",
      "train loss:0.03222932057237257\n",
      "train loss:0.03850298542081608\n",
      "train loss:0.056145043576447826\n",
      "train loss:0.042628805041943316\n",
      "train loss:0.041128840904412926\n",
      "train loss:0.10674815896411946\n",
      "train loss:0.026093569809870723\n",
      "train loss:0.028096121842736573\n",
      "train loss:0.04694200722974049\n",
      "train loss:0.05918976667903017\n",
      "train loss:0.05788314639746137\n",
      "train loss:0.017475983143345145\n",
      "train loss:0.053253688660898205\n",
      "train loss:0.024907118722323908\n",
      "train loss:0.05329746772863771\n",
      "train loss:0.04701207024293358\n",
      "train loss:0.058247901100287075\n",
      "train loss:0.054320672960984924\n",
      "train loss:0.07145394861713988\n",
      "train loss:0.0963423429828972\n",
      "train loss:0.08642564662783975\n",
      "train loss:0.048463334678553106\n",
      "train loss:0.015675510053163224\n",
      "train loss:0.07353581092908335\n",
      "train loss:0.025029407616485987\n",
      "train loss:0.03978773349546507\n",
      "train loss:0.045499613499708\n",
      "train loss:0.06295257840863204\n",
      "train loss:0.0513960015461532\n",
      "train loss:0.015554504520242415\n",
      "train loss:0.11620738554445188\n",
      "train loss:0.020768877220888885\n",
      "train loss:0.02723836309134855\n",
      "train loss:0.0994032423492761\n",
      "train loss:0.04962849049001579\n",
      "train loss:0.021847852860064174\n",
      "train loss:0.015250133087588016\n",
      "train loss:0.039398817770260094\n",
      "train loss:0.04338524346814674\n",
      "train loss:0.05483653057153547\n",
      "train loss:0.02766956718392172\n",
      "train loss:0.09394680259836428\n",
      "train loss:0.08347942538941976\n",
      "train loss:0.05441371163263971\n",
      "train loss:0.10607419148061624\n",
      "train loss:0.022135226583553186\n",
      "train loss:0.05533637743290378\n",
      "train loss:0.08553537330201198\n",
      "train loss:0.040855922414649394\n",
      "train loss:0.07975790792857153\n",
      "train loss:0.06248474278252912\n",
      "train loss:0.05717342631558184\n",
      "train loss:0.029951748716594683\n",
      "train loss:0.06731923212602754\n",
      "train loss:0.020550844179551955\n",
      "train loss:0.044823738761691566\n",
      "train loss:0.02559865768086616\n",
      "train loss:0.07776244978162229\n",
      "train loss:0.06333170555854979\n",
      "train loss:0.07826872536394103\n",
      "train loss:0.10999744717486974\n",
      "train loss:0.04569192976704433\n",
      "train loss:0.07065456040453254\n",
      "train loss:0.058059308764236255\n",
      "train loss:0.02156995700560467\n",
      "train loss:0.11720858274913731\n",
      "train loss:0.04303524881018608\n",
      "train loss:0.10721592646321736\n",
      "train loss:0.02819835820679701\n",
      "train loss:0.054046656831564725\n",
      "train loss:0.05007631554205865\n",
      "train loss:0.02961997046921267\n",
      "train loss:0.055747313697977516\n",
      "train loss:0.05497998058090354\n",
      "train loss:0.03848864738065831\n",
      "train loss:0.06584983417916496\n",
      "train loss:0.12072077481950474\n",
      "train loss:0.07083287907236785\n",
      "train loss:0.06455595927138083\n",
      "train loss:0.09888477180248438\n",
      "train loss:0.08256763944882449\n",
      "train loss:0.04569215286806497\n",
      "train loss:0.05341392595230898\n",
      "train loss:0.06281000246846478\n",
      "train loss:0.025785463983002837\n",
      "train loss:0.030624926716888136\n",
      "train loss:0.051673063619858614\n",
      "train loss:0.09367979369466535\n",
      "train loss:0.16827087873099253\n",
      "train loss:0.04626224205936867\n",
      "train loss:0.021308987748091698\n",
      "train loss:0.0399647458705338\n",
      "train loss:0.05311671227506683\n",
      "train loss:0.03480719201256785\n",
      "train loss:0.08235574161119003\n",
      "train loss:0.03831164543065292\n",
      "train loss:0.0376640458572022\n",
      "train loss:0.022397410099627008\n",
      "train loss:0.0721878569305869\n",
      "train loss:0.02622257879462021\n",
      "train loss:0.03737826777056154\n",
      "train loss:0.11069575056030746\n",
      "train loss:0.05649878687417296\n",
      "train loss:0.03526310757176166\n",
      "train loss:0.0461099912788012\n",
      "train loss:0.04160587777074722\n",
      "train loss:0.041204120580754386\n",
      "train loss:0.1597224758978546\n",
      "train loss:0.03701494097346351\n",
      "train loss:0.09727691415432198\n",
      "train loss:0.06262690457025405\n",
      "train loss:0.12998783369358624\n",
      "train loss:0.019871243450920523\n",
      "train loss:0.07367130280556838\n",
      "train loss:0.053244913401784284\n",
      "train loss:0.013549902846988099\n",
      "train loss:0.07267998073717132\n",
      "train loss:0.08924981894982956\n",
      "train loss:0.02091598356516351\n",
      "train loss:0.031193782694265336\n",
      "train loss:0.018215080179393255\n",
      "train loss:0.09047200040429529\n",
      "train loss:0.02920249010175726\n",
      "train loss:0.03473233337438809\n",
      "train loss:0.04307656185520858\n",
      "train loss:0.07784294906885507\n",
      "train loss:0.06081175119154305\n",
      "train loss:0.01292931428596663\n",
      "train loss:0.07728120680616714\n",
      "train loss:0.12279788565109831\n",
      "train loss:0.04737548741587328\n",
      "train loss:0.05347528781471279\n",
      "train loss:0.030602176775588852\n",
      "train loss:0.015524115502990115\n",
      "train loss:0.08576317394446585\n",
      "train loss:0.06255211794451272\n",
      "train loss:0.09244440444328582\n",
      "train loss:0.06727968241267987\n",
      "train loss:0.06663974812778747\n",
      "train loss:0.04119272457263581\n",
      "train loss:0.03236896358651672\n",
      "train loss:0.06226104800001471\n",
      "train loss:0.019881168365192704\n",
      "train loss:0.08691118236085364\n",
      "train loss:0.03488432256070174\n",
      "train loss:0.026585533103434457\n",
      "train loss:0.013473244282103676\n",
      "train loss:0.10323600899353443\n",
      "train loss:0.038124986981652315\n",
      "train loss:0.08240824230111723\n",
      "train loss:0.03931937230777069\n",
      "train loss:0.031852279692616586\n",
      "train loss:0.07195371001260013\n",
      "train loss:0.11594055688158006\n",
      "train loss:0.011951212249090001\n",
      "train loss:0.03362228172220388\n",
      "train loss:0.01291160556960893\n",
      "train loss:0.030158904386112625\n",
      "train loss:0.057309829012511554\n",
      "train loss:0.07304879285982976\n",
      "train loss:0.030999495397333234\n",
      "train loss:0.020347961781020975\n",
      "train loss:0.10136969415944411\n",
      "train loss:0.052067447318015575\n",
      "train loss:0.07545451707659745\n",
      "train loss:0.09904606293588325\n",
      "train loss:0.07281958497950372\n",
      "train loss:0.029471554227468288\n",
      "train loss:0.05339293801732341\n",
      "train loss:0.020796339525767992\n",
      "train loss:0.014434777312485558\n",
      "train loss:0.0473013186508079\n",
      "train loss:0.03201510569496056\n",
      "train loss:0.035883351743579366\n",
      "train loss:0.05274093361898086\n",
      "train loss:0.0763868298532343\n",
      "train loss:0.03854541864710009\n",
      "train loss:0.0416104743128545\n",
      "train loss:0.09746845233213905\n",
      "train loss:0.01854309373432337\n",
      "train loss:0.07946953496283783\n",
      "train loss:0.019619894578191296\n",
      "train loss:0.08076436650475458\n",
      "train loss:0.08713216703652671\n",
      "train loss:0.03708427224142046\n",
      "train loss:0.04275272720570742\n",
      "train loss:0.021515092772986622\n",
      "train loss:0.09068677426217352\n",
      "train loss:0.08019622568687648\n",
      "train loss:0.04882305468223282\n",
      "train loss:0.04604225943859982\n",
      "train loss:0.05577689549767994\n",
      "train loss:0.0564649828019069\n",
      "train loss:0.053592400156960866\n",
      "train loss:0.06642669067131923\n",
      "train loss:0.05832490208551878\n",
      "train loss:0.09808670073368608\n",
      "train loss:0.01893909382376401\n",
      "train loss:0.03969920826955958\n",
      "train loss:0.02412872718446473\n",
      "train loss:0.07396475144896894\n",
      "train loss:0.05445719886759255\n",
      "train loss:0.016709027063906767\n",
      "train loss:0.08010960030043508\n",
      "train loss:0.020429527174762388\n",
      "train loss:0.02044843994398712\n",
      "train loss:0.039776628832966426\n",
      "train loss:0.054720653331885034\n",
      "train loss:0.05939220839207032\n",
      "train loss:0.010268485569229904\n",
      "train loss:0.03514433721707085\n",
      "train loss:0.08972056200387225\n",
      "train loss:0.10979376943334243\n",
      "train loss:0.02028936134237505\n",
      "train loss:0.04093486584628935\n",
      "train loss:0.07299984236215935\n",
      "train loss:0.04283622283484581\n",
      "train loss:0.019700145469798983\n",
      "train loss:0.021338508224297018\n",
      "train loss:0.049854388727175694\n",
      "train loss:0.00903821899687586\n",
      "train loss:0.014652232422487168\n",
      "train loss:0.033182328592904\n",
      "train loss:0.05592056960804701\n",
      "train loss:0.032557227035097204\n",
      "train loss:0.027559489827428698\n",
      "train loss:0.1268044606146285\n",
      "train loss:0.016861545279815343\n",
      "train loss:0.07375583789997389\n",
      "train loss:0.017517661744993224\n",
      "train loss:0.059926372375760394\n",
      "train loss:0.07431455358849724\n",
      "train loss:0.037958268895539674\n",
      "train loss:0.031661426559751085\n",
      "train loss:0.10456236321944107\n",
      "train loss:0.026770192350240172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026661292072880483\n",
      "train loss:0.0431230948516732\n",
      "train loss:0.10146335520719235\n",
      "train loss:0.01914619593487887\n",
      "train loss:0.033565448158405016\n",
      "train loss:0.053791513517485026\n",
      "train loss:0.02681090986252957\n",
      "train loss:0.03272722249710243\n",
      "train loss:0.030256108943965777\n",
      "train loss:0.017328836768882184\n",
      "train loss:0.03942405068250347\n",
      "train loss:0.027913091960102106\n",
      "train loss:0.08391875357082741\n",
      "train loss:0.029116420292089114\n",
      "train loss:0.0377364338181912\n",
      "train loss:0.09745083701193223\n",
      "train loss:0.04474539890634639\n",
      "train loss:0.02017683825441163\n",
      "train loss:0.019354436474458635\n",
      "train loss:0.024259419800046585\n",
      "train loss:0.011788408448999395\n",
      "train loss:0.09951995106882007\n",
      "train loss:0.08255131156832082\n",
      "train loss:0.01844488250522545\n",
      "train loss:0.01868928764054318\n",
      "train loss:0.1398080989700384\n",
      "train loss:0.04666820519894586\n",
      "train loss:0.12016749175877972\n",
      "train loss:0.028152622207091676\n",
      "train loss:0.03889646476890815\n",
      "train loss:0.07090969482118\n",
      "train loss:0.029177662301681097\n",
      "train loss:0.026244302845448722\n",
      "train loss:0.04588720669345701\n",
      "train loss:0.03271187474804904\n",
      "train loss:0.019383354354190325\n",
      "train loss:0.024833924292779905\n",
      "train loss:0.016234761907921464\n",
      "train loss:0.06549322280708415\n",
      "train loss:0.029062515606704066\n",
      "train loss:0.0157329606038099\n",
      "train loss:0.03054143756952029\n",
      "train loss:0.13741302239897105\n",
      "train loss:0.04863588800165984\n",
      "train loss:0.10113247831773033\n",
      "train loss:0.03436419101234247\n",
      "train loss:0.07292826149891792\n",
      "train loss:0.01622017432238029\n",
      "train loss:0.04567492513780356\n",
      "train loss:0.08187323753308752\n",
      "train loss:0.03997859834952983\n",
      "train loss:0.03577727781700558\n",
      "train loss:0.06404643027447919\n",
      "train loss:0.026722935284251334\n",
      "train loss:0.04092574496999947\n",
      "train loss:0.055918385309250994\n",
      "train loss:0.015849571714831576\n",
      "train loss:0.021397984549269583\n",
      "train loss:0.05514532069060814\n",
      "train loss:0.01682103131570357\n",
      "train loss:0.07116104702243732\n",
      "train loss:0.042085628078276954\n",
      "train loss:0.010826504841975382\n",
      "train loss:0.02409223254127835\n",
      "train loss:0.07995909715520907\n",
      "train loss:0.010380713706155087\n",
      "train loss:0.021772648993510998\n",
      "train loss:0.02564229275106389\n",
      "train loss:0.010593010040519641\n",
      "train loss:0.025865352165005396\n",
      "train loss:0.0739978411626672\n",
      "train loss:0.03731006542061118\n",
      "train loss:0.05147108195838778\n",
      "train loss:0.027625785539845023\n",
      "train loss:0.029455610843969877\n",
      "train loss:0.014871463340995763\n",
      "train loss:0.05565210210502865\n",
      "train loss:0.0276311666224271\n",
      "train loss:0.12125477420134649\n",
      "train loss:0.03333906157213956\n",
      "train loss:0.09216574767140046\n",
      "train loss:0.17398423489872955\n",
      "train loss:0.05625146364290906\n",
      "train loss:0.04673050151866266\n",
      "train loss:0.00971542235430815\n",
      "train loss:0.04131062746350207\n",
      "train loss:0.025294799512528374\n",
      "train loss:0.053825262185425736\n",
      "train loss:0.07716674026834201\n",
      "train loss:0.0900288166164366\n",
      "train loss:0.03011304866023593\n",
      "train loss:0.032165119425992934\n",
      "train loss:0.023883968652049687\n",
      "train loss:0.0450613349967873\n",
      "train loss:0.02723359093632455\n",
      "train loss:0.017599996313632293\n",
      "train loss:0.12095932825398509\n",
      "train loss:0.044305080760960264\n",
      "train loss:0.011312745222010628\n",
      "train loss:0.16020941612334305\n",
      "train loss:0.07752128288709559\n",
      "train loss:0.010782113590965314\n",
      "train loss:0.02308363855250151\n",
      "train loss:0.09692657262796882\n",
      "train loss:0.04742541906302379\n",
      "train loss:0.048411123433180145\n",
      "train loss:0.023407696094419533\n",
      "train loss:0.03491906901257166\n",
      "train loss:0.02524159996624015\n",
      "train loss:0.03354471567179744\n",
      "train loss:0.06207204887410981\n",
      "train loss:0.1741129984838729\n",
      "train loss:0.028035730990625105\n",
      "train loss:0.02440110250993284\n",
      "train loss:0.01766626632359955\n",
      "train loss:0.015637604112463795\n",
      "train loss:0.024553357504879365\n",
      "train loss:0.013925071067331858\n",
      "train loss:0.07193036769603255\n",
      "train loss:0.05446834285474171\n",
      "train loss:0.06940305256899436\n",
      "train loss:0.039385246571896605\n",
      "train loss:0.04477873609678612\n",
      "train loss:0.02273132589243165\n",
      "train loss:0.021865660716647407\n",
      "train loss:0.04632866031393488\n",
      "train loss:0.03120629403379359\n",
      "train loss:0.017499537802403705\n",
      "train loss:0.06904607773816625\n",
      "train loss:0.009733399760689716\n",
      "train loss:0.16959916197690333\n",
      "train loss:0.04368317529327658\n",
      "train loss:0.013815389452164022\n",
      "train loss:0.040823922902800215\n",
      "train loss:0.0194757003953212\n",
      "train loss:0.08409032070346852\n",
      "train loss:0.025527434519804645\n",
      "train loss:0.034843707708101586\n",
      "train loss:0.07912713651176546\n",
      "train loss:0.051651052893342805\n",
      "train loss:0.03478807107105049\n",
      "train loss:0.1343909398536629\n",
      "train loss:0.019811672845010505\n",
      "train loss:0.015012406218135068\n",
      "train loss:0.006105726263588617\n",
      "train loss:0.023197943567530913\n",
      "train loss:0.02623184418242421\n",
      "train loss:0.042837336240725464\n",
      "train loss:0.01322259955760291\n",
      "train loss:0.025257560161314748\n",
      "train loss:0.024920830897796297\n",
      "train loss:0.015928524822891584\n",
      "train loss:0.02938599533979378\n",
      "train loss:0.010863878425596211\n",
      "train loss:0.010853954614401352\n",
      "train loss:0.03672422955986599\n",
      "train loss:0.02268868405958819\n",
      "train loss:0.05236286888872495\n",
      "train loss:0.02007542030637648\n",
      "train loss:0.0730653119733338\n",
      "train loss:0.04449788238533872\n",
      "train loss:0.06268222060611367\n",
      "train loss:0.06668246932959546\n",
      "train loss:0.014629286317760448\n",
      "train loss:0.020318321532875046\n",
      "train loss:0.021799993377248\n",
      "train loss:0.017438830891695515\n",
      "train loss:0.007142282501870616\n",
      "train loss:0.0473333824422206\n",
      "train loss:0.061920809136665936\n",
      "train loss:0.022589750304228717\n",
      "train loss:0.17508121219312892\n",
      "train loss:0.07127490506963151\n",
      "train loss:0.036048891269109345\n",
      "train loss:0.05060160466642742\n",
      "train loss:0.02408549643067627\n",
      "train loss:0.03388284114657818\n",
      "train loss:0.04399359945095108\n",
      "train loss:0.01058384196267563\n",
      "train loss:0.02758064705100586\n",
      "train loss:0.025090031778307133\n",
      "train loss:0.03682387439711976\n",
      "train loss:0.04172181892566784\n",
      "train loss:0.005945615898552907\n",
      "train loss:0.022005026990943158\n",
      "train loss:0.03202145648681129\n",
      "train loss:0.08490190148138385\n",
      "train loss:0.027431148699746496\n",
      "train loss:0.02167426547182839\n",
      "train loss:0.028702301340139787\n",
      "train loss:0.031057095510834003\n",
      "train loss:0.008897578427064144\n",
      "train loss:0.05416755339672667\n",
      "train loss:0.01617949479936025\n",
      "train loss:0.048343064000122025\n",
      "train loss:0.03596738759022957\n",
      "train loss:0.04082397616980897\n",
      "train loss:0.05138991077972862\n",
      "train loss:0.031572517763523995\n",
      "train loss:0.010294386684837979\n",
      "train loss:0.022335582198965795\n",
      "train loss:0.040131952002365745\n",
      "train loss:0.010217851077442696\n",
      "train loss:0.027641242574190275\n",
      "train loss:0.06567425314634233\n",
      "train loss:0.01252076776290966\n",
      "train loss:0.0288355881302716\n",
      "train loss:0.09133420092324393\n",
      "train loss:0.021895197980491797\n",
      "train loss:0.02144071771746796\n",
      "=== epoch:4, train acc:0.984, test acc:0.984 ===\n",
      "train loss:0.07918300837561493\n",
      "train loss:0.021609359867168446\n",
      "train loss:0.026417656585585543\n",
      "train loss:0.0630600828365666\n",
      "train loss:0.033317813404608924\n",
      "train loss:0.037248833700835385\n",
      "train loss:0.04077608416646416\n",
      "train loss:0.08155083399153007\n",
      "train loss:0.0312381810816025\n",
      "train loss:0.00885732781726986\n",
      "train loss:0.016601242133274914\n",
      "train loss:0.02154566276214378\n",
      "train loss:0.023601476192021208\n",
      "train loss:0.0549170117910299\n",
      "train loss:0.08794957107018328\n",
      "train loss:0.021878687805192847\n",
      "train loss:0.03682148268791185\n",
      "train loss:0.04412332281340332\n",
      "train loss:0.015725878361229625\n",
      "train loss:0.01505720071974551\n",
      "train loss:0.008303194488078982\n",
      "train loss:0.05939155979490928\n",
      "train loss:0.026013026200827585\n",
      "train loss:0.03327334725856928\n",
      "train loss:0.08952875023509957\n",
      "train loss:0.014227876244743648\n",
      "train loss:0.024558227422971847\n",
      "train loss:0.03768403855606818\n",
      "train loss:0.016582218908082064\n",
      "train loss:0.033663175996729085\n",
      "train loss:0.033417106800684764\n",
      "train loss:0.12420947105473124\n",
      "train loss:0.11707098807701635\n",
      "train loss:0.010844161804550253\n",
      "train loss:0.035450193195082386\n",
      "train loss:0.04259230882781246\n",
      "train loss:0.09283793599144609\n",
      "train loss:0.015431889408763949\n",
      "train loss:0.020843555122077584\n",
      "train loss:0.025118727417704153\n",
      "train loss:0.02422575472755375\n",
      "train loss:0.021088917396845618\n",
      "train loss:0.024655821562733587\n",
      "train loss:0.06407029654326662\n",
      "train loss:0.009108014886657743\n",
      "train loss:0.04179672590949753\n",
      "train loss:0.013978239646968758\n",
      "train loss:0.02907387999085735\n",
      "train loss:0.038136012264767115\n",
      "train loss:0.06566181930526355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03246090313737072\n",
      "train loss:0.046256031797942396\n",
      "train loss:0.05652373586816428\n",
      "train loss:0.02735497694428842\n",
      "train loss:0.06712151122914398\n",
      "train loss:0.08842444514190173\n",
      "train loss:0.07781941678087095\n",
      "train loss:0.03384448533604918\n",
      "train loss:0.012914905040052544\n",
      "train loss:0.037992022338104746\n",
      "train loss:0.054690635298618194\n",
      "train loss:0.054763425844694326\n",
      "train loss:0.019695083785336208\n",
      "train loss:0.03504654117006525\n",
      "train loss:0.032664679924555726\n",
      "train loss:0.047104025562192724\n",
      "train loss:0.035693961227573144\n",
      "train loss:0.03113482591728748\n",
      "train loss:0.012165443223962014\n",
      "train loss:0.01966622423303695\n",
      "train loss:0.04816082412762318\n",
      "train loss:0.015220993114274646\n",
      "train loss:0.06295072665058939\n",
      "train loss:0.019325141459840597\n",
      "train loss:0.028106190626516963\n",
      "train loss:0.05817864604504983\n",
      "train loss:0.02504373798485724\n",
      "train loss:0.059598091695881636\n",
      "train loss:0.04335209327122137\n",
      "train loss:0.05453577466798122\n",
      "train loss:0.029311308150739693\n",
      "train loss:0.05100738466269487\n",
      "train loss:0.005152406589494527\n",
      "train loss:0.046650747270207696\n",
      "train loss:0.011426891398004424\n",
      "train loss:0.02431929327232853\n",
      "train loss:0.006359133772629381\n",
      "train loss:0.08472064480781659\n",
      "train loss:0.02337865797459777\n",
      "train loss:0.027612436369540937\n",
      "train loss:0.00726097691965194\n",
      "train loss:0.05616229555403323\n",
      "train loss:0.02205861481357461\n",
      "train loss:0.168765294414421\n",
      "train loss:0.02560596338752021\n",
      "train loss:0.03718981933508608\n",
      "train loss:0.010541824650467116\n",
      "train loss:0.007331007962071765\n",
      "train loss:0.04965932054884619\n",
      "train loss:0.03518878977758722\n",
      "train loss:0.018093903993384154\n",
      "train loss:0.024486966253906624\n",
      "train loss:0.027903915553240802\n",
      "train loss:0.021111301273323106\n",
      "train loss:0.0351141079921461\n",
      "train loss:0.11026029571178779\n",
      "train loss:0.05591385212186852\n",
      "train loss:0.02576257991182248\n",
      "train loss:0.05408836947499939\n",
      "train loss:0.020483425892462482\n",
      "train loss:0.04804904564690693\n",
      "train loss:0.014229402390761696\n",
      "train loss:0.07544299640956138\n",
      "train loss:0.0557197395955272\n",
      "train loss:0.017844434175662702\n",
      "train loss:0.042431910124470035\n",
      "train loss:0.03443478605361003\n",
      "train loss:0.08468218720752381\n",
      "train loss:0.04368202307934971\n",
      "train loss:0.0624743388279738\n",
      "train loss:0.04571251585911969\n",
      "train loss:0.06160584710764004\n",
      "train loss:0.10259744176384242\n",
      "train loss:0.05985767593350953\n",
      "train loss:0.06437848806273136\n",
      "train loss:0.006756431366061023\n",
      "train loss:0.10131530114975398\n",
      "train loss:0.04097600106923663\n",
      "train loss:0.050540687514640296\n",
      "train loss:0.0395883541390199\n",
      "train loss:0.09013698952987083\n",
      "train loss:0.009059961757633496\n",
      "train loss:0.014975670302708778\n",
      "train loss:0.018172262328066725\n",
      "train loss:0.03120457538733258\n",
      "train loss:0.01062767004384549\n",
      "train loss:0.025912432446231738\n",
      "train loss:0.010374297323850486\n",
      "train loss:0.0319158028998342\n",
      "train loss:0.08437959051621315\n",
      "train loss:0.03635818953881716\n",
      "train loss:0.0603425468019794\n",
      "train loss:0.06177220358606579\n",
      "train loss:0.06327524098013897\n",
      "train loss:0.04131052767639962\n",
      "train loss:0.03429144104188581\n",
      "train loss:0.020388528883570203\n",
      "train loss:0.04872473914504607\n",
      "train loss:0.0326835747555763\n",
      "train loss:0.07117824326155522\n",
      "train loss:0.023467652737034814\n",
      "train loss:0.038404954397186074\n",
      "train loss:0.00912603667804637\n",
      "train loss:0.01567159840684374\n",
      "train loss:0.021228586131521412\n",
      "train loss:0.015725432678785792\n",
      "train loss:0.09813653800130712\n",
      "train loss:0.050317900628105476\n",
      "train loss:0.04245677220387388\n",
      "train loss:0.02607706744022442\n",
      "train loss:0.053280338548639394\n",
      "train loss:0.04113829308636066\n",
      "train loss:0.012489395783251967\n",
      "train loss:0.06923296134397815\n",
      "train loss:0.028353485950811705\n",
      "train loss:0.037984253725628574\n",
      "train loss:0.13706215929824292\n",
      "train loss:0.014851347814203919\n",
      "train loss:0.04028914124530401\n",
      "train loss:0.02068489348059724\n",
      "train loss:0.024045780946970775\n",
      "train loss:0.09061250557393567\n",
      "train loss:0.03833498878221139\n",
      "train loss:0.023613675533278373\n",
      "train loss:0.07744713482999731\n",
      "train loss:0.007237271223793164\n",
      "train loss:0.02022508367576554\n",
      "train loss:0.02113796000974034\n",
      "train loss:0.05333504362170017\n",
      "train loss:0.023205791554946825\n",
      "train loss:0.05022260964808959\n",
      "train loss:0.025098179824940274\n",
      "train loss:0.03141449095837453\n",
      "train loss:0.07795132918596302\n",
      "train loss:0.022108967958296956\n",
      "train loss:0.03517296461157126\n",
      "train loss:0.023978800946117297\n",
      "train loss:0.010006390889719344\n",
      "train loss:0.08558949765800536\n",
      "train loss:0.02773469685677423\n",
      "train loss:0.01887159631085609\n",
      "train loss:0.06367442796428731\n",
      "train loss:0.01678087524542637\n",
      "train loss:0.05489764971319458\n",
      "train loss:0.020816063753682154\n",
      "train loss:0.06345267733397228\n",
      "train loss:0.009850129186842384\n",
      "train loss:0.03658753740128866\n",
      "train loss:0.006327032971472769\n",
      "train loss:0.00912408308259371\n",
      "train loss:0.112232592854195\n",
      "train loss:0.02291898217005747\n",
      "train loss:0.007856354306269497\n",
      "train loss:0.014395445311414862\n",
      "train loss:0.024606117485324888\n",
      "train loss:0.021650289437513237\n",
      "train loss:0.05956230234022154\n",
      "train loss:0.024994290855125775\n",
      "train loss:0.019180063841268163\n",
      "train loss:0.10986568735998896\n",
      "train loss:0.03136063911495932\n",
      "train loss:0.04845213733951455\n",
      "train loss:0.037423223748205385\n",
      "train loss:0.016090634027263653\n",
      "train loss:0.029667069679743575\n",
      "train loss:0.03333110703226804\n",
      "train loss:0.02881247459216399\n",
      "train loss:0.042628498562894704\n",
      "train loss:0.05194622776150189\n",
      "train loss:0.026473399016910107\n",
      "train loss:0.04012627617409196\n",
      "train loss:0.016620902678164337\n",
      "train loss:0.00648983179413759\n",
      "train loss:0.09316461712358615\n",
      "train loss:0.015416042874185609\n",
      "train loss:0.05160630964010696\n",
      "train loss:0.026346465373933304\n",
      "train loss:0.03770982599200869\n",
      "train loss:0.026792607567518202\n",
      "train loss:0.017937419863930194\n",
      "train loss:0.05936552529424076\n",
      "train loss:0.021069022841043464\n",
      "train loss:0.028891450274166407\n",
      "train loss:0.05416219829143542\n",
      "train loss:0.04187498461474524\n",
      "train loss:0.02281616651809015\n",
      "train loss:0.009896979939849733\n",
      "train loss:0.04739538132051555\n",
      "train loss:0.05046994781822194\n",
      "train loss:0.038319847950882065\n",
      "train loss:0.034251769327965705\n",
      "train loss:0.0411699360167803\n",
      "train loss:0.058425020030162145\n",
      "train loss:0.011078242549342197\n",
      "train loss:0.028242800360457086\n",
      "train loss:0.028121988908727927\n",
      "train loss:0.052875764121418305\n",
      "train loss:0.053239658853150205\n",
      "train loss:0.05304920919004072\n",
      "train loss:0.050170326913688966\n",
      "train loss:0.0904308920661319\n",
      "train loss:0.014382298759991752\n",
      "train loss:0.029945028339112813\n",
      "train loss:0.05612853275052282\n",
      "train loss:0.03871010480169783\n",
      "train loss:0.011216770578241154\n",
      "train loss:0.03398480015104971\n",
      "train loss:0.028383465330960665\n",
      "train loss:0.10231160645175667\n",
      "train loss:0.060878837701006286\n",
      "train loss:0.05542150345985127\n",
      "train loss:0.05816738710432971\n",
      "train loss:0.031826361502957534\n",
      "train loss:0.02244408819924751\n",
      "train loss:0.05145853953186521\n",
      "train loss:0.05769907511466709\n",
      "train loss:0.008527246376430285\n",
      "train loss:0.04358901766179542\n",
      "train loss:0.03544173770604074\n",
      "train loss:0.02150225484434852\n",
      "train loss:0.02231663622964518\n",
      "train loss:0.007900770637239466\n",
      "train loss:0.016596168213818076\n",
      "train loss:0.04033215070583579\n",
      "train loss:0.04188152109687463\n",
      "train loss:0.01732875784763395\n",
      "train loss:0.01937645118638742\n",
      "train loss:0.01659686626787921\n",
      "train loss:0.03238169726577009\n",
      "train loss:0.018172913891606884\n",
      "train loss:0.024431853835146403\n",
      "train loss:0.01412983047879214\n",
      "train loss:0.005894931344279336\n",
      "train loss:0.03974242872216778\n",
      "train loss:0.07443853823043634\n",
      "train loss:0.017693552890528964\n",
      "train loss:0.011523111267992232\n",
      "train loss:0.06097475726195509\n",
      "train loss:0.02252467836482897\n",
      "train loss:0.02284500547173851\n",
      "train loss:0.0898608349321173\n",
      "train loss:0.01606382983457315\n",
      "train loss:0.01308587641931983\n",
      "train loss:0.012614262146755097\n",
      "train loss:0.014648875269976193\n",
      "train loss:0.06809975909713833\n",
      "train loss:0.15413414080816923\n",
      "train loss:0.02115592681339735\n",
      "train loss:0.036940153912418824\n",
      "train loss:0.010949088439933594\n",
      "train loss:0.10219544764815333\n",
      "train loss:0.05003066952507499\n",
      "train loss:0.04227394689233525\n",
      "train loss:0.009624681831012396\n",
      "train loss:0.014322995161790747\n",
      "train loss:0.03358940322918949\n",
      "train loss:0.09214232882085122\n",
      "train loss:0.009022850316439533\n",
      "train loss:0.008132583101203857\n",
      "train loss:0.04071470334801122\n",
      "train loss:0.009597276421379445\n",
      "train loss:0.08404477236447433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07392158921701082\n",
      "train loss:0.011657069323917652\n",
      "train loss:0.012068423174065526\n",
      "train loss:0.02856551439516808\n",
      "train loss:0.013017735789467933\n",
      "train loss:0.04367490706405805\n",
      "train loss:0.02239797007842921\n",
      "train loss:0.07824229002958555\n",
      "train loss:0.025557198310201062\n",
      "train loss:0.012625639120576565\n",
      "train loss:0.02927786669411546\n",
      "train loss:0.06278640606287363\n",
      "train loss:0.04586645888853914\n",
      "train loss:0.03884576564588685\n",
      "train loss:0.01840833451944821\n",
      "train loss:0.03313732419155529\n",
      "train loss:0.05118744672783688\n",
      "train loss:0.0401140864960001\n",
      "train loss:0.05060700496889864\n",
      "train loss:0.011665129691948752\n",
      "train loss:0.010915361094070122\n",
      "train loss:0.016025992768270013\n",
      "train loss:0.12705164056439355\n",
      "train loss:0.00990286896531333\n",
      "train loss:0.02807918095286333\n",
      "train loss:0.027542985725320393\n",
      "train loss:0.06104572588557112\n",
      "train loss:0.05796045871755856\n",
      "train loss:0.040341681786966815\n",
      "train loss:0.005941692657494522\n",
      "train loss:0.03440873286031674\n",
      "train loss:0.0312963272897872\n",
      "train loss:0.07618499410049961\n",
      "train loss:0.03719741430539366\n",
      "train loss:0.11810554502563829\n",
      "train loss:0.04188956328484689\n",
      "train loss:0.14458691203659887\n",
      "train loss:0.08161462528510804\n",
      "train loss:0.03737803613116154\n",
      "train loss:0.03693667995055649\n",
      "train loss:0.13953184210380534\n",
      "train loss:0.046951766087569055\n",
      "train loss:0.028707934455512493\n",
      "train loss:0.03900825030510065\n",
      "train loss:0.025635468008352078\n",
      "train loss:0.03184476574041519\n",
      "train loss:0.0748504522044838\n",
      "train loss:0.06510717919114255\n",
      "train loss:0.0480194320005398\n",
      "train loss:0.011233542690355957\n",
      "train loss:0.06569477863774682\n",
      "train loss:0.009388392221821912\n",
      "train loss:0.05404995181653626\n",
      "train loss:0.052995333770761016\n",
      "train loss:0.048225325712421135\n",
      "train loss:0.021827959170091626\n",
      "train loss:0.06825808976663893\n",
      "train loss:0.01572470898563005\n",
      "train loss:0.0547957402391118\n",
      "train loss:0.040976787901130324\n",
      "train loss:0.11808464122571767\n",
      "train loss:0.025784772770865116\n",
      "train loss:0.022169017255071827\n",
      "train loss:0.09315400668485191\n",
      "train loss:0.0483442154247847\n",
      "train loss:0.01744460296715276\n",
      "train loss:0.051724957890306233\n",
      "train loss:0.017280225729048967\n",
      "train loss:0.01004768298277515\n",
      "train loss:0.02746989637052208\n",
      "train loss:0.022135887060244414\n",
      "train loss:0.08139779495726474\n",
      "train loss:0.017786335310648202\n",
      "train loss:0.024061198882755434\n",
      "train loss:0.04725371051540631\n",
      "train loss:0.057180262471675715\n",
      "train loss:0.04606516028942127\n",
      "train loss:0.05621106830312425\n",
      "train loss:0.0301401978828997\n",
      "train loss:0.018832792617579364\n",
      "train loss:0.007245120326374992\n",
      "train loss:0.04143109902645753\n",
      "train loss:0.02689162710962943\n",
      "train loss:0.05636460687445544\n",
      "train loss:0.03502161846726366\n",
      "train loss:0.016349703889303478\n",
      "train loss:0.039672581429866044\n",
      "train loss:0.022831443515909298\n",
      "train loss:0.02287245137560951\n",
      "train loss:0.056871137211224984\n",
      "train loss:0.02519109178873702\n",
      "train loss:0.020809498300937083\n",
      "train loss:0.020198501447578416\n",
      "train loss:0.10997112411853804\n",
      "train loss:0.012207756237998928\n",
      "train loss:0.028367093358520726\n",
      "train loss:0.008273237861630341\n",
      "train loss:0.012741491110387105\n",
      "train loss:0.019834289492710412\n",
      "train loss:0.046034836605208816\n",
      "train loss:0.08362950497862863\n",
      "train loss:0.034764019561070746\n",
      "train loss:0.015905392750103872\n",
      "train loss:0.022620908717028744\n",
      "train loss:0.061831024447816824\n",
      "train loss:0.012622253421393783\n",
      "train loss:0.020861019860195527\n",
      "train loss:0.014809242653219585\n",
      "train loss:0.018166154276423555\n",
      "train loss:0.017713924541901432\n",
      "train loss:0.011144855363816392\n",
      "train loss:0.029157801600130945\n",
      "train loss:0.03927987798585308\n",
      "train loss:0.019629258848948884\n",
      "train loss:0.015668191024445707\n",
      "train loss:0.04812101984155527\n",
      "train loss:0.04838756993686046\n",
      "train loss:0.020926716231712602\n",
      "train loss:0.022901446532717716\n",
      "train loss:0.09769515306184884\n",
      "train loss:0.033081104684417474\n",
      "train loss:0.003969885404333629\n",
      "train loss:0.05389977981053842\n",
      "train loss:0.007117920297059644\n",
      "train loss:0.042889296570080976\n",
      "train loss:0.010693938183238154\n",
      "train loss:0.046232201562500866\n",
      "train loss:0.02488035813794925\n",
      "train loss:0.06084355739072271\n",
      "train loss:0.03649427417682098\n",
      "train loss:0.008916606532707025\n",
      "train loss:0.0317764808030886\n",
      "train loss:0.05841132669189352\n",
      "train loss:0.023571697985358\n",
      "train loss:0.0216582407843066\n",
      "train loss:0.043050446111355424\n",
      "train loss:0.03426470219290141\n",
      "train loss:0.07828355545388044\n",
      "train loss:0.037835249578603035\n",
      "train loss:0.030910502151332852\n",
      "train loss:0.016500929185647294\n",
      "train loss:0.009716941048770023\n",
      "train loss:0.038125099488547004\n",
      "train loss:0.004456915986283301\n",
      "train loss:0.039035193831013906\n",
      "train loss:0.017377537836929545\n",
      "train loss:0.011002703553315864\n",
      "train loss:0.03382020932607179\n",
      "train loss:0.08741805477576324\n",
      "train loss:0.03747945453102434\n",
      "train loss:0.005659599393029708\n",
      "train loss:0.020469059207566222\n",
      "train loss:0.019307171838776317\n",
      "train loss:0.04626256121617942\n",
      "train loss:0.01906634700927831\n",
      "train loss:0.020278442464684285\n",
      "train loss:0.024688871182011084\n",
      "train loss:0.008079134188894211\n",
      "train loss:0.04746813788050768\n",
      "train loss:0.02017685896669809\n",
      "train loss:0.004200737482911391\n",
      "train loss:0.01926067446654738\n",
      "train loss:0.014146095909893502\n",
      "train loss:0.08186420682395128\n",
      "train loss:0.03286155625226938\n",
      "train loss:0.007079052591807749\n",
      "train loss:0.029089486730555194\n",
      "train loss:0.07876552289208175\n",
      "train loss:0.013440301431120572\n",
      "train loss:0.06958816090291524\n",
      "train loss:0.027527978870678812\n",
      "train loss:0.037921905418383015\n",
      "train loss:0.017503909220175213\n",
      "train loss:0.044582601334304715\n",
      "train loss:0.11562049622973335\n",
      "train loss:0.03030803048334756\n",
      "train loss:0.021343326032774515\n",
      "train loss:0.037756375449533586\n",
      "train loss:0.015791410392242473\n",
      "train loss:0.018432265735531365\n",
      "train loss:0.016627989384193517\n",
      "train loss:0.06007103119001777\n",
      "train loss:0.03767288380825269\n",
      "train loss:0.038249515215030214\n",
      "train loss:0.08092909165341836\n",
      "train loss:0.028033107323984924\n",
      "train loss:0.09336060941918571\n",
      "train loss:0.04605546638592392\n",
      "train loss:0.12085233809334428\n",
      "train loss:0.017326479931455276\n",
      "train loss:0.0574700709638139\n",
      "train loss:0.012471389956567549\n",
      "train loss:0.025080582038949056\n",
      "train loss:0.0330517003930413\n",
      "train loss:0.013273851040743656\n",
      "train loss:0.01950785973173264\n",
      "train loss:0.02813595337995637\n",
      "train loss:0.0406824249776066\n",
      "train loss:0.022019578744262504\n",
      "train loss:0.01569334722956974\n",
      "train loss:0.019591565796615935\n",
      "train loss:0.03329541520309498\n",
      "train loss:0.016017290505688262\n",
      "train loss:0.008428922034172533\n",
      "train loss:0.051923816505493825\n",
      "train loss:0.027033611338435817\n",
      "train loss:0.03695888951567067\n",
      "train loss:0.09084771443339953\n",
      "train loss:0.013911408073794452\n",
      "train loss:0.012761895523252331\n",
      "train loss:0.047104658817283394\n",
      "train loss:0.03132685611609269\n",
      "train loss:0.05903375553275752\n",
      "train loss:0.04671555036129597\n",
      "train loss:0.07999876623983743\n",
      "train loss:0.0787776696015375\n",
      "train loss:0.0289400943183096\n",
      "train loss:0.017791168112780614\n",
      "train loss:0.04929506762749148\n",
      "train loss:0.02064005093905911\n",
      "train loss:0.020342392922785238\n",
      "train loss:0.01300737061408943\n",
      "train loss:0.0516643808183165\n",
      "train loss:0.04608476349621487\n",
      "train loss:0.058713810072413324\n",
      "train loss:0.019280088252721584\n",
      "train loss:0.034362649304121515\n",
      "train loss:0.005463657868508279\n",
      "train loss:0.04606644864874054\n",
      "train loss:0.03048307211834953\n",
      "train loss:0.09046775424179339\n",
      "train loss:0.013949375492384302\n",
      "train loss:0.019809896563836023\n",
      "train loss:0.04461921394247322\n",
      "train loss:0.028250539675370306\n",
      "train loss:0.009699152823146474\n",
      "train loss:0.011074897163696145\n",
      "train loss:0.009881991776432106\n",
      "train loss:0.03624440202447556\n",
      "train loss:0.013548338034508684\n",
      "train loss:0.12659125867592327\n",
      "train loss:0.04408462539165032\n",
      "train loss:0.019066837214661493\n",
      "train loss:0.06547883537251863\n",
      "train loss:0.02613969296529752\n",
      "train loss:0.0359212118449657\n",
      "train loss:0.06334462204978132\n",
      "train loss:0.013330213139403819\n",
      "train loss:0.05035262140090737\n",
      "train loss:0.026765791479668784\n",
      "train loss:0.07800808152863321\n",
      "train loss:0.061508003208849\n",
      "train loss:0.09504872249805878\n",
      "train loss:0.11484529406574316\n",
      "train loss:0.02203590576383127\n",
      "train loss:0.03425749455384863\n",
      "train loss:0.02311285940073333\n",
      "train loss:0.04806324992234135\n",
      "train loss:0.025097269298712095\n",
      "train loss:0.03770489361506234\n",
      "train loss:0.0374134653392804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04748990910410857\n",
      "train loss:0.028644819875109494\n",
      "train loss:0.01806143149275782\n",
      "train loss:0.0526848468542572\n",
      "train loss:0.025910221971109912\n",
      "train loss:0.006451823926344072\n",
      "train loss:0.09979011834497824\n",
      "train loss:0.015951706213292925\n",
      "train loss:0.035187196306807056\n",
      "train loss:0.008660433542421412\n",
      "train loss:0.028053529798335846\n",
      "train loss:0.034074125451066146\n",
      "train loss:0.04343075692798377\n",
      "train loss:0.027310523838034884\n",
      "train loss:0.0065840578542087115\n",
      "train loss:0.05478415875637881\n",
      "train loss:0.02958842085959047\n",
      "train loss:0.02237888862146219\n",
      "train loss:0.009705507287785332\n",
      "train loss:0.042831338772194985\n",
      "train loss:0.005594475348154572\n",
      "train loss:0.007707791142981928\n",
      "train loss:0.06394179678525348\n",
      "train loss:0.02859835674706486\n",
      "train loss:0.03771530649407745\n",
      "train loss:0.00824923961998822\n",
      "train loss:0.008121105563321521\n",
      "=== epoch:5, train acc:0.987, test acc:0.982 ===\n",
      "train loss:0.023200364548291996\n",
      "train loss:0.004473586536256496\n",
      "train loss:0.03009563960045305\n",
      "train loss:0.019043148378280535\n",
      "train loss:0.012167396858248096\n",
      "train loss:0.04077510101817418\n",
      "train loss:0.05533610850587103\n",
      "train loss:0.05979930638610334\n",
      "train loss:0.05170700190346808\n",
      "train loss:0.035534585977339724\n",
      "train loss:0.005741225899330424\n",
      "train loss:0.05488987222488191\n",
      "train loss:0.014722268215524243\n",
      "train loss:0.05495057759617727\n",
      "train loss:0.014574541644817605\n",
      "train loss:0.040523869631628774\n",
      "train loss:0.007231389720762768\n",
      "train loss:0.008810626234624096\n",
      "train loss:0.04786695111911997\n",
      "train loss:0.06173464306553265\n",
      "train loss:0.016075058633214193\n",
      "train loss:0.029690276407252365\n",
      "train loss:0.03906104473436173\n",
      "train loss:0.033168881602835446\n",
      "train loss:0.020370029586228723\n",
      "train loss:0.012158362226116375\n",
      "train loss:0.023129550574567212\n",
      "train loss:0.022479446904412725\n",
      "train loss:0.042565873233513345\n",
      "train loss:0.010571886285562458\n",
      "train loss:0.12582039134263134\n",
      "train loss:0.007120078024268064\n",
      "train loss:0.06463862885010059\n",
      "train loss:0.00982479649847708\n",
      "train loss:0.03513887257604109\n",
      "train loss:0.008295818351576677\n",
      "train loss:0.03857813242600167\n",
      "train loss:0.0610280578153444\n",
      "train loss:0.03807135482985588\n",
      "train loss:0.0215214509771761\n",
      "train loss:0.01333850525905507\n",
      "train loss:0.023082651112138218\n",
      "train loss:0.017304752338713647\n",
      "train loss:0.017590776386091314\n",
      "train loss:0.007817518766984038\n",
      "train loss:0.009866083382047969\n",
      "train loss:0.009953241559295925\n",
      "train loss:0.023246611404023156\n",
      "train loss:0.007665322372900292\n",
      "train loss:0.005441188873958028\n",
      "train loss:0.031988653205104495\n",
      "train loss:0.019514633782299295\n",
      "train loss:0.013183220537683253\n",
      "train loss:0.046799892270187396\n",
      "train loss:0.024419049497871263\n",
      "train loss:0.050683821445666064\n",
      "train loss:0.05047343451054194\n",
      "train loss:0.0938148283166932\n",
      "train loss:0.08493890975528635\n",
      "train loss:0.011371939204336774\n",
      "train loss:0.033786522580003295\n",
      "train loss:0.014695779582968837\n",
      "train loss:0.03217694804034247\n",
      "train loss:0.03079797568779233\n",
      "train loss:0.0093624337731815\n",
      "train loss:0.024454936041989565\n",
      "train loss:0.011639158784460148\n",
      "train loss:0.041886256727774705\n",
      "train loss:0.056807787145999315\n",
      "train loss:0.012804431001324376\n",
      "train loss:0.035797805853008464\n",
      "train loss:0.04208610361966723\n",
      "train loss:0.05985880706984147\n",
      "train loss:0.04689707356058394\n",
      "train loss:0.02992461654183301\n",
      "train loss:0.07236073129569649\n",
      "train loss:0.014880077352554253\n",
      "train loss:0.033824807250226775\n",
      "train loss:0.018329115522732246\n",
      "train loss:0.011122509906326789\n",
      "train loss:0.04465591286193876\n",
      "train loss:0.009796860925750514\n",
      "train loss:0.04144871352154901\n",
      "train loss:0.03735048788493671\n",
      "train loss:0.05222248716016471\n",
      "train loss:0.017181639433294944\n",
      "train loss:0.009898245719861651\n",
      "train loss:0.01753144301455184\n",
      "train loss:0.014545327616509465\n",
      "train loss:0.011831169431661327\n",
      "train loss:0.0134493747142851\n",
      "train loss:0.10907845263145596\n",
      "train loss:0.005679097784235737\n",
      "train loss:0.016534860484147845\n",
      "train loss:0.008052408713367636\n",
      "train loss:0.009159860769774725\n",
      "train loss:0.0209275621046761\n",
      "train loss:0.016830834528739826\n",
      "train loss:0.025942494734699756\n",
      "train loss:0.00823791955446668\n",
      "train loss:0.011641715841729352\n",
      "train loss:0.009199094409436736\n",
      "train loss:0.04556776572230352\n",
      "train loss:0.005849294865943051\n",
      "train loss:0.00931339980484702\n",
      "train loss:0.02217409363014203\n",
      "train loss:0.007444677364697065\n",
      "train loss:0.018833614616403448\n",
      "train loss:0.16508120120881195\n",
      "train loss:0.056224904151841226\n",
      "train loss:0.029746704718443647\n",
      "train loss:0.013234643527447677\n",
      "train loss:0.03587536954161927\n",
      "train loss:0.024718324619309884\n",
      "train loss:0.010595539060721925\n",
      "train loss:0.0738770128204068\n",
      "train loss:0.033163499205630456\n",
      "train loss:0.01060037848030127\n",
      "train loss:0.0061247792723853\n",
      "train loss:0.10210937022514294\n",
      "train loss:0.024379332124771037\n",
      "train loss:0.003796399524522919\n",
      "train loss:0.019210860602422202\n",
      "train loss:0.03503232333653639\n",
      "train loss:0.04244459370120146\n",
      "train loss:0.010971092666260007\n",
      "train loss:0.007885556465223858\n",
      "train loss:0.0078113456703098934\n",
      "train loss:0.010135361842033614\n",
      "train loss:0.12807966070184829\n",
      "train loss:0.009901929789724628\n",
      "train loss:0.05320769120031378\n",
      "train loss:0.014435130227122178\n",
      "train loss:0.004041737770507882\n",
      "train loss:0.019444775818354007\n",
      "train loss:0.0308139590282462\n",
      "train loss:0.02697506656853841\n",
      "train loss:0.01701883445546582\n",
      "train loss:0.008897027181761684\n",
      "train loss:0.010822387058679555\n",
      "train loss:0.020294680254731717\n",
      "train loss:0.07645329566858913\n",
      "train loss:0.03373100958040762\n",
      "train loss:0.0581064614850625\n",
      "train loss:0.05069595389402625\n",
      "train loss:0.02049574265362177\n",
      "train loss:0.023104932854954612\n",
      "train loss:0.01738957973338522\n",
      "train loss:0.08800672643903697\n",
      "train loss:0.0036943889096643858\n",
      "train loss:0.006135388891783715\n",
      "train loss:0.016994342449750482\n",
      "train loss:0.007026890836816116\n",
      "train loss:0.09036426498373926\n",
      "train loss:0.002660906235865814\n",
      "train loss:0.019895346385135636\n",
      "train loss:0.02912597391492859\n",
      "train loss:0.03177972466557606\n",
      "train loss:0.0029225855879371704\n",
      "train loss:0.05582391516953773\n",
      "train loss:0.035609768038286395\n",
      "train loss:0.00994050260031779\n",
      "train loss:0.01486277598841299\n",
      "train loss:0.018090353907633427\n",
      "train loss:0.06212355152223825\n",
      "train loss:0.0314540702760877\n",
      "train loss:0.03960453311756338\n",
      "train loss:0.02299197652043041\n",
      "train loss:0.07233717349108951\n",
      "train loss:0.017155998776728385\n",
      "train loss:0.08879472512809\n",
      "train loss:0.01107046415992601\n",
      "train loss:0.03505633945054692\n",
      "train loss:0.011334934950207754\n",
      "train loss:0.03348080765351979\n",
      "train loss:0.015883480376952485\n",
      "train loss:0.1319008290791188\n",
      "train loss:0.01304180017792366\n",
      "train loss:0.011743088889501731\n",
      "train loss:0.053745184705805533\n",
      "train loss:0.045306911828068556\n",
      "train loss:0.0077786292381891945\n",
      "train loss:0.030259491890123277\n",
      "train loss:0.09844662920267169\n",
      "train loss:0.025870439698157898\n",
      "train loss:0.009830454178579681\n",
      "train loss:0.0115716057707181\n",
      "train loss:0.029521341733296885\n",
      "train loss:0.009304412771983777\n",
      "train loss:0.02370717642516681\n",
      "train loss:0.01307681406276769\n",
      "train loss:0.04179718075402519\n",
      "train loss:0.024600345297732296\n",
      "train loss:0.015010405000232693\n",
      "train loss:0.02752177629930611\n",
      "train loss:0.05243251553171057\n",
      "train loss:0.029027318890365094\n",
      "train loss:0.04114916214256234\n",
      "train loss:0.019093374013500777\n",
      "train loss:0.01978707880208284\n",
      "train loss:0.016502910559233117\n",
      "train loss:0.007627089228948696\n",
      "train loss:0.031136745319094848\n",
      "train loss:0.006217446751636126\n",
      "train loss:0.008158344966801965\n",
      "train loss:0.04778404213290067\n",
      "train loss:0.0067108633410437836\n",
      "train loss:0.013352347808936026\n",
      "train loss:0.05973856796801301\n",
      "train loss:0.024018212545438497\n",
      "train loss:0.073911621455621\n",
      "train loss:0.01669812078506005\n",
      "train loss:0.01753055395696645\n",
      "train loss:0.0174846658525819\n",
      "train loss:0.01850004622347028\n",
      "train loss:0.017527399617197997\n",
      "train loss:0.045321877394918324\n",
      "train loss:0.010175464059015451\n",
      "train loss:0.01947345567925971\n",
      "train loss:0.05107530415721229\n",
      "train loss:0.020177240036914873\n",
      "train loss:0.04433745390040914\n",
      "train loss:0.06507640233872841\n",
      "train loss:0.043664797530944606\n",
      "train loss:0.009375949151339213\n",
      "train loss:0.03319790469296029\n",
      "train loss:0.006661779165146428\n",
      "train loss:0.016364968726485584\n",
      "train loss:0.03297698933749584\n",
      "train loss:0.03552081199878013\n",
      "train loss:0.054011323773617226\n",
      "train loss:0.030229100565017583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016174273798819458\n",
      "train loss:0.009514438324370121\n",
      "train loss:0.020979764971681924\n",
      "train loss:0.011391283448853727\n",
      "train loss:0.024256402034589473\n",
      "train loss:0.05672337119382705\n",
      "train loss:0.05437554186836961\n",
      "train loss:0.003347599805140282\n",
      "train loss:0.016361851619427957\n",
      "train loss:0.011049054119251405\n",
      "train loss:0.040297280725103996\n",
      "train loss:0.005157717773896508\n",
      "train loss:0.06156816475015435\n",
      "train loss:0.023896762083573206\n",
      "train loss:0.021068335408349407\n",
      "train loss:0.02057878673544494\n",
      "train loss:0.0267676957029634\n",
      "train loss:0.031396639999852274\n",
      "train loss:0.031120933398163412\n",
      "train loss:0.006066075748997023\n",
      "train loss:0.05172525076401168\n",
      "train loss:0.028747007889725715\n",
      "train loss:0.0830423359106601\n",
      "train loss:0.05668366950646898\n",
      "train loss:0.00859665263229515\n",
      "train loss:0.054800339548942\n",
      "train loss:0.032568613537979185\n",
      "train loss:0.012419697164256362\n",
      "train loss:0.020306367038938723\n",
      "train loss:0.007375185832096481\n",
      "train loss:0.01192653024540712\n",
      "train loss:0.031488887350104716\n",
      "train loss:0.0530572597652705\n",
      "train loss:0.09985901049073254\n",
      "train loss:0.028607372360214732\n",
      "train loss:0.07700746807607006\n",
      "train loss:0.03170554200173662\n",
      "train loss:0.0627738243693909\n",
      "train loss:0.0031046342966762957\n",
      "train loss:0.03109118209479121\n",
      "train loss:0.021955313554853317\n",
      "train loss:0.019491063762101125\n",
      "train loss:0.013485927065222707\n",
      "train loss:0.04522228897641679\n",
      "train loss:0.02899973940196315\n",
      "train loss:0.03955675630020896\n",
      "train loss:0.03963172591754309\n",
      "train loss:0.04826566763342819\n",
      "train loss:0.005514867458319513\n",
      "train loss:0.014202118482007687\n",
      "train loss:0.016568961126340324\n",
      "train loss:0.01603376284255165\n",
      "train loss:0.0544437131851349\n",
      "train loss:0.022007746884580917\n",
      "train loss:0.06776158502420565\n",
      "train loss:0.008662376036451591\n",
      "train loss:0.0907519986354824\n",
      "train loss:0.09177913780132536\n",
      "train loss:0.029591299661531744\n",
      "train loss:0.019694753710607353\n",
      "train loss:0.008293630419315223\n",
      "train loss:0.03165756353453555\n",
      "train loss:0.022403154330618364\n",
      "train loss:0.03652676629969481\n",
      "train loss:0.06907487321745792\n",
      "train loss:0.022348776324056803\n",
      "train loss:0.027428710205206267\n",
      "train loss:0.09157380911790143\n",
      "train loss:0.022940511514695814\n",
      "train loss:0.1566670946859926\n",
      "train loss:0.04095467223701545\n",
      "train loss:0.0475957535480085\n",
      "train loss:0.02261003034979752\n",
      "train loss:0.05783315523613869\n",
      "train loss:0.006790036618472226\n",
      "train loss:0.005781977449984678\n",
      "train loss:0.028968157246642832\n",
      "train loss:0.018460940785370857\n",
      "train loss:0.01703022868952645\n",
      "train loss:0.032953984166126535\n",
      "train loss:0.06339918125781047\n",
      "train loss:0.010489780396095192\n",
      "train loss:0.013541955630923561\n",
      "train loss:0.033873865939064725\n",
      "train loss:0.013368548718930662\n",
      "train loss:0.017138768813467056\n",
      "train loss:0.04276554278301121\n",
      "train loss:0.010836829699541055\n",
      "train loss:0.02071418263682394\n",
      "train loss:0.024542620661469016\n",
      "train loss:0.04803514821213332\n",
      "train loss:0.01703854408999553\n",
      "train loss:0.037107263394035785\n",
      "train loss:0.0026424616771478014\n",
      "train loss:0.032522303502267536\n",
      "train loss:0.002901554397822903\n",
      "train loss:0.06360036698289939\n",
      "train loss:0.016325932285271787\n",
      "train loss:0.04955650529116839\n",
      "train loss:0.024284999459258428\n",
      "train loss:0.03126087652402094\n",
      "train loss:0.014846348573045863\n",
      "train loss:0.045514901683459834\n",
      "train loss:0.010621004740211673\n",
      "train loss:0.02183414725771133\n",
      "train loss:0.004305397150612267\n",
      "train loss:0.02247145308370794\n",
      "train loss:0.018221325132729466\n",
      "train loss:0.018639393417523725\n",
      "train loss:0.019491289270477007\n",
      "train loss:0.00875741357506595\n",
      "train loss:0.016785477315800615\n",
      "train loss:0.017857777148423834\n",
      "train loss:0.05428840698460325\n",
      "train loss:0.018996461252803524\n",
      "train loss:0.031002994319964935\n",
      "train loss:0.010876838814052756\n",
      "train loss:0.04531184033241327\n",
      "train loss:0.02116689846492871\n",
      "train loss:0.044678274616561875\n",
      "train loss:0.019188214787292168\n",
      "train loss:0.016709536550497082\n",
      "train loss:0.0807019611412667\n",
      "train loss:0.046101826210186554\n",
      "train loss:0.024208836048703004\n",
      "train loss:0.08082206656533676\n",
      "train loss:0.006574566446210068\n",
      "train loss:0.014171975918161828\n",
      "train loss:0.006459225054566748\n",
      "train loss:0.017517136833294367\n",
      "train loss:0.06237061772407581\n",
      "train loss:0.024989553869448466\n",
      "train loss:0.027673873243102286\n",
      "train loss:0.028869385706021204\n",
      "train loss:0.05136958780539769\n",
      "train loss:0.01591189622361795\n",
      "train loss:0.07165497417824103\n",
      "train loss:0.07001521486771026\n",
      "train loss:0.006604344284579911\n",
      "train loss:0.0771812216081941\n",
      "train loss:0.019924895624548803\n",
      "train loss:0.007272579890676743\n",
      "train loss:0.013664743247414526\n",
      "train loss:0.031111032081918042\n",
      "train loss:0.07236644331822797\n",
      "train loss:0.0064499610204725175\n",
      "train loss:0.016347706674597912\n",
      "train loss:0.04034266952088715\n",
      "train loss:0.06042098049388582\n",
      "train loss:0.021321922687170543\n",
      "train loss:0.01603387036865245\n",
      "train loss:0.016788291327665555\n",
      "train loss:0.014534552882787677\n",
      "train loss:0.015303524083354544\n",
      "train loss:0.01978691104735191\n",
      "train loss:0.029661124026458537\n",
      "train loss:0.07511419990450538\n",
      "train loss:0.021270905519519115\n",
      "train loss:0.03304105332230322\n",
      "train loss:0.012597218422486045\n",
      "train loss:0.014669242278433406\n",
      "train loss:0.10477400493446319\n",
      "train loss:0.00970398038659386\n",
      "train loss:0.07790354242200442\n",
      "train loss:0.09593519489985874\n",
      "train loss:0.011934567226411376\n",
      "train loss:0.055213354809962055\n",
      "train loss:0.051809553760119274\n",
      "train loss:0.014629310069827555\n",
      "train loss:0.03197753681655934\n",
      "train loss:0.01149206914909509\n",
      "train loss:0.017471513216371016\n",
      "train loss:0.03051651922091327\n",
      "train loss:0.00756329155541605\n",
      "train loss:0.02834157748154667\n",
      "train loss:0.015388485462474477\n",
      "train loss:0.027854984549627076\n",
      "train loss:0.01580476803026839\n",
      "train loss:0.023830840034678724\n",
      "train loss:0.018647405219567592\n",
      "train loss:0.0035570556806162525\n",
      "train loss:0.04950461987729729\n",
      "train loss:0.053881219634689996\n",
      "train loss:0.058930627627324164\n",
      "train loss:0.012793336970569788\n",
      "train loss:0.008710452990199275\n",
      "train loss:0.013063670602677569\n",
      "train loss:0.036188629645337395\n",
      "train loss:0.031495967602048355\n",
      "train loss:0.15917129255319107\n",
      "train loss:0.020599420572372275\n",
      "train loss:0.03436058170173827\n",
      "train loss:0.02637017503459676\n",
      "train loss:0.01879075262047351\n",
      "train loss:0.018792054140064515\n",
      "train loss:0.0431783807329586\n",
      "train loss:0.007633717104356338\n",
      "train loss:0.047439635537226854\n",
      "train loss:0.04322688815495746\n",
      "train loss:0.06429229240470179\n",
      "train loss:0.01786616901537596\n",
      "train loss:0.006332054642051224\n",
      "train loss:0.0204178292557661\n",
      "train loss:0.019952995353600515\n",
      "train loss:0.030029559232087215\n",
      "train loss:0.10058533920115989\n",
      "train loss:0.020632046008851945\n",
      "train loss:0.0275418829189253\n",
      "train loss:0.002991790492207436\n",
      "train loss:0.03491274428342726\n",
      "train loss:0.025480894053159876\n",
      "train loss:0.09193649579208542\n",
      "train loss:0.010002773615860048\n",
      "train loss:0.026469726339099938\n",
      "train loss:0.031347754028735644\n",
      "train loss:0.02852036727647008\n",
      "train loss:0.054965152078965344\n",
      "train loss:0.028442376830953093\n",
      "train loss:0.021844227496106264\n",
      "train loss:0.016807985272483374\n",
      "train loss:0.014786820589257415\n",
      "train loss:0.012073358936789347\n",
      "train loss:0.07821992739833383\n",
      "train loss:0.0315889054368672\n",
      "train loss:0.027341696657772675\n",
      "train loss:0.05437178205472984\n",
      "train loss:0.016737862606489795\n",
      "train loss:0.041389315930851336\n",
      "train loss:0.07152525024677439\n",
      "train loss:0.028129102231432227\n",
      "train loss:0.017863297891690662\n",
      "train loss:0.01109915455334295\n",
      "train loss:0.01118155058783651\n",
      "train loss:0.01173302424604803\n",
      "train loss:0.022654114982079587\n",
      "train loss:0.024363515574865543\n",
      "train loss:0.03440122018295351\n",
      "train loss:0.012576554554575283\n",
      "train loss:0.02785207615059816\n",
      "train loss:0.045155393044697574\n",
      "train loss:0.022715916293745413\n",
      "train loss:0.08681390304568669\n",
      "train loss:0.030415588965224016\n",
      "train loss:0.030424517960966426\n",
      "train loss:0.016784238386539554\n",
      "train loss:0.07520217001960627\n",
      "train loss:0.046288975084913205\n",
      "train loss:0.023295658030780594\n",
      "train loss:0.009238780385811786\n",
      "train loss:0.07285877287200798\n",
      "train loss:0.008846928971361452\n",
      "train loss:0.010418582718095372\n",
      "train loss:0.015950323161023277\n",
      "train loss:0.04349743327268207\n",
      "train loss:0.041235151216882635\n",
      "train loss:0.0093234660320957\n",
      "train loss:0.04641857856155965\n",
      "train loss:0.006783814164468037\n",
      "train loss:0.006849084843514807\n",
      "train loss:0.004635071987572823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007511734370349302\n",
      "train loss:0.007457454214641652\n",
      "train loss:0.012708073164112068\n",
      "train loss:0.04304660930832226\n",
      "train loss:0.05027564564989588\n",
      "train loss:0.007012734904000375\n",
      "train loss:0.008964346839490748\n",
      "train loss:0.019645159080622806\n",
      "train loss:0.02269701558904186\n",
      "train loss:0.03888236428526798\n",
      "train loss:0.004213890746859436\n",
      "train loss:0.007004094500269782\n",
      "train loss:0.010007816771803658\n",
      "train loss:0.013386486968616228\n",
      "train loss:0.02724997564420552\n",
      "train loss:0.017725322553604615\n",
      "train loss:0.015912957717568205\n",
      "train loss:0.013364956987170393\n",
      "train loss:0.04918712152982375\n",
      "train loss:0.029929004932248048\n",
      "train loss:0.01420297044355246\n",
      "train loss:0.006727328414778439\n",
      "train loss:0.04158230173549579\n",
      "train loss:0.01939332182194137\n",
      "train loss:0.06576580777879082\n",
      "train loss:0.013095546255537587\n",
      "train loss:0.004937133453937448\n",
      "train loss:0.02657701157889736\n",
      "train loss:0.08163075547365127\n",
      "train loss:0.02129952020741221\n",
      "train loss:0.004727185789855146\n",
      "train loss:0.005670038640089806\n",
      "train loss:0.007699602439663884\n",
      "train loss:0.0213488666434916\n",
      "train loss:0.013312519956187083\n",
      "train loss:0.08273647637695836\n",
      "train loss:0.03251599843330471\n",
      "train loss:0.009542023615749828\n",
      "train loss:0.08527773497516672\n",
      "train loss:0.007030592118617357\n",
      "train loss:0.01426997361188613\n",
      "train loss:0.027352965873678338\n",
      "train loss:0.04072684347127706\n",
      "train loss:0.08196497094872195\n",
      "train loss:0.005696575450238452\n",
      "train loss:0.010185674915995438\n",
      "train loss:0.03340065171332615\n",
      "train loss:0.006578578962147272\n",
      "train loss:0.03719602764883842\n",
      "train loss:0.018252331772018626\n",
      "train loss:0.03998632098062059\n",
      "train loss:0.024625448052393185\n",
      "train loss:0.015438126921978854\n",
      "train loss:0.00905220366316054\n",
      "train loss:0.008972222396103157\n",
      "train loss:0.003539907396551081\n",
      "train loss:0.016650140945456887\n",
      "train loss:0.015481807015571251\n",
      "train loss:0.01803617492133689\n",
      "train loss:0.09438058232407492\n",
      "train loss:0.013128849392162063\n",
      "train loss:0.026253192436685672\n",
      "train loss:0.07260149805043135\n",
      "train loss:0.011096348652883874\n",
      "train loss:0.029480223874921087\n",
      "train loss:0.014409967762211104\n",
      "train loss:0.017144933945435946\n",
      "train loss:0.036305020608819086\n",
      "train loss:0.01722434089967857\n",
      "train loss:0.05556685120294251\n",
      "train loss:0.03345887371671258\n",
      "train loss:0.02160973537305896\n",
      "train loss:0.03938500827543718\n",
      "train loss:0.03825370977107517\n",
      "train loss:0.010773016796962156\n",
      "train loss:0.016825831746289682\n",
      "train loss:0.021016362409446872\n",
      "train loss:0.010053324259269848\n",
      "train loss:0.02699226351485529\n",
      "train loss:0.011848213362635635\n",
      "train loss:0.017243092729749613\n",
      "train loss:0.02315096411137598\n",
      "train loss:0.04652526410415871\n",
      "train loss:0.016938866196843087\n",
      "train loss:0.010536811543374316\n",
      "train loss:0.11880759811697274\n",
      "train loss:0.023454716375961516\n",
      "train loss:0.011085987343401927\n",
      "train loss:0.017263188392916306\n",
      "train loss:0.02102962001451653\n",
      "train loss:0.019004405282125773\n",
      "train loss:0.011939215403869396\n",
      "train loss:0.051356088611334574\n",
      "train loss:0.0233122678499669\n",
      "train loss:0.010255838916617063\n",
      "train loss:0.009356147085913088\n",
      "train loss:0.004655470390484088\n",
      "train loss:0.00522404667032632\n",
      "train loss:0.052426436699631436\n",
      "train loss:0.01900259662137631\n",
      "train loss:0.06709761565662264\n",
      "train loss:0.024788599551548794\n",
      "train loss:0.051586258227067104\n",
      "train loss:0.017972012867957764\n",
      "train loss:0.014626591473568252\n",
      "train loss:0.02518535569863189\n",
      "train loss:0.08155851851700543\n",
      "train loss:0.027070666054561522\n",
      "=== epoch:6, train acc:0.987, test acc:0.982 ===\n",
      "train loss:0.05430418994441179\n",
      "train loss:0.04554279383779382\n",
      "train loss:0.060768393980402624\n",
      "train loss:0.0037447948556874337\n",
      "train loss:0.0035112431907318763\n",
      "train loss:0.0069003004897644615\n",
      "train loss:0.02370674061328015\n",
      "train loss:0.019431956983043633\n",
      "train loss:0.1164857581209367\n",
      "train loss:0.010364003428993449\n",
      "train loss:0.04149243009117986\n",
      "train loss:0.06023266591298544\n",
      "train loss:0.02326115390709902\n",
      "train loss:0.01423860989023964\n",
      "train loss:0.03463790198005787\n",
      "train loss:0.058809405078810995\n",
      "train loss:0.011629569232780246\n",
      "train loss:0.053717933641839986\n",
      "train loss:0.03361536061724939\n",
      "train loss:0.02351763402135219\n",
      "train loss:0.010084950989816594\n",
      "train loss:0.01258563519030263\n",
      "train loss:0.016283165406017295\n",
      "train loss:0.009886790968527287\n",
      "train loss:0.00998536603891937\n",
      "train loss:0.010516581890084633\n",
      "train loss:0.018353584432271596\n",
      "train loss:0.05214419685215046\n",
      "train loss:0.003285848742936317\n",
      "train loss:0.021092894346973912\n",
      "train loss:0.005226839708484516\n",
      "train loss:0.06707925261226434\n",
      "train loss:0.06676235867534894\n",
      "train loss:0.019843977678360197\n",
      "train loss:0.027708609881011634\n",
      "train loss:0.01013649276581769\n",
      "train loss:0.01442800855880123\n",
      "train loss:0.00402076438457506\n",
      "train loss:0.00806217524132851\n",
      "train loss:0.013227965343871138\n",
      "train loss:0.01218833600692322\n",
      "train loss:0.02038818285676768\n",
      "train loss:0.015115764171080869\n",
      "train loss:0.023584360329165128\n",
      "train loss:0.004042243295636167\n",
      "train loss:0.04030243212479061\n",
      "train loss:0.007451253204550365\n",
      "train loss:0.0050597826928878995\n",
      "train loss:0.003507646034777072\n",
      "train loss:0.03740534188738559\n",
      "train loss:0.059400126138681945\n",
      "train loss:0.018758244761443946\n",
      "train loss:0.045006205979282454\n",
      "train loss:0.00925572629555443\n",
      "train loss:0.01847826561149977\n",
      "train loss:0.013336614988273977\n",
      "train loss:0.006193417075289645\n",
      "train loss:0.036354773673072646\n",
      "train loss:0.0049461575742480906\n",
      "train loss:0.012751629680698134\n",
      "train loss:0.009377395023315947\n",
      "train loss:0.025328536999489518\n",
      "train loss:0.008919196290566004\n",
      "train loss:0.007288224329838326\n",
      "train loss:0.04392761588306139\n",
      "train loss:0.008095855668969962\n",
      "train loss:0.023304660858104693\n",
      "train loss:0.01504938169422427\n",
      "train loss:0.01975177145160317\n",
      "train loss:0.01041270763959512\n",
      "train loss:0.02678307314776919\n",
      "train loss:0.007314940226662252\n",
      "train loss:0.02307317035999437\n",
      "train loss:0.012895154306596636\n",
      "train loss:0.011530016281057306\n",
      "train loss:0.1827061889807438\n",
      "train loss:0.009647686010123956\n",
      "train loss:0.009402627370915169\n",
      "train loss:0.01750646378056663\n",
      "train loss:0.05552335814256464\n",
      "train loss:0.06728184050022112\n",
      "train loss:0.020894875892587553\n",
      "train loss:0.005897154323701562\n",
      "train loss:0.005036636102482224\n",
      "train loss:0.013696998296584243\n",
      "train loss:0.037570399253593505\n",
      "train loss:0.011060208962294808\n",
      "train loss:0.004977718229803723\n",
      "train loss:0.012644497135803234\n",
      "train loss:0.02151269752330225\n",
      "train loss:0.05763788935082635\n",
      "train loss:0.009677657250014855\n",
      "train loss:0.030591237602922546\n",
      "train loss:0.019234383113387696\n",
      "train loss:0.011412170608006995\n",
      "train loss:0.009778058505061834\n",
      "train loss:0.03424510828871638\n",
      "train loss:0.022477158760089204\n",
      "train loss:0.08734470093637524\n",
      "train loss:0.04139996838864228\n",
      "train loss:0.010283280732550599\n",
      "train loss:0.021460280188918407\n",
      "train loss:0.0077759085914261335\n",
      "train loss:0.03663778075570236\n",
      "train loss:0.008160499444612257\n",
      "train loss:0.03002034145643949\n",
      "train loss:0.00507457415276024\n",
      "train loss:0.003551868934984643\n",
      "train loss:0.07381446913618725\n",
      "train loss:0.009932836432028492\n",
      "train loss:0.02780737116197072\n",
      "train loss:0.016944256855936854\n",
      "train loss:0.00825361692808595\n",
      "train loss:0.019420573379189652\n",
      "train loss:0.020414725304464684\n",
      "train loss:0.008140403763986965\n",
      "train loss:0.030443451666996052\n",
      "train loss:0.02503581544076252\n",
      "train loss:0.009314109911646046\n",
      "train loss:0.00467454790613699\n",
      "train loss:0.010380259637117329\n",
      "train loss:0.008713944486863386\n",
      "train loss:0.0025920600932319558\n",
      "train loss:0.006836327280518076\n",
      "train loss:0.023251293961204463\n",
      "train loss:0.014618211859285779\n",
      "train loss:0.020781430295426877\n",
      "train loss:0.09565821140380142\n",
      "train loss:0.04894469392390062\n",
      "train loss:0.017183111562170412\n",
      "train loss:0.03590591228833071\n",
      "train loss:0.03378142327958365\n",
      "train loss:0.04424378457005724\n",
      "train loss:0.01002959377135523\n",
      "train loss:0.025459761223031854\n",
      "train loss:0.02165184139021119\n",
      "train loss:0.06744002500960264\n",
      "train loss:0.03851407941812139\n",
      "train loss:0.044417012022740635\n",
      "train loss:0.031989450236346674\n",
      "train loss:0.012990846970935771\n",
      "train loss:0.020850275886951052\n",
      "train loss:0.06232515423987665\n",
      "train loss:0.06649927082972291\n",
      "train loss:0.04526695331770055\n",
      "train loss:0.01096759156017382\n",
      "train loss:0.014013864063766085\n",
      "train loss:0.026798532959605454\n",
      "train loss:0.009146605661054881\n",
      "train loss:0.049216007603604936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1393506867164463\n",
      "train loss:0.008676262670354689\n",
      "train loss:0.019020469895165468\n",
      "train loss:0.01038582603398982\n",
      "train loss:0.027131787073214567\n",
      "train loss:0.008172581524401751\n",
      "train loss:0.022948186841699348\n",
      "train loss:0.009825592671739542\n",
      "train loss:0.013958538697002023\n",
      "train loss:0.006735073164542658\n",
      "train loss:0.0412964426562673\n",
      "train loss:0.1242858942058829\n",
      "train loss:0.01767439544622464\n",
      "train loss:0.01903120836242888\n",
      "train loss:0.016245947196082453\n",
      "train loss:0.015178980934633674\n",
      "train loss:0.006515068024393328\n",
      "train loss:0.020315747936456886\n",
      "train loss:0.1243239937200155\n",
      "train loss:0.05002380113155331\n",
      "train loss:0.007897477936753996\n",
      "train loss:0.02531534574801965\n",
      "train loss:0.07018685221326573\n",
      "train loss:0.00456778130660477\n",
      "train loss:0.03613773578051269\n",
      "train loss:0.013393103367650901\n",
      "train loss:0.012110605554635761\n",
      "train loss:0.038725901279014034\n",
      "train loss:0.006987508462176839\n",
      "train loss:0.009250356843600573\n",
      "train loss:0.026404673801749098\n",
      "train loss:0.08727376749292215\n",
      "train loss:0.008498572349015035\n",
      "train loss:0.019956589222322095\n",
      "train loss:0.01326839756683146\n",
      "train loss:0.007318564955252637\n",
      "train loss:0.022875307378746993\n",
      "train loss:0.04847060617889283\n",
      "train loss:0.009135661326216609\n",
      "train loss:0.008640427601673604\n",
      "train loss:0.024813063520113258\n",
      "train loss:0.0023514426650931984\n",
      "train loss:0.00912145051786595\n",
      "train loss:0.0031644986845412704\n",
      "train loss:0.0133505739100942\n",
      "train loss:0.014294587145797972\n",
      "train loss:0.01643338973615664\n",
      "train loss:0.029053938735024903\n",
      "train loss:0.008275510767742036\n",
      "train loss:0.0054279111492642265\n",
      "train loss:0.052332036848611034\n",
      "train loss:0.031156641015816694\n",
      "train loss:0.021039452955657626\n",
      "train loss:0.004632408388009487\n",
      "train loss:0.020838191744976507\n",
      "train loss:0.0063843484725589535\n",
      "train loss:0.0015771077421589913\n",
      "train loss:0.07919699424924333\n",
      "train loss:0.011445311000686735\n",
      "train loss:0.03762592957979567\n",
      "train loss:0.006170628668444053\n",
      "train loss:0.010487506903470284\n",
      "train loss:0.019218750414358696\n",
      "train loss:0.07133395342505464\n",
      "train loss:0.006759349872396466\n",
      "train loss:0.13451797617092834\n",
      "train loss:0.014505480233822305\n",
      "train loss:0.03285478293234305\n",
      "train loss:0.026203545658594486\n",
      "train loss:0.015875831773810446\n",
      "train loss:0.06042359853051356\n",
      "train loss:0.02580621576871138\n",
      "train loss:0.044054801929356485\n",
      "train loss:0.004731773802087025\n",
      "train loss:0.020631893885292102\n",
      "train loss:0.08096905309471952\n",
      "train loss:0.029527164649121525\n",
      "train loss:0.019587220043984454\n",
      "train loss:0.017613010612028742\n",
      "train loss:0.025894837067954986\n",
      "train loss:0.056231362267190194\n",
      "train loss:0.012000729024267805\n",
      "train loss:0.03457849457245961\n",
      "train loss:0.02735643147099246\n",
      "train loss:0.010461767998185177\n",
      "train loss:0.0074288162005220005\n",
      "train loss:0.02296566672273965\n",
      "train loss:0.04314145624662642\n",
      "train loss:0.009046035942100598\n",
      "train loss:0.007925673463283446\n",
      "train loss:0.07290989585952973\n",
      "train loss:0.01674463917640115\n",
      "train loss:0.005608403443821056\n",
      "train loss:0.05911670164401201\n",
      "train loss:0.042591729497392705\n",
      "train loss:0.027693384542889356\n",
      "train loss:0.041002502819338635\n",
      "train loss:0.06883334811621201\n",
      "train loss:0.06895690142845771\n",
      "train loss:0.037125152535920455\n",
      "train loss:0.0179447788245742\n",
      "train loss:0.027085131892524573\n",
      "train loss:0.017989641494567367\n",
      "train loss:0.030579650656576182\n",
      "train loss:0.03788944995179933\n",
      "train loss:0.02126902734851064\n",
      "train loss:0.03724453634387115\n",
      "train loss:0.03145945606402891\n",
      "train loss:0.019790307551521395\n",
      "train loss:0.0456640180221751\n",
      "train loss:0.036680410129311676\n",
      "train loss:0.10005259177742477\n",
      "train loss:0.009031382309154502\n",
      "train loss:0.037554867828464594\n",
      "train loss:0.0027720127702207504\n",
      "train loss:0.0019093636084863933\n",
      "train loss:0.011870466750968246\n",
      "train loss:0.010889934000538237\n",
      "train loss:0.017611801590712583\n",
      "train loss:0.012305071882656806\n",
      "train loss:0.023823865300315737\n",
      "train loss:0.039706372215270874\n",
      "train loss:0.018915970343568178\n",
      "train loss:0.029006874062063582\n",
      "train loss:0.020935980089772457\n",
      "train loss:0.009371567233157576\n",
      "train loss:0.006053271980897632\n",
      "train loss:0.024033260207939132\n",
      "train loss:0.015322096361380764\n",
      "train loss:0.040123087927593254\n",
      "train loss:0.013516646210880646\n",
      "train loss:0.014357951033735416\n",
      "train loss:0.005222533540169273\n",
      "train loss:0.047958931502185366\n",
      "train loss:0.009677652471051953\n",
      "train loss:0.011916001872975203\n",
      "train loss:0.028169796935150967\n",
      "train loss:0.07765775119177201\n",
      "train loss:0.006394127956092008\n",
      "train loss:0.06037543345606423\n",
      "train loss:0.04484082712118017\n",
      "train loss:0.005649501378975916\n",
      "train loss:0.014083413988739302\n",
      "train loss:0.07861579190504714\n",
      "train loss:0.03503946093987516\n",
      "train loss:0.04135896706954875\n",
      "train loss:0.03460174387139393\n",
      "train loss:0.024449116360877342\n",
      "train loss:0.0012567078690696107\n",
      "train loss:0.012452544915437182\n",
      "train loss:0.021022496297710518\n",
      "train loss:0.050054101737343294\n",
      "train loss:0.013117007193535271\n",
      "train loss:0.0204417779522606\n",
      "train loss:0.0061547002505340405\n",
      "train loss:0.012500372709168104\n",
      "train loss:0.010472397804414044\n",
      "train loss:0.020184530049904996\n",
      "train loss:0.03733996735839259\n",
      "train loss:0.011471660353512617\n",
      "train loss:0.008718150391305695\n",
      "train loss:0.015735270997324493\n",
      "train loss:0.01749456397500626\n",
      "train loss:0.009112427635510957\n",
      "train loss:0.0027336467096059926\n",
      "train loss:0.011620479549514631\n",
      "train loss:0.016515408758858378\n",
      "train loss:0.01361480886071907\n",
      "train loss:0.04028368764233496\n",
      "train loss:0.015579303143592222\n",
      "train loss:0.03335693970229572\n",
      "train loss:0.054744743841721476\n",
      "train loss:0.005144647885748567\n",
      "train loss:0.013995704409321347\n",
      "train loss:0.006349860258561094\n",
      "train loss:0.010825982821711846\n",
      "train loss:0.0033246207526585396\n",
      "train loss:0.02045975396425008\n",
      "train loss:0.011592284166347224\n",
      "train loss:0.012851863643865521\n",
      "train loss:0.033815084485442834\n",
      "train loss:0.008490194811349803\n",
      "train loss:0.004595589858283356\n",
      "train loss:0.03275115306665871\n",
      "train loss:0.017143182175627287\n",
      "train loss:0.06780476572519042\n",
      "train loss:0.006067617714058393\n",
      "train loss:0.008026397138372192\n",
      "train loss:0.0019231954884059944\n",
      "train loss:0.005722909917166053\n",
      "train loss:0.04484798043683665\n",
      "train loss:0.024479686865014526\n",
      "train loss:0.005895857406375525\n",
      "train loss:0.02344672092522915\n",
      "train loss:0.0267953710906385\n",
      "train loss:0.014367427381320672\n",
      "train loss:0.011556570611023805\n",
      "train loss:0.03757137473590286\n",
      "train loss:0.06925277520092787\n",
      "train loss:0.021589270439085376\n",
      "train loss:0.02224482655664951\n",
      "train loss:0.024443290451049194\n",
      "train loss:0.03190463664279038\n",
      "train loss:0.037470961004322303\n",
      "train loss:0.019827903177023695\n",
      "train loss:0.029887017728190718\n",
      "train loss:0.06570341396005826\n",
      "train loss:0.00514392885044557\n",
      "train loss:0.012191003461442751\n",
      "train loss:0.02717412400862558\n",
      "train loss:0.012778275856391502\n",
      "train loss:0.010944836676304517\n",
      "train loss:0.013222803458430124\n",
      "train loss:0.0087809298111653\n",
      "train loss:0.012864410348183404\n",
      "train loss:0.03096033500124422\n",
      "train loss:0.012909155112126694\n",
      "train loss:0.010332627234097865\n",
      "train loss:0.01393895911228641\n",
      "train loss:0.037048257062598206\n",
      "train loss:0.01919623799645209\n",
      "train loss:0.009515232896328059\n",
      "train loss:0.03974050969483969\n",
      "train loss:0.03430276563431703\n",
      "train loss:0.04697339763346856\n",
      "train loss:0.008192746909160846\n",
      "train loss:0.014219332910417543\n",
      "train loss:0.013511059202402293\n",
      "train loss:0.040284964160341025\n",
      "train loss:0.01080904349711785\n",
      "train loss:0.01915301251538874\n",
      "train loss:0.013641015670339856\n",
      "train loss:0.006685091390305078\n",
      "train loss:0.06926225548298125\n",
      "train loss:0.004898201434765712\n",
      "train loss:0.034163946828142756\n",
      "train loss:0.012966983825528453\n",
      "train loss:0.058912764217011374\n",
      "train loss:0.01620716490146389\n",
      "train loss:0.0032840567611766925\n",
      "train loss:0.007600509120773664\n",
      "train loss:0.012070198518909918\n",
      "train loss:0.011653042118923066\n",
      "train loss:0.022774187128034834\n",
      "train loss:0.003444049519042552\n",
      "train loss:0.06434640840601792\n",
      "train loss:0.007830181239603096\n",
      "train loss:0.006218449888934701\n",
      "train loss:0.0035704891515774425\n",
      "train loss:0.009402119760501279\n",
      "train loss:0.022156744889700854\n",
      "train loss:0.009803464695351833\n",
      "train loss:0.016967167800406854\n",
      "train loss:0.0015697546657056783\n",
      "train loss:0.009443023663186948\n",
      "train loss:0.008979401505218254\n",
      "train loss:0.041925594221535294\n",
      "train loss:0.016393218270467354\n",
      "train loss:0.010834748548460218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04981512825199747\n",
      "train loss:0.02394033525426977\n",
      "train loss:0.027117999570446708\n",
      "train loss:0.022192559765658464\n",
      "train loss:0.03080685302767551\n",
      "train loss:0.012013646975481802\n",
      "train loss:0.014294749358264398\n",
      "train loss:0.011520231278930418\n",
      "train loss:0.0067430159340091615\n",
      "train loss:0.0212816188513412\n",
      "train loss:0.06712646430849406\n",
      "train loss:0.0021184088366110014\n",
      "train loss:0.00837259751653893\n",
      "train loss:0.01687701577601469\n",
      "train loss:0.040983398315145234\n",
      "train loss:0.005678325201972102\n",
      "train loss:0.007950454354993655\n",
      "train loss:0.027322308656872307\n",
      "train loss:0.04009671851807072\n",
      "train loss:0.007081330875276827\n",
      "train loss:0.013364195687865111\n",
      "train loss:0.03055202688963116\n",
      "train loss:0.004300305452997079\n",
      "train loss:0.007476250077855779\n",
      "train loss:0.005805161533156523\n",
      "train loss:0.011860109334524405\n",
      "train loss:0.006346762098744521\n",
      "train loss:0.0019301016435930235\n",
      "train loss:0.011133150044442852\n",
      "train loss:0.01923382334398549\n",
      "train loss:0.02555182391216226\n",
      "train loss:0.01056753285930042\n",
      "train loss:0.016960089396516345\n",
      "train loss:0.04150781775646875\n",
      "train loss:0.026068934440329983\n",
      "train loss:0.014076153611970448\n",
      "train loss:0.009098772374635996\n",
      "train loss:0.009458625043043723\n",
      "train loss:0.03826432032968053\n",
      "train loss:0.028554264130174752\n",
      "train loss:0.01846469170050177\n",
      "train loss:0.019397364908490027\n",
      "train loss:0.004629283573927198\n",
      "train loss:0.030308699357602\n",
      "train loss:0.044834146480208614\n",
      "train loss:0.022491465141203947\n",
      "train loss:0.029220086269068146\n",
      "train loss:0.01638007124365279\n",
      "train loss:0.024604172315359003\n",
      "train loss:0.010472786532312612\n",
      "train loss:0.016160733643482274\n",
      "train loss:0.020892948104735177\n",
      "train loss:0.010382854510637736\n",
      "train loss:0.01631899971001533\n",
      "train loss:0.033976770152574234\n",
      "train loss:0.011115525554708794\n",
      "train loss:0.005459520507482838\n",
      "train loss:0.018566467740052293\n",
      "train loss:0.0244592085232447\n",
      "train loss:0.03234057640460717\n",
      "train loss:0.019352759753004135\n",
      "train loss:0.03366376922504452\n",
      "train loss:0.005203656794496743\n",
      "train loss:0.0444148534847664\n",
      "train loss:0.01710422366481985\n",
      "train loss:0.02076489188427898\n",
      "train loss:0.012581393236540141\n",
      "train loss:0.016756590108845237\n",
      "train loss:0.019590225212466915\n",
      "train loss:0.01469912380650787\n",
      "train loss:0.007803541638326711\n",
      "train loss:0.027137763317851366\n",
      "train loss:0.005308678565803135\n",
      "train loss:0.01836304942864402\n",
      "train loss:0.023739524728846682\n",
      "train loss:0.00751500126694879\n",
      "train loss:0.08053469623818595\n",
      "train loss:0.013728583607693834\n",
      "train loss:0.04599961066644906\n",
      "train loss:0.015041926248691488\n",
      "train loss:0.00860646340136837\n",
      "train loss:0.006798073527508558\n",
      "train loss:0.013800539370105567\n",
      "train loss:0.007033890685693945\n",
      "train loss:0.014232413514831434\n",
      "train loss:0.010387744470375482\n",
      "train loss:0.0036159024903624935\n",
      "train loss:0.02621616189284554\n",
      "train loss:0.023066777808594025\n",
      "train loss:0.005601897430931684\n",
      "train loss:0.009343498505168892\n",
      "train loss:0.0053225242153318655\n",
      "train loss:0.030116089882589403\n",
      "train loss:0.009494888242317513\n",
      "train loss:0.09409335740961006\n",
      "train loss:0.007072337587361282\n",
      "train loss:0.04856345102293545\n",
      "train loss:0.009671348176863409\n",
      "train loss:0.01478145207686489\n",
      "train loss:0.010810647489425586\n",
      "train loss:0.012025310971271366\n",
      "train loss:0.00789349355732034\n",
      "train loss:0.09063497324752451\n",
      "train loss:0.009494678869360361\n",
      "train loss:0.023921450954975155\n",
      "train loss:0.015241362030368535\n",
      "train loss:0.029346554327793893\n",
      "train loss:0.006712419871721697\n",
      "train loss:0.03908564187631209\n",
      "train loss:0.01179056341809889\n",
      "train loss:0.0027640611441163087\n",
      "train loss:0.0040620581517964325\n",
      "train loss:0.013986719485308266\n",
      "train loss:0.014194255340404105\n",
      "train loss:0.017008059964397602\n",
      "train loss:0.009889676041615279\n",
      "train loss:0.054672539414177865\n",
      "train loss:0.007624788163343125\n",
      "train loss:0.0370870394993003\n",
      "train loss:0.00831903595225073\n",
      "train loss:0.007014792205157791\n",
      "train loss:0.010291281548859192\n",
      "train loss:0.03990556967499505\n",
      "train loss:0.014271857146926059\n",
      "train loss:0.05352000847897998\n",
      "train loss:0.028624406446107226\n",
      "train loss:0.006736658149267822\n",
      "train loss:0.007148182623649754\n",
      "train loss:0.11123226424847824\n",
      "train loss:0.01126426186524468\n",
      "train loss:0.05268606897589073\n",
      "train loss:0.013799432244341926\n",
      "train loss:0.02042854901358098\n",
      "train loss:0.005051043521993248\n",
      "train loss:0.016620163818913864\n",
      "train loss:0.005761106656657154\n",
      "train loss:0.012416313777047829\n",
      "train loss:0.005398555992437362\n",
      "train loss:0.012578073057137954\n",
      "train loss:0.010521298932223623\n",
      "train loss:0.047480167654018995\n",
      "train loss:0.009953892863613518\n",
      "train loss:0.015496538196580343\n",
      "train loss:0.0067587320447704755\n",
      "train loss:0.0187159729666456\n",
      "train loss:0.004756299281592817\n",
      "train loss:0.008605229793224431\n",
      "train loss:0.025081155059679196\n",
      "train loss:0.009652192112648872\n",
      "train loss:0.010604846682280712\n",
      "train loss:0.04811517307976871\n",
      "train loss:0.005875565301834433\n",
      "train loss:0.009394531250665193\n",
      "train loss:0.005872926053774831\n",
      "train loss:0.07365154761428423\n",
      "train loss:0.052903689715862665\n",
      "train loss:0.013959683705465808\n",
      "train loss:0.01750665032582104\n",
      "train loss:0.021832117231266907\n",
      "train loss:0.023022252500667063\n",
      "train loss:0.004865303492091046\n",
      "train loss:0.01635035554944484\n",
      "train loss:0.09511523264572588\n",
      "train loss:0.01617978957410307\n",
      "train loss:0.04125319591816948\n",
      "train loss:0.027055138853821672\n",
      "train loss:0.04051304297401601\n",
      "train loss:0.03020835505601229\n",
      "train loss:0.05167081360038277\n",
      "train loss:0.012255219280103652\n",
      "train loss:0.027440159586969742\n",
      "train loss:0.02456846549084175\n",
      "train loss:0.011490692860580066\n",
      "train loss:0.04247608090466064\n",
      "train loss:0.005585408405927476\n",
      "train loss:0.009086605591539999\n",
      "train loss:0.0067441307780727495\n",
      "train loss:0.014525027317908579\n",
      "train loss:0.019266879235526356\n",
      "train loss:0.02481666012707409\n",
      "train loss:0.014257933402703165\n",
      "train loss:0.006288956270458362\n",
      "train loss:0.022263881360013355\n",
      "train loss:0.016973934986935092\n",
      "train loss:0.011437114153146981\n",
      "train loss:0.026189742184650738\n",
      "train loss:0.010541863702637416\n",
      "train loss:0.07227976887647683\n",
      "train loss:0.003482491696059193\n",
      "train loss:0.017628784716130524\n",
      "train loss:0.02658428244919435\n",
      "=== epoch:7, train acc:0.987, test acc:0.983 ===\n",
      "train loss:0.030104727913215456\n",
      "train loss:0.06188848928832671\n",
      "train loss:0.03917005317302663\n",
      "train loss:0.09983165408103474\n",
      "train loss:0.007591036129268087\n",
      "train loss:0.01525165849236505\n",
      "train loss:0.04469589253381529\n",
      "train loss:0.025067632184491272\n",
      "train loss:0.01596716129947889\n",
      "train loss:0.0028326152898130296\n",
      "train loss:0.012766331034361105\n",
      "train loss:0.026612454073292727\n",
      "train loss:0.027425099559744356\n",
      "train loss:0.03849993890514534\n",
      "train loss:0.024989832009094687\n",
      "train loss:0.007765422482272461\n",
      "train loss:0.006634743218349949\n",
      "train loss:0.010937803096144698\n",
      "train loss:0.02313288636957473\n",
      "train loss:0.033484286298571246\n",
      "train loss:0.054614179008055555\n",
      "train loss:0.05136543632435205\n",
      "train loss:0.014342798714202735\n",
      "train loss:0.028864940772577244\n",
      "train loss:0.020418874914723453\n",
      "train loss:0.006549421627407388\n",
      "train loss:0.05164929866970752\n",
      "train loss:0.010755024288123109\n",
      "train loss:0.007262347853225051\n",
      "train loss:0.01102525712606865\n",
      "train loss:0.01583997491263801\n",
      "train loss:0.029768521557598487\n",
      "train loss:0.009534421437103407\n",
      "train loss:0.055960841560954176\n",
      "train loss:0.05649757069448742\n",
      "train loss:0.0014884801926114907\n",
      "train loss:0.014944283659637408\n",
      "train loss:0.010104029106702354\n",
      "train loss:0.013500776449217693\n",
      "train loss:0.004761306102439311\n",
      "train loss:0.008791475489757825\n",
      "train loss:0.0057057965963153755\n",
      "train loss:0.07591160277470305\n",
      "train loss:0.009887154495180125\n",
      "train loss:0.029886055526414938\n",
      "train loss:0.02233534867174217\n",
      "train loss:0.06370277621317881\n",
      "train loss:0.01400255844138004\n",
      "train loss:0.005902586257887024\n",
      "train loss:0.0131440252576495\n",
      "train loss:0.00348660560535108\n",
      "train loss:0.025416980373420217\n",
      "train loss:0.006482714060559785\n",
      "train loss:0.010245016059675462\n",
      "train loss:0.053576912931998885\n",
      "train loss:0.018641811263534255\n",
      "train loss:0.018602539556883693\n",
      "train loss:0.05171078984546138\n",
      "train loss:0.031011207290236553\n",
      "train loss:0.009076088459312548\n",
      "train loss:0.008961292727207365\n",
      "train loss:0.046997895789030235\n",
      "train loss:0.006901229070151104\n",
      "train loss:0.02927548300563658\n",
      "train loss:0.03151223070119264\n",
      "train loss:0.028647073615041534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.045073845924489576\n",
      "train loss:0.007797663304940175\n",
      "train loss:0.006820986817200959\n",
      "train loss:0.015759856966779996\n",
      "train loss:0.010826797040163778\n",
      "train loss:0.014562598230668937\n",
      "train loss:0.012749502764080671\n",
      "train loss:0.01059498283271399\n",
      "train loss:0.007953064302883468\n",
      "train loss:0.013539490219562132\n",
      "train loss:0.00721488589984004\n",
      "train loss:0.024691474209676264\n",
      "train loss:0.014064427522945145\n",
      "train loss:0.022902955001900743\n",
      "train loss:0.006331511250483149\n",
      "train loss:0.0543687614474825\n",
      "train loss:0.0028890124775279176\n",
      "train loss:0.025293463158944894\n",
      "train loss:0.004149437808246498\n",
      "train loss:0.005418676555339132\n",
      "train loss:0.02016670976992693\n",
      "train loss:0.02565144546174566\n",
      "train loss:0.06333817544901996\n",
      "train loss:0.01605086550282772\n",
      "train loss:0.01120249827215486\n",
      "train loss:0.012700789882849855\n",
      "train loss:0.006469897183823975\n",
      "train loss:0.014107298922683848\n",
      "train loss:0.02190510207497174\n",
      "train loss:0.013191734807168192\n",
      "train loss:0.007553960557148925\n",
      "train loss:0.029251890015107355\n",
      "train loss:0.03441134941627626\n",
      "train loss:0.015925779572201176\n",
      "train loss:0.009714685165853124\n",
      "train loss:0.005363405821991581\n",
      "train loss:0.02209731812431489\n",
      "train loss:0.0528190633577265\n",
      "train loss:0.02695390685257469\n",
      "train loss:0.04730029676316993\n",
      "train loss:0.006430143348648099\n",
      "train loss:0.0750907972013644\n",
      "train loss:0.003775183546293652\n",
      "train loss:0.020781243256880525\n",
      "train loss:0.03284166127741008\n",
      "train loss:0.0025474902518595904\n",
      "train loss:0.1079690141906266\n",
      "train loss:0.09735102234982315\n",
      "train loss:0.013202463152486183\n",
      "train loss:0.05939763401885181\n",
      "train loss:0.009672156252071969\n",
      "train loss:0.006108685171982067\n",
      "train loss:0.054534696375668164\n",
      "train loss:0.020231014871337688\n",
      "train loss:0.021146749738247306\n",
      "train loss:0.008724096422482695\n",
      "train loss:0.011341032437191544\n",
      "train loss:0.08838399477439247\n",
      "train loss:0.010829144936971404\n",
      "train loss:0.0028390729761929557\n",
      "train loss:0.0610556369565324\n",
      "train loss:0.018272800612584895\n",
      "train loss:0.04557461456070901\n",
      "train loss:0.014974093739691732\n",
      "train loss:0.008135934737258094\n",
      "train loss:0.021594844104115895\n",
      "train loss:0.016770621313911743\n",
      "train loss:0.030283317594757914\n",
      "train loss:0.010630829437848523\n",
      "train loss:0.012243878385431665\n",
      "train loss:0.007288651880875146\n",
      "train loss:0.01025657967822198\n",
      "train loss:0.007910211721818291\n",
      "train loss:0.015186387072063873\n",
      "train loss:0.0015854691921808933\n",
      "train loss:0.00642683987983117\n",
      "train loss:0.002257686915124136\n",
      "train loss:0.005388407072795571\n",
      "train loss:0.023406713048879903\n",
      "train loss:0.015387278090165426\n",
      "train loss:0.009898343446594654\n",
      "train loss:0.0350019480292689\n",
      "train loss:0.008051460962186043\n",
      "train loss:0.01331854423920265\n",
      "train loss:0.01813493333730275\n",
      "train loss:0.018559474125169947\n",
      "train loss:0.02540392688805309\n",
      "train loss:0.06993040681886664\n",
      "train loss:0.02380311585068809\n",
      "train loss:0.004392167443756746\n",
      "train loss:0.012187616582600102\n",
      "train loss:0.008954595210321076\n",
      "train loss:0.0067823787733103935\n",
      "train loss:0.0647349554982008\n",
      "train loss:0.009299811721212527\n",
      "train loss:0.008879976361713829\n",
      "train loss:0.008393284103199224\n",
      "train loss:0.0341253436311995\n",
      "train loss:0.003939238688210232\n",
      "train loss:0.018582962277807976\n",
      "train loss:0.007556733299299531\n",
      "train loss:0.01580201238152134\n",
      "train loss:0.005841451514676439\n",
      "train loss:0.02195073288064784\n",
      "train loss:0.025124891356607178\n",
      "train loss:0.014858044234744301\n",
      "train loss:0.011018523432232186\n",
      "train loss:0.027255932428552173\n",
      "train loss:0.027896730132042698\n",
      "train loss:0.002960610225179953\n",
      "train loss:0.007459705793548364\n",
      "train loss:0.011580061804157007\n",
      "train loss:0.017150061290198026\n",
      "train loss:0.004859698769727191\n",
      "train loss:0.01666695672257112\n",
      "train loss:0.004400646340355023\n",
      "train loss:0.036921270345665114\n",
      "train loss:0.005981873784292419\n",
      "train loss:0.001963490938577992\n",
      "train loss:0.014832966578767178\n",
      "train loss:0.02124410938394593\n",
      "train loss:0.04053593918735073\n",
      "train loss:0.06396582083325861\n",
      "train loss:0.012470465931150348\n",
      "train loss:0.009310949631730016\n",
      "train loss:0.008974541400540633\n",
      "train loss:0.011101954321480425\n",
      "train loss:0.008256532589730976\n",
      "train loss:0.016428724267622933\n",
      "train loss:0.005154225002446854\n",
      "train loss:0.017993892150636157\n",
      "train loss:0.015122950289462674\n",
      "train loss:0.05494845555585998\n",
      "train loss:0.025207678870314783\n",
      "train loss:0.02583511100242432\n",
      "train loss:0.02346308719341552\n",
      "train loss:0.005494011990205546\n",
      "train loss:0.07140761244949292\n",
      "train loss:0.0054764113112223504\n",
      "train loss:0.011920587956836936\n",
      "train loss:0.013130360218531272\n",
      "train loss:0.015671204874454933\n",
      "train loss:0.030085226128353914\n",
      "train loss:0.04057177336687843\n",
      "train loss:0.009871378624763397\n",
      "train loss:0.003062191856997406\n",
      "train loss:0.002864974908556114\n",
      "train loss:0.005796109416589436\n",
      "train loss:0.015086631837612174\n",
      "train loss:0.005264080585668226\n",
      "train loss:0.025204250870419272\n",
      "train loss:0.007125823536422211\n",
      "train loss:0.015061647802401277\n",
      "train loss:0.08250344639056496\n",
      "train loss:0.02095353597152802\n",
      "train loss:0.004317570949870648\n",
      "train loss:0.020744591746942955\n",
      "train loss:0.017038548928925777\n",
      "train loss:0.18075231320824184\n",
      "train loss:0.0180956886866577\n",
      "train loss:0.04313728968924394\n",
      "train loss:0.0033770826541408656\n",
      "train loss:0.0062894807306189595\n",
      "train loss:0.08238923079299613\n",
      "train loss:0.00860663649334533\n",
      "train loss:0.023785519606668463\n",
      "train loss:0.003120574731885577\n",
      "train loss:0.09696709783968531\n",
      "train loss:0.03916843266613124\n",
      "train loss:0.050105967007782304\n",
      "train loss:0.025375329145941986\n",
      "train loss:0.014042195259495712\n",
      "train loss:0.019955216841750698\n",
      "train loss:0.011941130494617652\n",
      "train loss:0.02885444299627568\n",
      "train loss:0.01476412251142041\n",
      "train loss:0.032076823093261965\n",
      "train loss:0.004789494941956115\n",
      "train loss:0.045552350477260986\n",
      "train loss:0.005618999359600146\n",
      "train loss:0.009200798866425016\n",
      "train loss:0.012040256672384557\n",
      "train loss:0.020819374483487824\n",
      "train loss:0.005826630446457232\n",
      "train loss:0.0886152878193672\n",
      "train loss:0.010364464862064824\n",
      "train loss:0.029495160851721228\n",
      "train loss:0.010376048535827614\n",
      "train loss:0.004494481158151431\n",
      "train loss:0.012301882835132772\n",
      "train loss:0.009528575055974497\n",
      "train loss:0.01521525383962238\n",
      "train loss:0.0021290536484960742\n",
      "train loss:0.010240079402439267\n",
      "train loss:0.008672459253588638\n",
      "train loss:0.0078055780377951\n",
      "train loss:0.005663122532281936\n",
      "train loss:0.010884430978056437\n",
      "train loss:0.0053418988954881804\n",
      "train loss:0.0037882153069929763\n",
      "train loss:0.03705663701967989\n",
      "train loss:0.0017393246228515037\n",
      "train loss:0.00798753298498323\n",
      "train loss:0.012669778521317586\n",
      "train loss:0.00508087859133682\n",
      "train loss:0.012591107833901525\n",
      "train loss:0.04213040847855501\n",
      "train loss:0.04403896180396867\n",
      "train loss:0.0047881532559110014\n",
      "train loss:0.0027828077038739873\n",
      "train loss:0.07815473450866522\n",
      "train loss:0.003081857435803439\n",
      "train loss:0.017036117105579725\n",
      "train loss:0.012562167245567534\n",
      "train loss:0.021079058755696666\n",
      "train loss:0.009611365399483563\n",
      "train loss:0.0136258641415514\n",
      "train loss:0.032365107002909836\n",
      "train loss:0.005815909185603345\n",
      "train loss:0.04820670868494994\n",
      "train loss:0.06221492878303713\n",
      "train loss:0.023217683776990253\n",
      "train loss:0.008585502545376515\n",
      "train loss:0.027157186749620758\n",
      "train loss:0.005080777886317622\n",
      "train loss:0.02243178917873426\n",
      "train loss:0.017543946977238965\n",
      "train loss:0.006469437498300895\n",
      "train loss:0.016106526049133187\n",
      "train loss:0.0058708175276845605\n",
      "train loss:0.03389133815199401\n",
      "train loss:0.026560995203597636\n",
      "train loss:0.010067795358069238\n",
      "train loss:0.03805548727990895\n",
      "train loss:0.035282198022245276\n",
      "train loss:0.005597337471156863\n",
      "train loss:0.012145215585294815\n",
      "train loss:0.03075966806562276\n",
      "train loss:0.004377270201992456\n",
      "train loss:0.060319149082085494\n",
      "train loss:0.0362633888516684\n",
      "train loss:0.010401177716168086\n",
      "train loss:0.027576975967917087\n",
      "train loss:0.07027023403915447\n",
      "train loss:0.004842191700301221\n",
      "train loss:0.01043661185134893\n",
      "train loss:0.001855310961527861\n",
      "train loss:0.008908028523947745\n",
      "train loss:0.010615951932169132\n",
      "train loss:0.016861175913038425\n",
      "train loss:0.04774701362899404\n",
      "train loss:0.0060637001505876266\n",
      "train loss:0.03313139465969543\n",
      "train loss:0.03368298402854499\n",
      "train loss:0.007935000214312617\n",
      "train loss:0.029595512874107287\n",
      "train loss:0.007968767185113473\n",
      "train loss:0.03895772206562708\n",
      "train loss:0.041097109904378586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014873405623343791\n",
      "train loss:0.03731296952464585\n",
      "train loss:0.007794393759527264\n",
      "train loss:0.0062078078678515745\n",
      "train loss:0.0050319221026057185\n",
      "train loss:0.02481979927247909\n",
      "train loss:0.01636519966500379\n",
      "train loss:0.001751817936018122\n",
      "train loss:0.013180288628354093\n",
      "train loss:0.011924379344657034\n",
      "train loss:0.01216320574519904\n",
      "train loss:0.0043358493118618915\n",
      "train loss:0.009301146947005118\n",
      "train loss:0.015140646031791476\n",
      "train loss:0.030397261681158718\n",
      "train loss:0.010532406938176492\n",
      "train loss:0.008445766329953629\n",
      "train loss:0.04617825164657161\n",
      "train loss:0.01946006192219053\n",
      "train loss:0.013290305429711956\n",
      "train loss:0.011017765357366188\n",
      "train loss:0.028306745671317274\n",
      "train loss:0.017506031844702487\n",
      "train loss:0.028995047723771573\n",
      "train loss:0.014438465567963688\n",
      "train loss:0.017283141610935873\n",
      "train loss:0.005581179077002606\n",
      "train loss:0.002106302543142028\n",
      "train loss:0.027937324794554703\n",
      "train loss:0.027807834910247034\n",
      "train loss:0.01015335914726464\n",
      "train loss:0.00827648568522128\n",
      "train loss:0.013433016758488365\n",
      "train loss:0.03955822714298729\n",
      "train loss:0.020460152442737526\n",
      "train loss:0.005058533219098219\n",
      "train loss:0.02435084168762043\n",
      "train loss:0.0044635212300176376\n",
      "train loss:0.007171940007929534\n",
      "train loss:0.01312890239975492\n",
      "train loss:0.022706056176668925\n",
      "train loss:0.008468902234397294\n",
      "train loss:0.012573396433715831\n",
      "train loss:0.020457199415413303\n",
      "train loss:0.009750850531057134\n",
      "train loss:0.016941775553663888\n",
      "train loss:0.001403318356981867\n",
      "train loss:0.004693203666861095\n",
      "train loss:0.007247112858799366\n",
      "train loss:0.008525750778573545\n",
      "train loss:0.020679031826888145\n",
      "train loss:0.01115433340469795\n",
      "train loss:0.023943389371532012\n",
      "train loss:0.01530087053436801\n",
      "train loss:0.015286698179904062\n",
      "train loss:0.004262832687299904\n",
      "train loss:0.06355432017838746\n",
      "train loss:0.01024942643172245\n",
      "train loss:0.005735047621283631\n",
      "train loss:0.011435208186802747\n",
      "train loss:0.02414821837216321\n",
      "train loss:0.007774732927498695\n",
      "train loss:0.033878210815315\n",
      "train loss:0.006600533101414624\n",
      "train loss:0.00876872316120695\n",
      "train loss:0.012993566696123204\n",
      "train loss:0.005136162138493224\n",
      "train loss:0.02359037889371868\n",
      "train loss:0.058665803666625445\n",
      "train loss:0.008406271263438417\n",
      "train loss:0.017778862514708872\n",
      "train loss:0.0531341072188217\n",
      "train loss:0.01916864053665527\n",
      "train loss:0.011802803130284778\n",
      "train loss:0.04502891376021084\n",
      "train loss:0.015324760390836235\n",
      "train loss:0.007918003295321498\n",
      "train loss:0.015469898854309045\n",
      "train loss:0.01853373549689735\n",
      "train loss:0.02680436991822027\n",
      "train loss:0.0007866309220694184\n",
      "train loss:0.015594724492959264\n",
      "train loss:0.025720810343510977\n",
      "train loss:0.05069376575585045\n",
      "train loss:0.010555575229375178\n",
      "train loss:0.013621950474389063\n",
      "train loss:0.021979002497861982\n",
      "train loss:0.014671991868927195\n",
      "train loss:0.018398242311265422\n",
      "train loss:0.033306058620304696\n",
      "train loss:0.01804341498999822\n",
      "train loss:0.006129644191119034\n",
      "train loss:0.04190777067820009\n",
      "train loss:0.00397512267155734\n",
      "train loss:0.00970085738842917\n",
      "train loss:0.02836227256081949\n",
      "train loss:0.012125840602950091\n",
      "train loss:0.006135622002601449\n",
      "train loss:0.004916790512028699\n",
      "train loss:0.022594372506652482\n",
      "train loss:0.017317319505830094\n",
      "train loss:0.027808049401407738\n",
      "train loss:0.051497064153582184\n",
      "train loss:0.006815427610986077\n",
      "train loss:0.004208967564282776\n",
      "train loss:0.009033964998245997\n",
      "train loss:0.01306775773643186\n",
      "train loss:0.03747682432141823\n",
      "train loss:0.0037920662348736385\n",
      "train loss:0.012704158565032025\n",
      "train loss:0.015865940819535507\n",
      "train loss:0.013953771034587982\n",
      "train loss:0.016760627949676653\n",
      "train loss:0.018518888827448173\n",
      "train loss:0.01579568726624129\n",
      "train loss:0.007296186820924427\n",
      "train loss:0.013711631678254064\n",
      "train loss:0.004834983278699068\n",
      "train loss:0.021194571800631935\n",
      "train loss:0.007484511680055777\n",
      "train loss:0.014018223836970236\n",
      "train loss:0.0046444556065811105\n",
      "train loss:0.004418047806747138\n",
      "train loss:0.07605008456604655\n",
      "train loss:0.010273317913448122\n",
      "train loss:0.008964004091796499\n",
      "train loss:0.007293225463480791\n",
      "train loss:0.006599346621488113\n",
      "train loss:0.06990476252822783\n",
      "train loss:0.003798849106980779\n",
      "train loss:0.013934162985513412\n",
      "train loss:0.008163173735450781\n",
      "train loss:0.014998596650217912\n",
      "train loss:0.0028733116151882804\n",
      "train loss:0.011857562174169894\n",
      "train loss:0.010631544585491108\n",
      "train loss:0.01278029564151965\n",
      "train loss:0.0065067305988723125\n",
      "train loss:0.006282388480257642\n",
      "train loss:0.04444997411627306\n",
      "train loss:0.025634006243717932\n",
      "train loss:0.012859442393207486\n",
      "train loss:0.015575522040081198\n",
      "train loss:0.004156763968287744\n",
      "train loss:0.034873676305909\n",
      "train loss:0.014644580983255379\n",
      "train loss:0.006136962417101829\n",
      "train loss:0.0024025850581459725\n",
      "train loss:0.00724595338458967\n",
      "train loss:0.02622865099459554\n",
      "train loss:0.03410105917513136\n",
      "train loss:0.02497578127618727\n",
      "train loss:0.0056379555447238685\n",
      "train loss:0.005657254488979993\n",
      "train loss:0.009814699715750696\n",
      "train loss:0.00977252241255903\n",
      "train loss:0.04262424282290898\n",
      "train loss:0.008711496019850655\n",
      "train loss:0.0033539298509649208\n",
      "train loss:0.017098211673455276\n",
      "train loss:0.03355303498735615\n",
      "train loss:0.045994476650971707\n",
      "train loss:0.006439313970546133\n",
      "train loss:0.015927665342218914\n",
      "train loss:0.005705376374963268\n",
      "train loss:0.007620184312103305\n",
      "train loss:0.0038392203571384963\n",
      "train loss:0.02998307663268446\n",
      "train loss:0.06702202822599058\n",
      "train loss:0.0019289506100047043\n",
      "train loss:0.016499777388109035\n",
      "train loss:0.02044108151899136\n",
      "train loss:0.015322869551536777\n",
      "train loss:0.014859641473676797\n",
      "train loss:0.006937026027024865\n",
      "train loss:0.0030251765419064065\n",
      "train loss:0.04262519361281101\n",
      "train loss:0.004156729342851364\n",
      "train loss:0.03514595463702315\n",
      "train loss:0.012843601097630242\n",
      "train loss:0.03324686112749806\n",
      "train loss:0.01102499353479256\n",
      "train loss:0.007527809077012473\n",
      "train loss:0.001877312525620084\n",
      "train loss:0.020709699105828344\n",
      "train loss:0.013845117207535123\n",
      "train loss:0.01421902941667487\n",
      "train loss:0.0034529162190006252\n",
      "train loss:0.026584296149849203\n",
      "train loss:0.01469367939039638\n",
      "train loss:0.08404089826511647\n",
      "train loss:0.02020367067401336\n",
      "train loss:0.006681290307994219\n",
      "train loss:0.03840457655740622\n",
      "train loss:0.019814609026055894\n",
      "train loss:0.017600624126974038\n",
      "train loss:0.03199244256404115\n",
      "train loss:0.015249551156549846\n",
      "train loss:0.015011322905998402\n",
      "train loss:0.003981214717236018\n",
      "train loss:0.01279593034474564\n",
      "train loss:0.0072601476775411445\n",
      "train loss:0.007552322368325255\n",
      "train loss:0.009381626517952997\n",
      "train loss:0.03394243022419356\n",
      "train loss:0.012033405896146794\n",
      "train loss:0.02523782773092165\n",
      "train loss:0.015926825584124\n",
      "train loss:0.0019785735087682332\n",
      "train loss:0.051826212899557106\n",
      "train loss:0.04811630434911304\n",
      "train loss:0.007743084923802649\n",
      "train loss:0.015285698782844383\n",
      "train loss:0.008228542385036581\n",
      "train loss:0.011216219288639095\n",
      "train loss:0.011276475966669555\n",
      "train loss:0.03319380771543082\n",
      "train loss:0.014640117576047955\n",
      "train loss:0.022317011311773337\n",
      "train loss:0.015527225473496806\n",
      "train loss:0.032651684517790665\n",
      "train loss:0.003446768812511942\n",
      "train loss:0.003723522980725583\n",
      "train loss:0.014297453713376295\n",
      "train loss:0.015784454641538596\n",
      "train loss:0.008930868672371969\n",
      "train loss:0.01713761137564377\n",
      "train loss:0.0037087727325695085\n",
      "train loss:0.015262817535461435\n",
      "train loss:0.004061568806046129\n",
      "train loss:0.005160189928583956\n",
      "train loss:0.006318126482814842\n",
      "train loss:0.005424196439668032\n",
      "train loss:0.004885606720218115\n",
      "train loss:0.002255181440975006\n",
      "train loss:0.010846402605481635\n",
      "train loss:0.005160371541750023\n",
      "train loss:0.04157837642158854\n",
      "train loss:0.06066211396781166\n",
      "train loss:0.02035301119310671\n",
      "train loss:0.006326071475971603\n",
      "train loss:0.006144739043069394\n",
      "train loss:0.008118976913426418\n",
      "train loss:0.01818538941019591\n",
      "train loss:0.0016879421675482923\n",
      "train loss:0.01100155427551557\n",
      "train loss:0.006471563271455892\n",
      "train loss:0.060831821595400966\n",
      "train loss:0.021725520900340044\n",
      "train loss:0.06296338775915082\n",
      "train loss:0.017876540378365537\n",
      "train loss:0.002723544164098164\n",
      "train loss:0.04848871662725977\n",
      "train loss:0.008306523061104845\n",
      "train loss:0.01810914257986769\n",
      "train loss:0.004099025390331077\n",
      "train loss:0.005916907855968245\n",
      "train loss:0.0051000645426409865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10283607908341828\n",
      "train loss:0.016207751988083344\n",
      "train loss:0.03458872671431843\n",
      "train loss:0.015507698905837692\n",
      "train loss:0.017812336214329278\n",
      "train loss:0.04869676899963031\n",
      "train loss:0.006077547808240031\n",
      "train loss:0.0013094606723363725\n",
      "train loss:0.009134311070767422\n",
      "train loss:0.01004181356037674\n",
      "train loss:0.007793680202661667\n",
      "train loss:0.013418599982245281\n",
      "train loss:0.004788871714791579\n",
      "train loss:0.026154154770075634\n",
      "train loss:0.012383702214105586\n",
      "train loss:0.011740211411952582\n",
      "train loss:0.013985278327705322\n",
      "=== epoch:8, train acc:0.988, test acc:0.988 ===\n",
      "train loss:0.024677003756293024\n",
      "train loss:0.004005074126083817\n",
      "train loss:0.007114706249595378\n",
      "train loss:0.017165442316147403\n",
      "train loss:0.0026540547309904274\n",
      "train loss:0.003918369185018652\n",
      "train loss:0.011067601967362641\n",
      "train loss:0.02136358208950385\n",
      "train loss:0.04252916824565361\n",
      "train loss:0.020857723097763823\n",
      "train loss:0.011954821254131796\n",
      "train loss:0.015915611617295898\n",
      "train loss:0.015506159077948889\n",
      "train loss:0.0276369674270392\n",
      "train loss:0.0064087319741958325\n",
      "train loss:0.016520643478626657\n",
      "train loss:0.018090985427807457\n",
      "train loss:0.03181874735270406\n",
      "train loss:0.016719934980208274\n",
      "train loss:0.0027359685481575815\n",
      "train loss:0.0386123474609866\n",
      "train loss:0.023156027956375516\n",
      "train loss:0.005588552772231845\n",
      "train loss:0.014768217357701997\n",
      "train loss:0.0026613253920345875\n",
      "train loss:0.02113298173236758\n",
      "train loss:0.003971109422220175\n",
      "train loss:0.03853738988874312\n",
      "train loss:0.015337709719090679\n",
      "train loss:0.009257998942132552\n",
      "train loss:0.0684470522853467\n",
      "train loss:0.009603234772674742\n",
      "train loss:0.023081605676562717\n",
      "train loss:0.023979544415190214\n",
      "train loss:0.007231842877093611\n",
      "train loss:0.02547149881830778\n",
      "train loss:0.01512288159598515\n",
      "train loss:0.0023188010412490303\n",
      "train loss:0.008308994770736176\n",
      "train loss:0.031542873765665946\n",
      "train loss:0.02553282087831524\n",
      "train loss:0.010204083196576183\n",
      "train loss:0.017124104821418188\n",
      "train loss:0.019140079997392503\n",
      "train loss:0.024072196334273363\n",
      "train loss:0.005580526787676363\n",
      "train loss:0.0028441424426453904\n",
      "train loss:0.022827483184689423\n",
      "train loss:0.023415000273490277\n",
      "train loss:0.0017283903233789493\n",
      "train loss:0.007094166222740125\n",
      "train loss:0.005025465279330585\n",
      "train loss:0.021675791822377888\n",
      "train loss:0.034757250487295825\n",
      "train loss:0.006303333931421102\n",
      "train loss:0.006649201899281091\n",
      "train loss:0.058773487640526596\n",
      "train loss:0.007107819726044318\n",
      "train loss:0.038174764412482555\n",
      "train loss:0.005857315096726957\n",
      "train loss:0.004002498261337376\n",
      "train loss:0.005603612558654665\n",
      "train loss:0.0069548688785416694\n",
      "train loss:0.0016391291673795078\n",
      "train loss:0.010862170226929644\n",
      "train loss:0.02352049170879906\n",
      "train loss:0.0014564423586765573\n",
      "train loss:0.006086823943888239\n",
      "train loss:0.005615470424568507\n",
      "train loss:0.004806442870483368\n",
      "train loss:0.003447640770996718\n",
      "train loss:0.019371156984907236\n",
      "train loss:0.004442566182735236\n",
      "train loss:0.012158155382602332\n",
      "train loss:0.003320696729301584\n",
      "train loss:0.007719015807030228\n",
      "train loss:0.004782362835777945\n",
      "train loss:0.0720125013617388\n",
      "train loss:0.0023324206561541284\n",
      "train loss:0.028886636900977033\n",
      "train loss:0.004067782866144524\n",
      "train loss:0.007842456705141854\n",
      "train loss:0.028358775873835982\n",
      "train loss:0.005011131959615003\n",
      "train loss:0.006877235997966601\n",
      "train loss:0.034066208129927486\n",
      "train loss:0.01884099590319446\n",
      "train loss:0.011996637334641855\n",
      "train loss:0.008374359441891592\n",
      "train loss:0.037207380444243154\n",
      "train loss:0.002995273380717807\n",
      "train loss:0.021961429900395832\n",
      "train loss:0.008168057957767844\n",
      "train loss:0.024238770564770782\n",
      "train loss:0.05569114061227113\n",
      "train loss:0.09188366004721228\n",
      "train loss:0.00514870716084998\n",
      "train loss:0.015752297349303612\n",
      "train loss:0.020490198714131345\n",
      "train loss:0.008534222389832822\n",
      "train loss:0.01351304658322671\n",
      "train loss:0.0037925204895689663\n",
      "train loss:0.012963940250915566\n",
      "train loss:0.012347970499665115\n",
      "train loss:0.018004503784755432\n",
      "train loss:0.05359624047559935\n",
      "train loss:0.00400532231076369\n",
      "train loss:0.009495412023433087\n",
      "train loss:0.01963608349745861\n",
      "train loss:0.02447722302897355\n",
      "train loss:0.009164194874453878\n",
      "train loss:0.006008249519748012\n",
      "train loss:0.0038069894508838565\n",
      "train loss:0.006673678258688912\n",
      "train loss:0.0007627702139579922\n",
      "train loss:0.003682783169963939\n",
      "train loss:0.008470928736300424\n",
      "train loss:0.03127253444169795\n",
      "train loss:0.014055447830696644\n",
      "train loss:0.004164635725259136\n",
      "train loss:0.00700991262148564\n",
      "train loss:0.03000329592099495\n",
      "train loss:0.007445367043512566\n",
      "train loss:0.016738351049994212\n",
      "train loss:0.0021536451713720585\n",
      "train loss:0.0031210598115817677\n",
      "train loss:0.0005919725342473419\n",
      "train loss:0.01785547961413083\n",
      "train loss:0.01719257157545459\n",
      "train loss:0.011240904874422966\n",
      "train loss:0.01053093728623167\n",
      "train loss:0.037446869489273026\n",
      "train loss:0.00633093710739441\n",
      "train loss:0.02242608026839076\n",
      "train loss:0.023616004629065105\n",
      "train loss:0.00846374259245246\n",
      "train loss:0.009235613776337475\n",
      "train loss:0.0032954769332773437\n",
      "train loss:0.010055255164853583\n",
      "train loss:0.0027171265921790357\n",
      "train loss:0.010154454661555592\n",
      "train loss:0.042332401189210625\n",
      "train loss:0.008904367508549817\n",
      "train loss:0.0009514036402592651\n",
      "train loss:0.008248983966054555\n",
      "train loss:0.004429039596051866\n",
      "train loss:0.016602346969943\n",
      "train loss:0.013682442901777354\n",
      "train loss:0.007819030549279161\n",
      "train loss:0.006691489691375959\n",
      "train loss:0.0077291775519554825\n",
      "train loss:0.008700318618067172\n",
      "train loss:0.03291940556194869\n",
      "train loss:0.007985763507579407\n",
      "train loss:0.006110028138268774\n",
      "train loss:0.02413328226768731\n",
      "train loss:0.006139230241915265\n",
      "train loss:0.004639582784202448\n",
      "train loss:0.0429187768622334\n",
      "train loss:0.055283069398025894\n",
      "train loss:0.011454345093298717\n",
      "train loss:0.017735543970471883\n",
      "train loss:0.008306453181564366\n",
      "train loss:0.02459207824579322\n",
      "train loss:0.025652288678435827\n",
      "train loss:0.0038787219588914935\n",
      "train loss:0.008398408209118472\n",
      "train loss:0.010112518753189019\n",
      "train loss:0.00213897311226457\n",
      "train loss:0.004000620879801309\n",
      "train loss:0.004835091206613804\n",
      "train loss:0.008777972994875951\n",
      "train loss:0.006216148258214773\n",
      "train loss:0.028593820956874308\n",
      "train loss:0.01012736758827709\n",
      "train loss:0.0032141171732822226\n",
      "train loss:0.004860766331421174\n",
      "train loss:0.009055345193424037\n",
      "train loss:0.005747320590000855\n",
      "train loss:0.002954415159164382\n",
      "train loss:0.011382352237173947\n",
      "train loss:0.007856889360002072\n",
      "train loss:0.021472509651659394\n",
      "train loss:0.01532780148402057\n",
      "train loss:0.014217067744557667\n",
      "train loss:0.003938020025424259\n",
      "train loss:0.011529338556131793\n",
      "train loss:0.013774312486913598\n",
      "train loss:0.008091393814123089\n",
      "train loss:0.034064112424317075\n",
      "train loss:0.003938104545953684\n",
      "train loss:0.005261308987691707\n",
      "train loss:0.007294899281667194\n",
      "train loss:0.03060694680803368\n",
      "train loss:0.014581566966784427\n",
      "train loss:0.006097630541284479\n",
      "train loss:0.062195461058720654\n",
      "train loss:0.025289901218025657\n",
      "train loss:0.0028050957989250434\n",
      "train loss:0.022450967070447577\n",
      "train loss:0.010611421666203375\n",
      "train loss:0.0069679812207053445\n",
      "train loss:0.00368230564365225\n",
      "train loss:0.0063530968815067755\n",
      "train loss:0.007085106527835641\n",
      "train loss:0.027548020958386897\n",
      "train loss:0.0676280299436258\n",
      "train loss:0.0022058949948107164\n",
      "train loss:0.00727008601952977\n",
      "train loss:0.006821927355963867\n",
      "train loss:0.015275666115771531\n",
      "train loss:0.003534049542936037\n",
      "train loss:0.004415477917574285\n",
      "train loss:0.0036850969742721028\n",
      "train loss:0.01833577747536412\n",
      "train loss:0.00337735166110466\n",
      "train loss:0.016495944986801094\n",
      "train loss:0.008676837617892164\n",
      "train loss:0.006294463802330505\n",
      "train loss:0.006168596068434292\n",
      "train loss:0.008340547581853673\n",
      "train loss:0.006454124036971034\n",
      "train loss:0.016106754241161435\n",
      "train loss:0.009753715050325459\n",
      "train loss:0.020812048784405984\n",
      "train loss:0.0024223788860174462\n",
      "train loss:0.0009533813595611522\n",
      "train loss:0.008830290469225828\n",
      "train loss:0.007800965447322751\n",
      "train loss:0.0024443635513465988\n",
      "train loss:0.011525888665268581\n",
      "train loss:0.003518276627573576\n",
      "train loss:0.006160990294564438\n",
      "train loss:0.023317238366524214\n",
      "train loss:0.007262964047899635\n",
      "train loss:0.0057554889767963005\n",
      "train loss:0.024934571037813345\n",
      "train loss:0.004686733021268444\n",
      "train loss:0.003772934328145923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004513957937590281\n",
      "train loss:0.005317647901602068\n",
      "train loss:0.019883541103903432\n",
      "train loss:0.00931587901308949\n",
      "train loss:0.033403359452682115\n",
      "train loss:0.0037802373285438107\n",
      "train loss:0.0062541477940693336\n",
      "train loss:0.011101616989945752\n",
      "train loss:0.08106445730211083\n",
      "train loss:0.010185828216082358\n",
      "train loss:0.001968335331184553\n",
      "train loss:0.004563171671321713\n",
      "train loss:0.0036996635315425363\n",
      "train loss:0.004894083109822604\n",
      "train loss:0.009686474750991707\n",
      "train loss:0.02312932331377943\n",
      "train loss:0.014042659192771235\n",
      "train loss:0.00406637364801256\n",
      "train loss:0.008951469213626719\n",
      "train loss:0.004427102525940558\n",
      "train loss:0.010551748511389443\n",
      "train loss:0.01646838013140465\n",
      "train loss:0.007850959481444274\n",
      "train loss:0.03340070961995327\n",
      "train loss:0.016514032025123877\n",
      "train loss:0.02289707638564871\n",
      "train loss:0.008375780079360549\n",
      "train loss:0.03647197485786594\n",
      "train loss:0.0033115476050235675\n",
      "train loss:0.0006787051113000086\n",
      "train loss:0.005782202587102258\n",
      "train loss:0.002816910250518506\n",
      "train loss:0.004048265126915272\n",
      "train loss:0.005848825006574993\n",
      "train loss:0.01450824039720166\n",
      "train loss:0.0025505207716569806\n",
      "train loss:0.002351487834523793\n",
      "train loss:0.0022006940442342586\n",
      "train loss:0.005328520734497725\n",
      "train loss:0.0016374894834122107\n",
      "train loss:0.007313188308942825\n",
      "train loss:0.003899438407673214\n",
      "train loss:0.014097069027511719\n",
      "train loss:0.0012706251127990887\n",
      "train loss:0.016209978233046093\n",
      "train loss:0.005666841140622252\n",
      "train loss:0.07122979767494128\n",
      "train loss:0.0023630233377303043\n",
      "train loss:0.01296148291393945\n",
      "train loss:0.016574694136270555\n",
      "train loss:0.00796687180819261\n",
      "train loss:0.024659409309097872\n",
      "train loss:0.025374692643752795\n",
      "train loss:0.02232308259983716\n",
      "train loss:0.008164950696346936\n",
      "train loss:0.007309116222270417\n",
      "train loss:0.014152348571310836\n",
      "train loss:0.016795884971594822\n",
      "train loss:0.012397630538350315\n",
      "train loss:0.01624471668962632\n",
      "train loss:0.0254274173622095\n",
      "train loss:0.00645431898084878\n",
      "train loss:0.006228796073815539\n",
      "train loss:0.01236463655263608\n",
      "train loss:0.004773101027840618\n",
      "train loss:0.07190735605383475\n",
      "train loss:0.017175123366156973\n",
      "train loss:0.022370735145888342\n",
      "train loss:0.011111104456034096\n",
      "train loss:0.005074571124642101\n",
      "train loss:0.009853396866360836\n",
      "train loss:0.014783520614842055\n",
      "train loss:0.011956145283812265\n",
      "train loss:0.005632599620310478\n",
      "train loss:0.0005273851455821589\n",
      "train loss:0.00042358885718612056\n",
      "train loss:0.0018631083365445377\n",
      "train loss:0.03142978837750869\n",
      "train loss:0.0036623218771175033\n",
      "train loss:0.007504796913218008\n",
      "train loss:0.018565828814694187\n",
      "train loss:0.0062754295559883\n",
      "train loss:0.0018757098734759942\n",
      "train loss:0.010676352052210479\n",
      "train loss:0.024785053411361738\n",
      "train loss:0.1658248100605157\n",
      "train loss:0.04229502768471748\n",
      "train loss:0.025633955078157574\n",
      "train loss:0.00623808101239788\n",
      "train loss:0.004161372509881047\n",
      "train loss:0.01064845360817123\n",
      "train loss:0.014510688247756339\n",
      "train loss:0.0011174429727175547\n",
      "train loss:0.0029396961746519725\n",
      "train loss:0.0032499472894761093\n",
      "train loss:0.01998443943282378\n",
      "train loss:0.03334425918713772\n",
      "train loss:0.00262523056850382\n",
      "train loss:0.01566056523342329\n",
      "train loss:0.017207805640165538\n",
      "train loss:0.013458362623510993\n",
      "train loss:0.014375044498117415\n",
      "train loss:0.013910895648534618\n",
      "train loss:0.017277336061705294\n",
      "train loss:0.04562288028688464\n",
      "train loss:0.0038561970823982293\n",
      "train loss:0.002886671406069361\n",
      "train loss:0.0013094404852469679\n",
      "train loss:0.01177326838758952\n",
      "train loss:0.017476804890967937\n",
      "train loss:0.006961504371290585\n",
      "train loss:0.01564462946688014\n",
      "train loss:0.00682895658931404\n",
      "train loss:0.01264783749328732\n",
      "train loss:0.006438949471109956\n",
      "train loss:0.011184915164837621\n",
      "train loss:0.052975882076555826\n",
      "train loss:0.012341117277738432\n",
      "train loss:0.002220060534852855\n",
      "train loss:0.001815364857395158\n",
      "train loss:0.009354101384080557\n",
      "train loss:0.005334067900909496\n",
      "train loss:0.01908477498199523\n",
      "train loss:0.04281028584745579\n",
      "train loss:0.0011937112043362563\n",
      "train loss:0.013497124578968851\n",
      "train loss:0.012053082581522424\n",
      "train loss:0.035401177967777225\n",
      "train loss:0.0022782345514829787\n",
      "train loss:0.005291283115938\n",
      "train loss:0.005964242681707759\n",
      "train loss:0.008561547191221113\n",
      "train loss:0.008314052718703344\n",
      "train loss:0.006059721712089107\n",
      "train loss:0.00671145732135145\n",
      "train loss:0.011325243735057841\n",
      "train loss:0.014668522534208299\n",
      "train loss:0.005529185927227542\n",
      "train loss:0.012137444722615234\n",
      "train loss:0.006866840006704723\n",
      "train loss:0.012023097363407863\n",
      "train loss:0.005896744416922154\n",
      "train loss:0.007028107944244293\n",
      "train loss:0.010755719333803098\n",
      "train loss:0.01087988116980396\n",
      "train loss:0.006198787704087182\n",
      "train loss:0.009053354453948885\n",
      "train loss:0.011229861014419164\n",
      "train loss:0.002917041893341874\n",
      "train loss:0.034015957367669436\n",
      "train loss:0.00480724258310862\n",
      "train loss:0.007066093445455903\n",
      "train loss:0.0007675890969571319\n",
      "train loss:0.004303835284867311\n",
      "train loss:0.0029222237301850702\n",
      "train loss:0.006594305218205051\n",
      "train loss:0.017543734397981018\n",
      "train loss:0.022137950444194785\n",
      "train loss:0.0037367000291505443\n",
      "train loss:0.013128199055173206\n",
      "train loss:0.057345203312457856\n",
      "train loss:0.008777628709005711\n",
      "train loss:0.0017902709717254797\n",
      "train loss:0.0006688749739859328\n",
      "train loss:0.0034541275975366213\n",
      "train loss:0.00952098420784842\n",
      "train loss:0.01520810816246089\n",
      "train loss:0.006369982001221087\n",
      "train loss:0.002910016408122436\n",
      "train loss:0.01843114112027883\n",
      "train loss:0.04486215205300198\n",
      "train loss:0.012533632311117785\n",
      "train loss:0.0028320433237544146\n",
      "train loss:0.008848383361247728\n",
      "train loss:0.021540697018391973\n",
      "train loss:0.0258807180752547\n",
      "train loss:0.0018732609476819575\n",
      "train loss:0.011425338434186147\n",
      "train loss:0.005534357144923322\n",
      "train loss:0.008223151031758353\n",
      "train loss:0.010489941645079682\n",
      "train loss:0.004013051173797072\n",
      "train loss:0.012289937356955837\n",
      "train loss:0.005934366480714191\n",
      "train loss:0.013852540398113528\n",
      "train loss:0.013856450676688576\n",
      "train loss:0.000740231397854313\n",
      "train loss:0.005562697880023048\n",
      "train loss:0.008280356543717646\n",
      "train loss:0.01859413083968065\n",
      "train loss:0.006798446025867749\n",
      "train loss:0.00202976354116649\n",
      "train loss:0.008510299686657797\n",
      "train loss:0.0004298815016299513\n",
      "train loss:0.01777825115435317\n",
      "train loss:0.007341568168575459\n",
      "train loss:0.003401762415161261\n",
      "train loss:0.019721690330717197\n",
      "train loss:0.017947007860922615\n",
      "train loss:0.032465336241789385\n",
      "train loss:0.008238564146608132\n",
      "train loss:0.04294488853696095\n",
      "train loss:0.0044105018408844366\n",
      "train loss:0.006530348440281409\n",
      "train loss:0.0036393550304066108\n",
      "train loss:0.05927756783584714\n",
      "train loss:0.0025656811880259717\n",
      "train loss:0.01939704554643282\n",
      "train loss:0.013904973751812537\n",
      "train loss:0.004094114493346507\n",
      "train loss:0.09037126072499406\n",
      "train loss:0.002576882224546229\n",
      "train loss:0.0036973093412493406\n",
      "train loss:0.04129493200277125\n",
      "train loss:0.005290761831376782\n",
      "train loss:0.017419661461968158\n",
      "train loss:0.02243924981529899\n",
      "train loss:0.02715449417001371\n",
      "train loss:0.02620182623624129\n",
      "train loss:0.002881332689762936\n",
      "train loss:0.01577518674922734\n",
      "train loss:0.0022348411643637323\n",
      "train loss:0.017721879213440303\n",
      "train loss:0.006899161369888667\n",
      "train loss:0.022164225402390186\n",
      "train loss:0.008691634911569735\n",
      "train loss:0.005057574993125265\n",
      "train loss:0.006165668835221507\n",
      "train loss:0.007695060927332963\n",
      "train loss:0.006869889728475076\n",
      "train loss:0.017397089824750914\n",
      "train loss:0.0037377332885180433\n",
      "train loss:0.03519617329427383\n",
      "train loss:0.014654958306217785\n",
      "train loss:0.0016240833283475448\n",
      "train loss:0.009618428550864092\n",
      "train loss:0.0011735494856308436\n",
      "train loss:0.01668219137615432\n",
      "train loss:0.010556814158061659\n",
      "train loss:0.016403333587724552\n",
      "train loss:0.006242030898169187\n",
      "train loss:0.016469601560633554\n",
      "train loss:0.01655639935122651\n",
      "train loss:0.04025726859395753\n",
      "train loss:0.007079279052537293\n",
      "train loss:0.01426441656917542\n",
      "train loss:0.011000931816254918\n",
      "train loss:0.02875305766380814\n",
      "train loss:0.009906866802326867\n",
      "train loss:0.005572607476895971\n",
      "train loss:0.016629224268963044\n",
      "train loss:0.01788941353684318\n",
      "train loss:0.0014122498513704613\n",
      "train loss:0.02519483697675672\n",
      "train loss:0.01202110481912766\n",
      "train loss:0.012274339388064555\n",
      "train loss:0.029894113437064707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0040559199600275625\n",
      "train loss:0.013162323868761577\n",
      "train loss:0.05746977241995779\n",
      "train loss:0.02130296417573325\n",
      "train loss:0.00359985401109036\n",
      "train loss:0.010002844809579714\n",
      "train loss:0.005292317081162313\n",
      "train loss:0.0030311133456372135\n",
      "train loss:0.02708337012846853\n",
      "train loss:0.0014133726518971333\n",
      "train loss:0.00797753495037195\n",
      "train loss:0.009142360042219314\n",
      "train loss:0.001959077814029649\n",
      "train loss:0.007913863511637302\n",
      "train loss:0.007900224809699855\n",
      "train loss:0.08213685609284395\n",
      "train loss:0.0012820975439406788\n",
      "train loss:0.002801250555628107\n",
      "train loss:0.011827309353974637\n",
      "train loss:0.009182280472896778\n",
      "train loss:0.004619516398411444\n",
      "train loss:0.012037891777475518\n",
      "train loss:0.009479652073042433\n",
      "train loss:0.03739834436684167\n",
      "train loss:0.0022297382072010087\n",
      "train loss:0.0014474525863795518\n",
      "train loss:0.010193813792649586\n",
      "train loss:0.0071546430314334795\n",
      "train loss:0.005980568043055746\n",
      "train loss:0.0034766900792089135\n",
      "train loss:0.0009666043146160971\n",
      "train loss:0.0018100217442137533\n",
      "train loss:0.006215486861138531\n",
      "train loss:0.006536334740301344\n",
      "train loss:0.015225775624341312\n",
      "train loss:0.01465963635629284\n",
      "train loss:0.05192143546648373\n",
      "train loss:0.005122407750221592\n",
      "train loss:0.0019890725035615754\n",
      "train loss:0.016680288992225557\n",
      "train loss:0.052134925827304175\n",
      "train loss:0.003531118803832399\n",
      "train loss:0.011218606590933333\n",
      "train loss:0.006821077803184982\n",
      "train loss:0.005711428182737235\n",
      "train loss:0.009659298880711934\n",
      "train loss:0.009062063159088234\n",
      "train loss:0.015294366658143979\n",
      "train loss:0.011522294294742719\n",
      "train loss:0.0095726467108921\n",
      "train loss:0.002206514133684396\n",
      "train loss:0.006928591982413612\n",
      "train loss:0.011429089396028451\n",
      "train loss:0.003923112159514808\n",
      "train loss:0.014860894114551484\n",
      "train loss:0.0187732924522411\n",
      "train loss:0.03740761227679719\n",
      "train loss:0.009075510528117585\n",
      "train loss:0.017599162579212315\n",
      "train loss:0.004196555107897911\n",
      "train loss:0.01651468887674318\n",
      "train loss:0.09182536726978573\n",
      "train loss:0.016849249325755437\n",
      "train loss:0.013344306612335351\n",
      "train loss:0.013089012729083103\n",
      "train loss:0.0005352621050042286\n",
      "train loss:0.01436972136325186\n",
      "train loss:0.0024749273548250223\n",
      "train loss:0.012293041545821075\n",
      "train loss:0.005116613009735947\n",
      "train loss:0.0018777305082844544\n",
      "train loss:0.0065152913213724906\n",
      "train loss:0.0047393117375300695\n",
      "train loss:0.019390490036293485\n",
      "train loss:0.008214360938561848\n",
      "train loss:0.006174706092129525\n",
      "train loss:0.003156010323584473\n",
      "train loss:0.007350434553857676\n",
      "train loss:0.049214553575666564\n",
      "train loss:0.04665976660587491\n",
      "train loss:0.008687654321522898\n",
      "train loss:0.0451753882522117\n",
      "train loss:0.006010067225770562\n",
      "train loss:0.0485789303576784\n",
      "train loss:0.005769599215441257\n",
      "train loss:0.015609280804582942\n",
      "train loss:0.011307725850104445\n",
      "train loss:0.002042947595509127\n",
      "train loss:0.031389888725567056\n",
      "train loss:0.06888180442691548\n",
      "train loss:0.039207709455035857\n",
      "train loss:0.020571976565660222\n",
      "train loss:0.0060258469213875145\n",
      "train loss:0.004198840125641051\n",
      "train loss:0.005038943503940771\n",
      "train loss:0.025793427531808733\n",
      "train loss:0.016222533892384133\n",
      "train loss:0.012390961076937853\n",
      "train loss:0.017296210446288533\n",
      "train loss:0.005270330213244875\n",
      "train loss:0.004800247390447417\n",
      "train loss:0.009916865262898103\n",
      "train loss:0.006072496182581679\n",
      "train loss:0.03176285924797087\n",
      "=== epoch:9, train acc:0.992, test acc:0.986 ===\n",
      "train loss:0.03168412489902926\n",
      "train loss:0.017736693798544687\n",
      "train loss:0.0019420701711448684\n",
      "train loss:0.0016891831321577447\n",
      "train loss:0.003310743078758449\n",
      "train loss:0.026705645209459172\n",
      "train loss:0.00429624337360784\n",
      "train loss:0.008339114079520808\n",
      "train loss:0.019437048078335063\n",
      "train loss:0.005771618104340331\n",
      "train loss:0.007052816367937629\n",
      "train loss:0.009167837590205308\n",
      "train loss:0.010391926388999544\n",
      "train loss:0.014744503229572168\n",
      "train loss:0.02261617114093752\n",
      "train loss:0.023019498649322987\n",
      "train loss:0.08161005246101173\n",
      "train loss:0.01590966608116762\n",
      "train loss:0.011590907557737451\n",
      "train loss:0.01738919330072049\n",
      "train loss:0.005882004305897739\n",
      "train loss:0.008909000597878998\n",
      "train loss:0.04165376841494023\n",
      "train loss:0.0073757508805699454\n",
      "train loss:0.016295856663121205\n",
      "train loss:0.01834263278631616\n",
      "train loss:0.015635461460702132\n",
      "train loss:0.00928367834804452\n",
      "train loss:0.0020073196486406456\n",
      "train loss:0.021883482693589276\n",
      "train loss:0.003045524442090332\n",
      "train loss:0.005856462278051334\n",
      "train loss:0.003894483939069985\n",
      "train loss:0.0420683996271691\n",
      "train loss:0.0030215008103317486\n",
      "train loss:0.0075084693649737425\n",
      "train loss:0.015676012527565918\n",
      "train loss:0.010426751429088445\n",
      "train loss:0.005290123448578581\n",
      "train loss:0.005328778188786329\n",
      "train loss:0.01800722953749475\n",
      "train loss:0.007367147473829471\n",
      "train loss:0.05681558063513453\n",
      "train loss:0.0046572273910443765\n",
      "train loss:0.017469718884570436\n",
      "train loss:0.0031114001291580482\n",
      "train loss:0.007358717975822184\n",
      "train loss:0.004052310994017121\n",
      "train loss:0.011429794598150744\n",
      "train loss:0.016623891198646358\n",
      "train loss:0.003853300824113608\n",
      "train loss:0.024380941167112063\n",
      "train loss:0.006221786463017291\n",
      "train loss:0.009934977911397348\n",
      "train loss:0.01535395329794819\n",
      "train loss:0.006957011554047487\n",
      "train loss:0.0014977606555448227\n",
      "train loss:0.01165925312786346\n",
      "train loss:0.003915708451577221\n",
      "train loss:0.17084636952629706\n",
      "train loss:0.00644821098514166\n",
      "train loss:0.005215111092413841\n",
      "train loss:0.007324323664266552\n",
      "train loss:0.011289060135163011\n",
      "train loss:0.008663812651314362\n",
      "train loss:0.0032468490404273676\n",
      "train loss:0.0223826947269792\n",
      "train loss:0.0017533991803188758\n",
      "train loss:0.005121540414783753\n",
      "train loss:0.03527194514472167\n",
      "train loss:0.004554046965351111\n",
      "train loss:0.005646934664729568\n",
      "train loss:0.004564514775477129\n",
      "train loss:0.00863789809618194\n",
      "train loss:0.009975419214478549\n",
      "train loss:0.004348729510486203\n",
      "train loss:0.014351569160470859\n",
      "train loss:0.00567769853707853\n",
      "train loss:0.004818226031711005\n",
      "train loss:0.009127562840768004\n",
      "train loss:0.04420706181736017\n",
      "train loss:0.0017421205134894283\n",
      "train loss:0.002112260887469598\n",
      "train loss:0.0006855898942503037\n",
      "train loss:0.014388974412834456\n",
      "train loss:0.005671618347471702\n",
      "train loss:0.005747196927603901\n",
      "train loss:0.011294282707205245\n",
      "train loss:0.0024023353595249842\n",
      "train loss:0.011352326162505004\n",
      "train loss:0.0024645589317198687\n",
      "train loss:0.009309410944857243\n",
      "train loss:0.018470072706559384\n",
      "train loss:0.011052187792119188\n",
      "train loss:0.02449568340597547\n",
      "train loss:0.0034840685962965355\n",
      "train loss:0.0041651118835042186\n",
      "train loss:0.009012222606072502\n",
      "train loss:0.0062091704973336135\n",
      "train loss:0.009790391288276587\n",
      "train loss:0.007314482311699604\n",
      "train loss:0.027413651115317947\n",
      "train loss:0.018843642140652744\n",
      "train loss:0.004942090945314243\n",
      "train loss:0.011046637781472324\n",
      "train loss:0.01589827312339978\n",
      "train loss:0.004508951749602173\n",
      "train loss:0.0059882125759512924\n",
      "train loss:0.05400725600294737\n",
      "train loss:0.01586959834008565\n",
      "train loss:0.009428428433115983\n",
      "train loss:0.01086055557479963\n",
      "train loss:0.008616398528662366\n",
      "train loss:0.01519288409110349\n",
      "train loss:0.05431905923864012\n",
      "train loss:0.005073506974965408\n",
      "train loss:0.0015666927845690163\n",
      "train loss:0.013129121473223761\n",
      "train loss:0.0037154010636381817\n",
      "train loss:0.002314838269151063\n",
      "train loss:0.00471125715717239\n",
      "train loss:0.024313461802365564\n",
      "train loss:0.03968460963053207\n",
      "train loss:0.0017226889927405141\n",
      "train loss:0.002772435655077861\n",
      "train loss:0.011114536623746406\n",
      "train loss:0.015353959349958176\n",
      "train loss:0.0038925919244787778\n",
      "train loss:0.005204780571566945\n",
      "train loss:0.006799841891863924\n",
      "train loss:0.005643806088182878\n",
      "train loss:0.0034679923656468505\n",
      "train loss:0.003844779322523369\n",
      "train loss:0.008880639678266508\n",
      "train loss:0.03106038256426757\n",
      "train loss:0.0032013797021347673\n",
      "train loss:0.021192212989731535\n",
      "train loss:0.010484891015750043\n",
      "train loss:0.0028229032608971527\n",
      "train loss:0.004461320553698907\n",
      "train loss:0.001462049695308096\n",
      "train loss:0.024019600774342433\n",
      "train loss:0.019483246345427356\n",
      "train loss:0.0022338151121322645\n",
      "train loss:0.0030517076054653123\n",
      "train loss:0.01767082599318027\n",
      "train loss:0.010926284687770292\n",
      "train loss:0.005335577939259425\n",
      "train loss:0.011102314148191668\n",
      "train loss:0.02455699900006305\n",
      "train loss:0.014545301166160278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00564026589103292\n",
      "train loss:0.03857861306804087\n",
      "train loss:0.027921988074390128\n",
      "train loss:0.01945489829114765\n",
      "train loss:0.005994009727041057\n",
      "train loss:0.0014374467421239894\n",
      "train loss:0.006378389016072749\n",
      "train loss:0.028159492804178933\n",
      "train loss:0.014227848500552556\n",
      "train loss:0.0006747986722668832\n",
      "train loss:0.010330260603389024\n",
      "train loss:0.012652812436157113\n",
      "train loss:0.0041244559593552966\n",
      "train loss:0.007592658111579034\n",
      "train loss:0.0031499144152494045\n",
      "train loss:0.008176597176229716\n",
      "train loss:0.00943221952290401\n",
      "train loss:0.008563670833001713\n",
      "train loss:0.004293597962016264\n",
      "train loss:0.0018981985000901126\n",
      "train loss:0.004429379702811085\n",
      "train loss:0.005869057381018062\n",
      "train loss:0.005908803167095475\n",
      "train loss:0.01252939663230901\n",
      "train loss:0.0051891159904707594\n",
      "train loss:0.002122324771094047\n",
      "train loss:0.0025995169236874543\n",
      "train loss:0.021212527413757294\n",
      "train loss:0.010760283228489766\n",
      "train loss:0.04288589502493543\n",
      "train loss:0.003718731460463211\n",
      "train loss:0.007858704012178266\n",
      "train loss:0.0033398051099834576\n",
      "train loss:0.023574156978549733\n",
      "train loss:0.004708723174588415\n",
      "train loss:0.00788398131469479\n",
      "train loss:0.006658811756180504\n",
      "train loss:0.013189635370620427\n",
      "train loss:0.015978845909037\n",
      "train loss:0.004380509723952318\n",
      "train loss:0.017136347935598525\n",
      "train loss:0.00522537807081641\n",
      "train loss:0.00213025794057543\n",
      "train loss:0.005524455745733903\n",
      "train loss:0.009466565281679296\n",
      "train loss:0.021822033405692273\n",
      "train loss:0.0021487275883162265\n",
      "train loss:0.03213682806198291\n",
      "train loss:0.006849857278852197\n",
      "train loss:0.007390783510782383\n",
      "train loss:0.017029115731401846\n",
      "train loss:0.011618569091160807\n",
      "train loss:0.0010125867281667892\n",
      "train loss:0.009697042814320338\n",
      "train loss:0.00529772684803555\n",
      "train loss:0.004429386466731568\n",
      "train loss:0.004378520365046706\n",
      "train loss:0.007119100169032507\n",
      "train loss:0.003735221893730623\n",
      "train loss:0.004493812716693967\n",
      "train loss:0.006321377430341712\n",
      "train loss:0.005059454970274862\n",
      "train loss:0.0028101438690513185\n",
      "train loss:0.008128400549604875\n",
      "train loss:0.007904963939221446\n",
      "train loss:0.006020368865515252\n",
      "train loss:0.0314228951857766\n",
      "train loss:0.030073902074217465\n",
      "train loss:0.012566003796160734\n",
      "train loss:0.0013002957946309677\n",
      "train loss:0.0033002572408454478\n",
      "train loss:0.011611509661176295\n",
      "train loss:0.07357981100155146\n",
      "train loss:0.0036862409768597063\n",
      "train loss:0.016703790310012942\n",
      "train loss:0.001575925899982096\n",
      "train loss:0.0044464401869722244\n",
      "train loss:0.0006413395339968592\n",
      "train loss:0.020652635827641302\n",
      "train loss:0.00786393011333799\n",
      "train loss:0.002788247465275433\n",
      "train loss:0.0017978042334742322\n",
      "train loss:0.008214380728803088\n",
      "train loss:0.0027934387977932196\n",
      "train loss:0.005063495503949973\n",
      "train loss:0.00828108827401865\n",
      "train loss:0.009006058797790584\n",
      "train loss:0.0010637974611681093\n",
      "train loss:0.005873412099695781\n",
      "train loss:0.0038563439808388\n",
      "train loss:0.0006120039618830492\n",
      "train loss:0.03810892520471036\n",
      "train loss:0.01396941763204149\n",
      "train loss:0.00799459347310737\n",
      "train loss:0.006627563993514734\n",
      "train loss:0.005788269601171363\n",
      "train loss:0.001697839001140654\n",
      "train loss:0.005645906648849019\n",
      "train loss:0.009420340275752708\n",
      "train loss:0.010627454594711665\n",
      "train loss:0.023305253189650682\n",
      "train loss:0.008220862802397005\n",
      "train loss:0.007184173740820575\n",
      "train loss:0.0069634268601133946\n",
      "train loss:0.03256291392986408\n",
      "train loss:0.0025779946332048493\n",
      "train loss:0.02153657428998474\n",
      "train loss:0.0006314829916698651\n",
      "train loss:0.005750345858806072\n",
      "train loss:0.03176892017845698\n",
      "train loss:0.01125803512755759\n",
      "train loss:0.00406502776813023\n",
      "train loss:0.009653718313742747\n",
      "train loss:0.004408985585580034\n",
      "train loss:0.036485236068575046\n",
      "train loss:0.03115571314628102\n",
      "train loss:0.004719412665794829\n",
      "train loss:0.018499266788309755\n",
      "train loss:0.010318666827086105\n",
      "train loss:0.004024156732746756\n",
      "train loss:0.052636005028846806\n",
      "train loss:0.0033816051115040146\n",
      "train loss:0.003167886744963781\n",
      "train loss:0.012327980860668067\n",
      "train loss:0.017560870628913164\n",
      "train loss:0.07861720141140516\n",
      "train loss:0.004034430634832591\n",
      "train loss:0.004727653830452874\n",
      "train loss:0.0028491018959770657\n",
      "train loss:0.007583197343631787\n",
      "train loss:0.005712467832736574\n",
      "train loss:0.009120375552557083\n",
      "train loss:0.01891241890850208\n",
      "train loss:0.010722669222299246\n",
      "train loss:0.009094982197561666\n",
      "train loss:0.05900385382773452\n",
      "train loss:0.0006468578230036133\n",
      "train loss:0.004242728550590363\n",
      "train loss:0.007330850044830073\n",
      "train loss:0.009039929824631003\n",
      "train loss:0.004238959361684216\n",
      "train loss:0.005289890643568186\n",
      "train loss:0.009146728288109682\n",
      "train loss:0.0003160028323050056\n",
      "train loss:0.007646350204183638\n",
      "train loss:0.008778258878456015\n",
      "train loss:0.004318954271679858\n",
      "train loss:0.0060884759521517865\n",
      "train loss:0.009185563960505886\n",
      "train loss:0.02219285912129905\n",
      "train loss:0.014965531696961685\n",
      "train loss:0.011394806582978267\n",
      "train loss:0.009036366390064545\n",
      "train loss:0.008224995599235663\n",
      "train loss:0.014637946656431557\n",
      "train loss:0.003511624031935541\n",
      "train loss:0.017621290274977212\n",
      "train loss:0.005168468591943186\n",
      "train loss:0.07524146567590263\n",
      "train loss:0.034798834598545644\n",
      "train loss:0.024340028630422193\n",
      "train loss:0.0032991027311110232\n",
      "train loss:0.007360617857202714\n",
      "train loss:0.009102137366574146\n",
      "train loss:0.007063663897008899\n",
      "train loss:0.001688445260334046\n",
      "train loss:0.008163171939077835\n",
      "train loss:0.004892010715557942\n",
      "train loss:0.010266249419250216\n",
      "train loss:0.008894420204066247\n",
      "train loss:0.021117638891253832\n",
      "train loss:0.014449503981605993\n",
      "train loss:0.011930607150797468\n",
      "train loss:0.009647826559302802\n",
      "train loss:0.07174177542196306\n",
      "train loss:0.007823393767688007\n",
      "train loss:0.00555231401931544\n",
      "train loss:0.003571082433941152\n",
      "train loss:0.0018572874312264012\n",
      "train loss:0.009066381041967194\n",
      "train loss:0.005142986522506028\n",
      "train loss:0.0070451286022465455\n",
      "train loss:0.016951800237090333\n",
      "train loss:0.008689472236355312\n",
      "train loss:0.009401608810302171\n",
      "train loss:0.0061074138693175024\n",
      "train loss:0.007753561821059781\n",
      "train loss:0.004568194801951303\n",
      "train loss:0.02356457464075291\n",
      "train loss:0.0056154122876185516\n",
      "train loss:0.00903469591251915\n",
      "train loss:0.0019794075052884936\n",
      "train loss:0.005222622827080565\n",
      "train loss:0.002688510997753292\n",
      "train loss:0.005124408298593829\n",
      "train loss:0.00989720814096585\n",
      "train loss:0.005116259466683433\n",
      "train loss:0.012424938641558027\n",
      "train loss:0.00160717435924002\n",
      "train loss:0.005048279866585329\n",
      "train loss:0.0043204641331819615\n",
      "train loss:0.002074825724882696\n",
      "train loss:0.0053982393905093505\n",
      "train loss:0.0019024111789951005\n",
      "train loss:0.006619776696552726\n",
      "train loss:0.004429242583921311\n",
      "train loss:0.00290778623253277\n",
      "train loss:0.003560382028705692\n",
      "train loss:0.005222246086633123\n",
      "train loss:0.0050977984945642495\n",
      "train loss:0.007065862752895605\n",
      "train loss:0.006318682555144113\n",
      "train loss:0.01221185057000352\n",
      "train loss:0.008780747341882127\n",
      "train loss:0.007830497110306655\n",
      "train loss:0.015867602540968834\n",
      "train loss:0.009777884763308932\n",
      "train loss:0.007373007646881166\n",
      "train loss:0.01919782850206725\n",
      "train loss:0.0071180840034888015\n",
      "train loss:0.007503993361965352\n",
      "train loss:0.010150813322881948\n",
      "train loss:0.009006595166617693\n",
      "train loss:0.0017115405112630455\n",
      "train loss:0.03787569268489836\n",
      "train loss:0.0025792388732922434\n",
      "train loss:0.005457473519482416\n",
      "train loss:0.003949141413420725\n",
      "train loss:0.0034164256245776763\n",
      "train loss:0.0054734513116863935\n",
      "train loss:0.022550502256632177\n",
      "train loss:0.013083606877824082\n",
      "train loss:0.021048143616964266\n",
      "train loss:0.002002825966078885\n",
      "train loss:0.009012532206577656\n",
      "train loss:0.004506041781895308\n",
      "train loss:0.004284706895914852\n",
      "train loss:0.003237215007507976\n",
      "train loss:0.002329087496605827\n",
      "train loss:0.001838236429253969\n",
      "train loss:0.022357876735416032\n",
      "train loss:0.006355878177864741\n",
      "train loss:0.008196627552470496\n",
      "train loss:0.00279264606545102\n",
      "train loss:0.004109782977614522\n",
      "train loss:0.008580385273362188\n",
      "train loss:0.0011219311853323363\n",
      "train loss:0.009405839646918521\n",
      "train loss:0.0043205533718345965\n",
      "train loss:0.015738181381363472\n",
      "train loss:0.0036416021959155957\n",
      "train loss:0.0038829223385806705\n",
      "train loss:0.0016356149370135493\n",
      "train loss:0.013903936974293953\n",
      "train loss:0.005041630406634684\n",
      "train loss:0.014346354164712876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00395216414678111\n",
      "train loss:0.0009345112620015038\n",
      "train loss:0.019611134347370905\n",
      "train loss:0.002152880853579625\n",
      "train loss:0.0034496587680189193\n",
      "train loss:0.012532467633871471\n",
      "train loss:0.0033662884596814763\n",
      "train loss:0.013817061696135035\n",
      "train loss:0.019398721934473416\n",
      "train loss:0.004431960388102149\n",
      "train loss:0.003157511316329619\n",
      "train loss:0.017932268546208205\n",
      "train loss:0.021524581348363325\n",
      "train loss:0.01835011691364162\n",
      "train loss:0.01414227139927059\n",
      "train loss:0.006591064929229769\n",
      "train loss:0.0018355335971195583\n",
      "train loss:0.011578639971878038\n",
      "train loss:0.025089164161547085\n",
      "train loss:0.004577600512066397\n",
      "train loss:0.004667494049190107\n",
      "train loss:0.004195164471283861\n",
      "train loss:0.018754838254408074\n",
      "train loss:0.024085486861994458\n",
      "train loss:0.008254173162886529\n",
      "train loss:0.0158602398511602\n",
      "train loss:0.03845473614029811\n",
      "train loss:0.0033211622292289894\n",
      "train loss:0.006691371917701156\n",
      "train loss:0.0013629635766045861\n",
      "train loss:0.003148297047024839\n",
      "train loss:0.00878533764696678\n",
      "train loss:0.009844401087963688\n",
      "train loss:0.0009139047867024918\n",
      "train loss:0.0011372208883852536\n",
      "train loss:0.0013375400439162412\n",
      "train loss:0.00988360527952172\n",
      "train loss:0.001201936270131698\n",
      "train loss:0.008813739754125319\n",
      "train loss:0.004705396996734987\n",
      "train loss:0.010207799928110516\n",
      "train loss:0.010555530189143816\n",
      "train loss:0.006579184797025718\n",
      "train loss:0.025154449483123748\n",
      "train loss:0.0021274663859195096\n",
      "train loss:0.002040878145068453\n",
      "train loss:0.006215476850255831\n",
      "train loss:0.014702079741205203\n",
      "train loss:0.015428347567220547\n",
      "train loss:0.012156311000569268\n",
      "train loss:0.009086841422812372\n",
      "train loss:0.005324013570205542\n",
      "train loss:0.004191475211209121\n",
      "train loss:0.002920951989262221\n",
      "train loss:0.017552919855236854\n",
      "train loss:0.002709437568243981\n",
      "train loss:0.0021674463607279236\n",
      "train loss:0.012147957772838738\n",
      "train loss:0.0018060320179757632\n",
      "train loss:0.0013957463169191869\n",
      "train loss:0.007219333852904577\n",
      "train loss:0.00553525602646481\n",
      "train loss:0.002694608172423444\n",
      "train loss:0.0031063579338374125\n",
      "train loss:0.002420054964583573\n",
      "train loss:0.004224560232618754\n",
      "train loss:0.0008158450113888211\n",
      "train loss:0.000863640773929566\n",
      "train loss:0.0054052894891583915\n",
      "train loss:0.0037897739251147923\n",
      "train loss:0.06278473383187137\n",
      "train loss:0.012879653523398366\n",
      "train loss:0.029785179179672983\n",
      "train loss:0.0047752410539165175\n",
      "train loss:0.001291653577659428\n",
      "train loss:0.028376599168635566\n",
      "train loss:0.02850280901529667\n",
      "train loss:0.02512506306189163\n",
      "train loss:0.016641675204180008\n",
      "train loss:0.012244038195020884\n",
      "train loss:0.011227134230384066\n",
      "train loss:0.002788598663967434\n",
      "train loss:0.0025385893769221445\n",
      "train loss:0.007479189833300027\n",
      "train loss:0.007378677318139615\n",
      "train loss:0.015237050538399986\n",
      "train loss:0.0032999088083867823\n",
      "train loss:0.0014354097064344976\n",
      "train loss:0.0027139343700415476\n",
      "train loss:0.004181887184693945\n",
      "train loss:0.015908792763899584\n",
      "train loss:0.007764242522633861\n",
      "train loss:0.007311704109231645\n",
      "train loss:0.0233301158274612\n",
      "train loss:0.003835539794510936\n",
      "train loss:0.0019131275208600137\n",
      "train loss:0.033518757171088195\n",
      "train loss:0.0010096214270337326\n",
      "train loss:0.008702937933502396\n",
      "train loss:0.0031684300751098388\n",
      "train loss:0.004826694470988487\n",
      "train loss:0.00392839004730959\n",
      "train loss:0.0033145025691903368\n",
      "train loss:0.0005956095184113242\n",
      "train loss:0.006728444885918508\n",
      "train loss:0.00492508587738328\n",
      "train loss:0.012748601110964956\n",
      "train loss:0.003775424623501916\n",
      "train loss:0.009735035129017067\n",
      "train loss:0.009481671596991042\n",
      "train loss:0.003532832388211912\n",
      "train loss:0.008118096428570656\n",
      "train loss:0.005504291977142745\n",
      "train loss:0.010338015102328561\n",
      "train loss:0.010213609451507425\n",
      "train loss:0.006807191702696028\n",
      "train loss:0.002756546908078099\n",
      "train loss:0.007843353993154839\n",
      "train loss:0.011457990737378592\n",
      "train loss:0.004045745823891241\n",
      "train loss:0.023677516654483855\n",
      "train loss:0.0032208545283513483\n",
      "train loss:0.009704257440192593\n",
      "train loss:0.006047431165484562\n",
      "train loss:0.0033836496657930655\n",
      "train loss:0.007376909249805917\n",
      "train loss:0.021828936906651025\n",
      "train loss:0.013712880883452077\n",
      "train loss:0.0021602080505831052\n",
      "train loss:0.0024301217528483045\n",
      "train loss:0.0020087449856533357\n",
      "train loss:0.005291858659890352\n",
      "train loss:0.0013385545541544283\n",
      "train loss:0.032479887562569205\n",
      "train loss:0.016358230858956328\n",
      "train loss:0.043770888579996475\n",
      "train loss:0.007801911569496963\n",
      "train loss:0.02636658894416052\n",
      "train loss:0.004201596042334917\n",
      "train loss:0.009068505577948346\n",
      "train loss:0.008893383049260352\n",
      "train loss:0.0012057751977150371\n",
      "train loss:0.03563948359354887\n",
      "train loss:0.0024678533235400423\n",
      "train loss:0.01252764928005204\n",
      "train loss:0.0019141079555102022\n",
      "train loss:0.006388360342217348\n",
      "train loss:0.010877834877398553\n",
      "train loss:0.004747220502582045\n",
      "train loss:0.010360226036950346\n",
      "train loss:0.005454089153149827\n",
      "train loss:0.00204421673979208\n",
      "train loss:0.016366209970698476\n",
      "train loss:0.0355152929162162\n",
      "train loss:0.03318938300573238\n",
      "train loss:0.0032679177359494667\n",
      "train loss:0.003536171961972916\n",
      "train loss:0.00460549495114185\n",
      "train loss:0.055693163688326254\n",
      "train loss:0.0025873677132148467\n",
      "train loss:0.010042012630871002\n",
      "train loss:0.001153437016738844\n",
      "train loss:0.004761060623450869\n",
      "train loss:0.003968207823423132\n",
      "train loss:0.005317200904129905\n",
      "train loss:0.0013802248095733213\n",
      "train loss:0.014831627845526123\n",
      "train loss:0.019294390017520976\n",
      "train loss:0.005927899661402505\n",
      "train loss:0.0035704264964092447\n",
      "train loss:0.0078370130258075\n",
      "train loss:0.050858751397456686\n",
      "train loss:0.00703583033563317\n",
      "train loss:0.009174138588271983\n",
      "train loss:0.003691486638906624\n",
      "train loss:0.009333911859010455\n",
      "train loss:0.020437216155637605\n",
      "train loss:0.0347751599092035\n",
      "train loss:0.002348863388764936\n",
      "train loss:0.007830080703097115\n",
      "train loss:0.02250456889612515\n",
      "train loss:0.008238453230074841\n",
      "train loss:0.0038337233933458865\n",
      "train loss:0.01817444058406918\n",
      "train loss:0.047119792518337617\n",
      "train loss:0.005011708723757708\n",
      "train loss:0.006180556256082719\n",
      "train loss:0.0047409421789824146\n",
      "train loss:0.0015783959239343067\n",
      "train loss:0.0019434426461331226\n",
      "train loss:0.015837764509362185\n",
      "train loss:0.01602451145805799\n",
      "train loss:0.00412118307380901\n",
      "=== epoch:10, train acc:0.993, test acc:0.988 ===\n",
      "train loss:0.000894984878038916\n",
      "train loss:0.025517022593989632\n",
      "train loss:0.018305669262831135\n",
      "train loss:0.010009282122741823\n",
      "train loss:0.0053635280642817815\n",
      "train loss:0.01127328173082506\n",
      "train loss:0.03418162787588346\n",
      "train loss:0.008325758171953973\n",
      "train loss:0.0117240627791864\n",
      "train loss:0.028692604488949537\n",
      "train loss:0.019050068402829884\n",
      "train loss:0.006425089766173579\n",
      "train loss:0.003298057974997953\n",
      "train loss:0.002405123115094539\n",
      "train loss:0.008744158962013705\n",
      "train loss:0.01704291424685866\n",
      "train loss:0.0005838794434608768\n",
      "train loss:0.004251974215345138\n",
      "train loss:0.005359259323430394\n",
      "train loss:0.00804506441677497\n",
      "train loss:0.0011169639194140585\n",
      "train loss:0.0047583144203375075\n",
      "train loss:0.01088669310356304\n",
      "train loss:0.011411026294501955\n",
      "train loss:0.0064978265931075595\n",
      "train loss:0.02669851647028877\n",
      "train loss:0.003662363011879729\n",
      "train loss:0.009081094831090972\n",
      "train loss:0.001547038661076381\n",
      "train loss:0.0018131490427539965\n",
      "train loss:0.015115145498166307\n",
      "train loss:0.008294236996174858\n",
      "train loss:0.004048706397023248\n",
      "train loss:0.004445375809346216\n",
      "train loss:0.00479335121645751\n",
      "train loss:0.004210373502003921\n",
      "train loss:0.012209250554001554\n",
      "train loss:0.0014348307805307633\n",
      "train loss:0.0229905888709752\n",
      "train loss:0.020238639280480187\n",
      "train loss:0.029231140196763955\n",
      "train loss:0.004037973640911498\n",
      "train loss:0.005090232794491247\n",
      "train loss:0.00556394119005854\n",
      "train loss:0.00923375726671398\n",
      "train loss:0.004065564810132265\n",
      "train loss:0.01412380800802113\n",
      "train loss:0.003957499413637365\n",
      "train loss:0.00502991019640942\n",
      "train loss:0.0019546842896676075\n",
      "train loss:0.006312015068686755\n",
      "train loss:0.020827230140088426\n",
      "train loss:0.006734372650835331\n",
      "train loss:0.0044054891197050595\n",
      "train loss:0.0033532332898486405\n",
      "train loss:0.002239732144758315\n",
      "train loss:0.0013976326040625845\n",
      "train loss:0.0026790478845426496\n",
      "train loss:0.05607836160720665\n",
      "train loss:0.004635322937903344\n",
      "train loss:0.00884213245547886\n",
      "train loss:0.0010332947726692573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0042938029141479485\n",
      "train loss:0.0053091131608821954\n",
      "train loss:0.006164335416445415\n",
      "train loss:0.056337917872873525\n",
      "train loss:0.014776872082491167\n",
      "train loss:0.0382275404191471\n",
      "train loss:0.00240226336148207\n",
      "train loss:0.00396470169469997\n",
      "train loss:0.006255203548311198\n",
      "train loss:0.010103596377000505\n",
      "train loss:0.004916747067996476\n",
      "train loss:0.004563613518605419\n",
      "train loss:0.005242784968173063\n",
      "train loss:0.0012075222918698884\n",
      "train loss:0.004189761896686422\n",
      "train loss:0.0037915581400296983\n",
      "train loss:0.001654026716439839\n",
      "train loss:0.04119556300262401\n",
      "train loss:0.0005182012858256086\n",
      "train loss:0.0014015936669516025\n",
      "train loss:0.04628091216402206\n",
      "train loss:0.015027632065841427\n",
      "train loss:0.005767772685834811\n",
      "train loss:0.0017574606108961839\n",
      "train loss:0.00199577076780107\n",
      "train loss:0.011664334029927273\n",
      "train loss:0.012530917040825637\n",
      "train loss:0.004637550953840789\n",
      "train loss:0.003280715774149964\n",
      "train loss:0.005962004532009238\n",
      "train loss:0.01118589177467471\n",
      "train loss:0.015003745903642403\n",
      "train loss:0.010191815352896472\n",
      "train loss:0.00764785665237178\n",
      "train loss:0.005845568497960105\n",
      "train loss:0.0011656574008720474\n",
      "train loss:0.008285854137446001\n",
      "train loss:0.0070101236100471795\n",
      "train loss:0.00988287650929961\n",
      "train loss:0.012762933536568908\n",
      "train loss:0.0076481895267718585\n",
      "train loss:0.0070205922754605354\n",
      "train loss:0.01456135686561776\n",
      "train loss:0.005844679693163777\n",
      "train loss:0.006799326460143208\n",
      "train loss:0.00406273951947046\n",
      "train loss:0.004033864558121838\n",
      "train loss:0.007999374590314145\n",
      "train loss:0.003464604980003341\n",
      "train loss:0.009896229789196917\n",
      "train loss:0.0255250378043711\n",
      "train loss:0.01118250880972674\n",
      "train loss:0.02178910959062489\n",
      "train loss:0.0014122316815712872\n",
      "train loss:0.04712924762315289\n",
      "train loss:0.0342682200807538\n",
      "train loss:0.004056009968939972\n",
      "train loss:0.0018430587306589735\n",
      "train loss:0.0001060641199071771\n",
      "train loss:0.003143313372048658\n",
      "train loss:0.02015197070159348\n",
      "train loss:0.00041980640629452797\n",
      "train loss:0.004944883480237234\n",
      "train loss:0.009838498447424786\n",
      "train loss:0.006296664878754193\n",
      "train loss:0.031080838373133707\n",
      "train loss:0.009525276613489522\n",
      "train loss:0.008016511925045992\n",
      "train loss:0.04565333697088575\n",
      "train loss:0.01084588821341085\n",
      "train loss:0.0043445421988001585\n",
      "train loss:0.002202219136092797\n",
      "train loss:0.026292078023535656\n",
      "train loss:0.0020486867312537126\n",
      "train loss:0.013532635555702263\n",
      "train loss:0.003802555266636828\n",
      "train loss:0.008441325121879038\n",
      "train loss:0.012759354756872574\n",
      "train loss:0.008089166537848766\n",
      "train loss:0.007026686173790779\n",
      "train loss:0.003528280589221524\n",
      "train loss:0.005989439861967694\n",
      "train loss:0.006122740823220705\n",
      "train loss:0.0008768259689932109\n",
      "train loss:0.01039728236072871\n",
      "train loss:0.004273718987760354\n",
      "train loss:0.007645153065797616\n",
      "train loss:0.011211173244080212\n",
      "train loss:0.006654822326395672\n",
      "train loss:0.01350693716717136\n",
      "train loss:0.031352247566934485\n",
      "train loss:0.0024992375760695333\n",
      "train loss:0.015545247936021975\n",
      "train loss:0.012194159688744348\n",
      "train loss:0.005193037006122191\n",
      "train loss:0.00433532309094764\n",
      "train loss:0.010445034847416813\n",
      "train loss:0.003186962944928746\n",
      "train loss:0.0008372908687862761\n",
      "train loss:0.004081302343890511\n",
      "train loss:0.004385482999160134\n",
      "train loss:0.0027320273088270114\n",
      "train loss:0.014279824642242358\n",
      "train loss:0.019777609625188444\n",
      "train loss:0.04128214804560117\n",
      "train loss:0.0021954726797993513\n",
      "train loss:0.013613487344715075\n",
      "train loss:0.0009954164508118304\n",
      "train loss:0.0007168563355981672\n",
      "train loss:0.004882294042630776\n",
      "train loss:0.0048676602479332\n",
      "train loss:0.031745551939179294\n",
      "train loss:0.011701667849861444\n",
      "train loss:0.006927831903694159\n",
      "train loss:0.01697357649216531\n",
      "train loss:0.005446360778655821\n",
      "train loss:0.004338005864287965\n",
      "train loss:0.005974741278819877\n",
      "train loss:0.005501732386858653\n",
      "train loss:0.010478712440545428\n",
      "train loss:0.020639407725004628\n",
      "train loss:0.009296810292319612\n",
      "train loss:0.031318023691286674\n",
      "train loss:0.002499227856464569\n",
      "train loss:0.005076561836383037\n",
      "train loss:0.011363926394521162\n",
      "train loss:0.0022550824292340297\n",
      "train loss:0.0025823747677698526\n",
      "train loss:0.003392790977846336\n",
      "train loss:0.03984881300454004\n",
      "train loss:0.004150992694397594\n",
      "train loss:0.026139000828574253\n",
      "train loss:0.00844193013669455\n",
      "train loss:0.005296400341630577\n",
      "train loss:0.005646989891519779\n",
      "train loss:0.015028002930499884\n",
      "train loss:0.021742982601093096\n",
      "train loss:0.0006155485034004073\n",
      "train loss:0.006722919136097361\n",
      "train loss:0.012253346557036342\n",
      "train loss:0.0002692747290753152\n",
      "train loss:0.0038264241274434774\n",
      "train loss:0.011105436651935932\n",
      "train loss:0.017695017128012972\n",
      "train loss:0.0015997871778941882\n",
      "train loss:0.004910504125120583\n",
      "train loss:0.011011542745139536\n",
      "train loss:0.0008624637061810058\n",
      "train loss:0.016195535373779397\n",
      "train loss:0.002745009832372347\n",
      "train loss:0.010230009068222008\n",
      "train loss:0.0023170041001780613\n",
      "train loss:0.004333204979164783\n",
      "train loss:0.004338393121653123\n",
      "train loss:0.009396522297935375\n",
      "train loss:0.010418568615602001\n",
      "train loss:0.019623211170043446\n",
      "train loss:0.001094874976640244\n",
      "train loss:0.01047438513463545\n",
      "train loss:0.007063965283091166\n",
      "train loss:0.010310445709893272\n",
      "train loss:0.006885615200965637\n",
      "train loss:0.012489640315461877\n",
      "train loss:0.002525910533498377\n",
      "train loss:0.0031296551931486306\n",
      "train loss:0.002506940787424328\n",
      "train loss:0.003175619051469098\n",
      "train loss:0.02230354143453877\n",
      "train loss:0.0011811336685890786\n",
      "train loss:0.013562383850412649\n",
      "train loss:0.008588470318163975\n",
      "train loss:0.0025418916541188447\n",
      "train loss:0.0020450890795179143\n",
      "train loss:0.03426204032771898\n",
      "train loss:0.027371300449038825\n",
      "train loss:0.016332270075837613\n",
      "train loss:0.0007965169896785824\n",
      "train loss:0.01554217037459004\n",
      "train loss:0.027917237488659555\n",
      "train loss:0.009642212386221363\n",
      "train loss:0.0017313762599365657\n",
      "train loss:0.0031788393246971187\n",
      "train loss:0.010310628567405618\n",
      "train loss:0.006782725245895293\n",
      "train loss:0.007723081996581934\n",
      "train loss:0.004002340817641966\n",
      "train loss:0.018167405179908586\n",
      "train loss:0.004207547759422213\n",
      "train loss:0.0037622718380963638\n",
      "train loss:0.0009520371009893009\n",
      "train loss:0.0019448061817468984\n",
      "train loss:0.0062046735640953945\n",
      "train loss:0.00649428776196404\n",
      "train loss:0.08684619216952572\n",
      "train loss:0.008053735909813845\n",
      "train loss:0.005622833631620111\n",
      "train loss:0.0029224053455130334\n",
      "train loss:0.006540890685571925\n",
      "train loss:0.00975297093856776\n",
      "train loss:0.00516589154856004\n",
      "train loss:0.014100676330201612\n",
      "train loss:0.0011333611213374692\n",
      "train loss:0.012525739047181555\n",
      "train loss:0.004480364947488857\n",
      "train loss:0.009719893334702778\n",
      "train loss:0.005176380348770105\n",
      "train loss:0.009372822583165796\n",
      "train loss:0.00105608210146594\n",
      "train loss:0.005690042253263933\n",
      "train loss:0.007650755065149917\n",
      "train loss:0.007689656692024065\n",
      "train loss:0.008290719177675286\n",
      "train loss:0.02710983454821421\n",
      "train loss:0.0009091569015326103\n",
      "train loss:0.008196606631742698\n",
      "train loss:0.011452677592040028\n",
      "train loss:0.003504389248706826\n",
      "train loss:0.002391139971222581\n",
      "train loss:0.008525561043500217\n",
      "train loss:0.0013470075672511348\n",
      "train loss:0.015388402009511925\n",
      "train loss:0.014128851772016372\n",
      "train loss:0.012079003444258076\n",
      "train loss:0.005962473342153562\n",
      "train loss:0.007288790932552974\n",
      "train loss:0.04058497778929301\n",
      "train loss:0.0016664703799929065\n",
      "train loss:0.0007742691049865337\n",
      "train loss:0.0025610972584548986\n",
      "train loss:0.018366689570485064\n",
      "train loss:0.019133188721172752\n",
      "train loss:0.0011509164302070955\n",
      "train loss:0.00042253796711587475\n",
      "train loss:0.006058731078749575\n",
      "train loss:0.01185072771985879\n",
      "train loss:0.00832628833383219\n",
      "train loss:0.00596316043725909\n",
      "train loss:0.001880951698160038\n",
      "train loss:0.002400592837853977\n",
      "train loss:0.022775233102895375\n",
      "train loss:0.0032692643203318826\n",
      "train loss:0.0006891096889173391\n",
      "train loss:0.0016605518043437666\n",
      "train loss:0.0016460214755817792\n",
      "train loss:0.006230526266656961\n",
      "train loss:0.004506413490049415\n",
      "train loss:0.006513801627202633\n",
      "train loss:0.002621568578071645\n",
      "train loss:0.004351684305521044\n",
      "train loss:0.006890627002390066\n",
      "train loss:0.02028640253726505\n",
      "train loss:0.001299266396822921\n",
      "train loss:0.001114707417048759\n",
      "train loss:0.026458733511405354\n",
      "train loss:0.024720086247859117\n",
      "train loss:0.0030085144321779756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014864499680043698\n",
      "train loss:0.02654667497507194\n",
      "train loss:0.007873978323992609\n",
      "train loss:0.01846121185258312\n",
      "train loss:0.004715301472415676\n",
      "train loss:0.00045318857398955444\n",
      "train loss:0.0057550925518750325\n",
      "train loss:0.007997801573549\n",
      "train loss:0.0042995457127400485\n",
      "train loss:0.014088733377895174\n",
      "train loss:0.003892414106376087\n",
      "train loss:0.002321698313663025\n",
      "train loss:0.0041347193627482935\n",
      "train loss:0.0132821002935439\n",
      "train loss:0.008170500649591586\n",
      "train loss:0.012095699256835714\n",
      "train loss:0.008981455903389859\n",
      "train loss:0.009027603796761378\n",
      "train loss:0.0003550485198086883\n",
      "train loss:0.025153306269984452\n",
      "train loss:0.0029400107747391707\n",
      "train loss:0.008554934992746214\n",
      "train loss:0.013442116776375681\n",
      "train loss:0.04913077887767808\n",
      "train loss:0.011523055730128098\n",
      "train loss:0.032439263393661606\n",
      "train loss:0.009145275537755416\n",
      "train loss:0.0017391604681912746\n",
      "train loss:0.0036645853697485882\n",
      "train loss:0.02418519821833666\n",
      "train loss:0.003368550963388615\n",
      "train loss:0.003178801606029113\n",
      "train loss:0.0033954516393333977\n",
      "train loss:0.0026513774850901754\n",
      "train loss:0.0012749436261099939\n",
      "train loss:0.010546833271646123\n",
      "train loss:0.020752109008889505\n",
      "train loss:0.0010759472266755096\n",
      "train loss:0.0025606113512355445\n",
      "train loss:0.028246824283136598\n",
      "train loss:0.014081542067811155\n",
      "train loss:0.015177888713478853\n",
      "train loss:0.01571838047793345\n",
      "train loss:0.006122211235397731\n",
      "train loss:0.001748592165768116\n",
      "train loss:0.0063191830063536285\n",
      "train loss:0.03612822473429862\n",
      "train loss:0.028339218848853976\n",
      "train loss:0.001955961000441117\n",
      "train loss:0.003045314596918546\n",
      "train loss:0.0031935713331505706\n",
      "train loss:0.016493575130370114\n",
      "train loss:0.013722474633532591\n",
      "train loss:0.009194138831943876\n",
      "train loss:0.007995620648688927\n",
      "train loss:0.01086774473755875\n",
      "train loss:0.032533717769990596\n",
      "train loss:0.009051617146509592\n",
      "train loss:0.008818580850913365\n",
      "train loss:0.018513619661023103\n",
      "train loss:0.0030256907140104377\n",
      "train loss:0.003549615155422815\n",
      "train loss:0.028034449221301664\n",
      "train loss:0.02908228982064186\n",
      "train loss:0.009413483969874892\n",
      "train loss:0.008582261920089719\n",
      "train loss:0.010746996145996163\n",
      "train loss:0.010277087145671422\n",
      "train loss:0.011757310784768146\n",
      "train loss:0.008527415249449699\n",
      "train loss:0.004317660892259159\n",
      "train loss:0.031014582528639586\n",
      "train loss:0.009673369021670195\n",
      "train loss:0.006126468840497189\n",
      "train loss:0.006667290156064865\n",
      "train loss:0.025666988184930323\n",
      "train loss:0.003146797810645106\n",
      "train loss:0.002648130247283159\n",
      "train loss:0.020433889279258266\n",
      "train loss:0.008268279441643015\n",
      "train loss:0.00593769923288002\n",
      "train loss:0.01031938667937026\n",
      "train loss:0.0010353270749106143\n",
      "train loss:0.0032099727031310336\n",
      "train loss:0.012597887101395193\n",
      "train loss:0.01261351392105422\n",
      "train loss:0.011215450587025727\n",
      "train loss:0.01175623218280693\n",
      "train loss:0.004134883377743724\n",
      "train loss:0.0022797872494177045\n",
      "train loss:0.0022630552020003517\n",
      "train loss:0.015562315324862882\n",
      "train loss:0.009427271533797948\n",
      "train loss:0.009429815065974742\n",
      "train loss:0.005196462423468815\n",
      "train loss:0.004103215397965022\n",
      "train loss:0.04023304821195157\n",
      "train loss:0.0012859950006186619\n",
      "train loss:0.004118819520291589\n",
      "train loss:0.0008585788835380173\n",
      "train loss:0.013529217803466928\n",
      "train loss:0.0036363797746045844\n",
      "train loss:0.028260857976410477\n",
      "train loss:0.003908555211408048\n",
      "train loss:0.002345416870898608\n",
      "train loss:0.0008738858987009463\n",
      "train loss:0.004463551251038368\n",
      "train loss:0.031752527153293\n",
      "train loss:0.004195597787685235\n",
      "train loss:0.0008837089858829497\n",
      "train loss:0.002231139531210048\n",
      "train loss:0.0031630941995950917\n",
      "train loss:0.0032153521427167615\n",
      "train loss:0.004349587991699541\n",
      "train loss:0.004928713568680228\n",
      "train loss:0.01573434334230859\n",
      "train loss:0.0014217838296122782\n",
      "train loss:0.003183491163803191\n",
      "train loss:0.0025449661910756554\n",
      "train loss:0.0034414801798243033\n",
      "train loss:0.023139673356800804\n",
      "train loss:0.006065995316538148\n",
      "train loss:0.004800952803596433\n",
      "train loss:0.011968544791537947\n",
      "train loss:0.010969413232063458\n",
      "train loss:0.0014827135031313821\n",
      "train loss:0.002099178387840658\n",
      "train loss:0.004136249116209319\n",
      "train loss:0.00045983231982534847\n",
      "train loss:0.019432641559598927\n",
      "train loss:0.009858432123993396\n",
      "train loss:0.0009580767727678616\n",
      "train loss:0.001210330737388917\n",
      "train loss:0.008767575190012067\n",
      "train loss:0.001362695782669836\n",
      "train loss:0.010118490507271722\n",
      "train loss:0.001164475830916177\n",
      "train loss:0.0053169158808685476\n",
      "train loss:0.0026512240984895917\n",
      "train loss:0.0006920625495432236\n",
      "train loss:0.00491555654325306\n",
      "train loss:0.03403142820468597\n",
      "train loss:0.006388985687396282\n",
      "train loss:0.007453030728192014\n",
      "train loss:0.00424678182727551\n",
      "train loss:0.002556519270666772\n",
      "train loss:0.0019576873427010534\n",
      "train loss:0.0029340499601881744\n",
      "train loss:0.0004865230473913627\n",
      "train loss:0.0035824173991601833\n",
      "train loss:0.0016229441150540163\n",
      "train loss:0.004027067565473095\n",
      "train loss:0.023415000627983976\n",
      "train loss:0.005630849595653652\n",
      "train loss:0.0003419396987657595\n",
      "train loss:0.002689322417086264\n",
      "train loss:0.003141536970208049\n",
      "train loss:0.002203748809240958\n",
      "train loss:0.00024397826220679978\n",
      "train loss:0.0013210126636977538\n",
      "train loss:0.0035911901765923325\n",
      "train loss:0.026082834666402613\n",
      "train loss:0.0003508382682970228\n",
      "train loss:0.0034437159259832054\n",
      "train loss:0.0024629771848082697\n",
      "train loss:0.0014923102614272106\n",
      "train loss:0.0008066344837527667\n",
      "train loss:0.015247925698949323\n",
      "train loss:0.008447652620105484\n",
      "train loss:0.014186214041165233\n",
      "train loss:0.0018500839506148817\n",
      "train loss:0.002391125692776317\n",
      "train loss:0.0075046498450769316\n",
      "train loss:0.0044605814085618605\n",
      "train loss:0.003234294330759193\n",
      "train loss:0.009821585717442115\n",
      "train loss:0.005842050289679489\n",
      "train loss:0.0023902416336612714\n",
      "train loss:0.005700659572233689\n",
      "train loss:0.012722677140264706\n",
      "train loss:0.0029135088393749324\n",
      "train loss:0.0033590615690463673\n",
      "train loss:0.0031312465509245905\n",
      "train loss:0.004058257224020911\n",
      "train loss:0.010412273299310064\n",
      "train loss:0.010064084794872943\n",
      "train loss:0.013746517155376907\n",
      "train loss:0.0038408980669223584\n",
      "train loss:0.000419530905917083\n",
      "train loss:0.009098720158778429\n",
      "train loss:0.002358970112855012\n",
      "train loss:0.01409514657859066\n",
      "train loss:0.00692350551449356\n",
      "train loss:0.002206427141707984\n",
      "train loss:0.0041258484187138185\n",
      "train loss:0.0011519159005958233\n",
      "train loss:0.008664054966850203\n",
      "train loss:0.16364614543235742\n",
      "train loss:0.004973807959142761\n",
      "train loss:0.014838083135986824\n",
      "train loss:0.0042865404331052905\n",
      "train loss:0.0028643692144175725\n",
      "train loss:0.003051912561884334\n",
      "train loss:0.006280957928654941\n",
      "train loss:0.0012257264610589383\n",
      "train loss:0.006239559744605273\n",
      "train loss:0.0019292024328857924\n",
      "train loss:0.006935380969416015\n",
      "train loss:0.021906910616342826\n",
      "train loss:0.011267532771613105\n",
      "train loss:0.00450507191836453\n",
      "train loss:0.007361546018111966\n",
      "train loss:0.0030788307169746267\n",
      "train loss:0.006496073784972246\n",
      "train loss:0.01458052271197314\n",
      "train loss:0.01140536287123627\n",
      "train loss:0.0812407571218619\n",
      "train loss:0.03820162169673101\n",
      "train loss:0.0005936689994456972\n",
      "train loss:0.01913011644681438\n",
      "train loss:0.007491494497290138\n",
      "train loss:0.007939299302263026\n",
      "train loss:0.0025332445271943997\n",
      "train loss:0.0015235062944071783\n",
      "train loss:0.0066242461342958196\n",
      "train loss:0.012634389099898353\n",
      "train loss:0.006057276710299812\n",
      "train loss:0.002291649557001078\n",
      "train loss:0.015497341168405702\n",
      "train loss:0.005251442086235268\n",
      "train loss:0.0023142543384582276\n",
      "train loss:0.0060897862975705375\n",
      "train loss:0.0029623398220564572\n",
      "train loss:0.001380110530442892\n",
      "train loss:0.05731913893106911\n",
      "train loss:0.005354625052125134\n",
      "train loss:0.011505693801210018\n",
      "train loss:0.003816528085889543\n",
      "train loss:0.019068408341942965\n",
      "train loss:0.003484351856586662\n",
      "train loss:0.005186337554542781\n",
      "train loss:0.0004925724438885664\n",
      "train loss:0.003029256133518345\n",
      "train loss:0.016569169418149957\n",
      "train loss:0.008937878632614091\n",
      "train loss:0.006859398600158597\n",
      "train loss:0.014036079501741594\n",
      "train loss:0.0014898676539087754\n",
      "train loss:0.0031158932023382987\n",
      "train loss:0.00490107978714387\n",
      "train loss:0.0009804446128065557\n",
      "train loss:0.018051151875685907\n",
      "train loss:0.010766404882930975\n",
      "train loss:0.011139797267125636\n",
      "train loss:0.0033929711184275896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012707031129200641\n",
      "train loss:0.009591011981416061\n",
      "train loss:0.006394293373766423\n",
      "train loss:0.012403446924291154\n",
      "train loss:0.007089493851765561\n",
      "train loss:0.00810884725834379\n",
      "train loss:0.010122930778618821\n",
      "train loss:0.005134401895864701\n",
      "train loss:0.0021358958414976164\n",
      "train loss:0.005516227017201522\n",
      "train loss:0.0056267292194359655\n",
      "train loss:0.01237338070867852\n",
      "train loss:0.0036140064286192715\n",
      "train loss:0.001267568489497712\n",
      "train loss:0.010342843361281398\n",
      "train loss:0.002101271317877644\n",
      "train loss:0.006311132689427917\n",
      "train loss:0.0042950605685500125\n",
      "train loss:0.0013686414990258771\n",
      "train loss:0.003272928522769331\n",
      "train loss:0.0026626027415231008\n",
      "train loss:0.0008949255920358392\n",
      "train loss:0.02013460805065993\n",
      "train loss:0.0046994960941759804\n",
      "train loss:0.0024823138370941166\n",
      "train loss:0.00507136077732661\n",
      "train loss:0.0018613099287621423\n",
      "=== epoch:11, train acc:0.998, test acc:0.983 ===\n",
      "train loss:0.006048015934865551\n",
      "train loss:0.006369956899842216\n",
      "train loss:0.01040301942323953\n",
      "train loss:0.007510697251154257\n",
      "train loss:0.001542562900766451\n",
      "train loss:0.027479855217879646\n",
      "train loss:0.003289354502038303\n",
      "train loss:0.011560198250795241\n",
      "train loss:0.0013767231141180952\n",
      "train loss:0.00037324654079859393\n",
      "train loss:0.044972422213999934\n",
      "train loss:0.016771418534699375\n",
      "train loss:0.0015007044748864395\n",
      "train loss:0.003481521943890639\n",
      "train loss:0.003181952158184124\n",
      "train loss:0.0024286805913697885\n",
      "train loss:0.0015898275444682685\n",
      "train loss:0.029176523200473467\n",
      "train loss:0.04148111532368369\n",
      "train loss:0.006887771832036339\n",
      "train loss:0.009944178247035354\n",
      "train loss:0.00960575177248643\n",
      "train loss:0.031361657091517676\n",
      "train loss:0.004799709843133655\n",
      "train loss:0.010496925668080841\n",
      "train loss:0.0035990026903130233\n",
      "train loss:0.006466645284812993\n",
      "train loss:0.0009083523789320725\n",
      "train loss:0.0015424686842272623\n",
      "train loss:0.0051945823078203114\n",
      "train loss:0.008741861876314134\n",
      "train loss:0.0010202567873957684\n",
      "train loss:0.031197822912288\n",
      "train loss:0.08586899489267383\n",
      "train loss:0.002438845721349872\n",
      "train loss:0.0017519073329478607\n",
      "train loss:0.006542616482863069\n",
      "train loss:0.014967711366203536\n",
      "train loss:0.012240392470226949\n",
      "train loss:0.023522848416476606\n",
      "train loss:0.006346217336863262\n",
      "train loss:0.007577715153619175\n",
      "train loss:0.0024667406990327937\n",
      "train loss:0.009102570122760775\n",
      "train loss:0.013760145352918845\n",
      "train loss:0.002970961192369121\n",
      "train loss:0.0008044205732439347\n",
      "train loss:0.017012645826038442\n",
      "train loss:0.003278698624578294\n",
      "train loss:0.0037017939729569443\n",
      "train loss:0.007242386175118988\n",
      "train loss:0.003920058749977605\n",
      "train loss:0.005048521727874165\n",
      "train loss:0.002247583378933743\n",
      "train loss:0.007636912253089515\n",
      "train loss:0.004670710362795264\n",
      "train loss:0.002347592094039534\n",
      "train loss:0.002749808094754147\n",
      "train loss:0.0008007348257418404\n",
      "train loss:0.0036255783755443716\n",
      "train loss:0.0027206068735710037\n",
      "train loss:0.00391901291663387\n",
      "train loss:0.0021055778728859063\n",
      "train loss:0.0010173731205881478\n",
      "train loss:0.010232680093448803\n",
      "train loss:0.02948169582671473\n",
      "train loss:0.005864719728228191\n",
      "train loss:0.015202849201100543\n",
      "train loss:0.010117796137549144\n",
      "train loss:0.0053665114166834135\n",
      "train loss:0.013631447812906743\n",
      "train loss:0.008877600750485128\n",
      "train loss:0.0025977789615285614\n",
      "train loss:0.015396085928068506\n",
      "train loss:0.009671934608113258\n",
      "train loss:0.0017573568005693541\n",
      "train loss:0.007236965756671705\n",
      "train loss:0.003551056635240968\n",
      "train loss:0.0061112473537161946\n",
      "train loss:0.0011253598298277968\n",
      "train loss:0.006627621014642249\n",
      "train loss:0.006292977798377783\n",
      "train loss:0.0059583289878401766\n",
      "train loss:0.01698849449792954\n",
      "train loss:0.0036651494953090324\n",
      "train loss:0.008817788558940524\n",
      "train loss:0.010932172356279473\n",
      "train loss:0.007054712166448458\n",
      "train loss:0.0013764714396995441\n",
      "train loss:0.0047291570119351225\n",
      "train loss:0.015507669162118884\n",
      "train loss:0.005807731653663365\n",
      "train loss:0.058495636108792944\n",
      "train loss:0.0006750983449133241\n",
      "train loss:0.007498228349026076\n",
      "train loss:0.002566349237368325\n",
      "train loss:0.01149210471469111\n",
      "train loss:0.0030626215119509883\n",
      "train loss:0.002379677752529628\n",
      "train loss:0.0014618820590600223\n",
      "train loss:0.002252639824527873\n",
      "train loss:0.004443389497817959\n",
      "train loss:0.051676465529392895\n",
      "train loss:0.0032029060770397398\n",
      "train loss:0.0033268369757738646\n",
      "train loss:0.03560070367305054\n",
      "train loss:0.01170212877828214\n",
      "train loss:0.003509605921206041\n",
      "train loss:0.008332403274324244\n",
      "train loss:0.010517224888560021\n",
      "train loss:0.004267240634719306\n",
      "train loss:0.0012036579220289863\n",
      "train loss:0.01044022139876401\n",
      "train loss:0.002372492440666209\n",
      "train loss:0.0010326428136446303\n",
      "train loss:0.021073462624882175\n",
      "train loss:0.0009641125153961261\n",
      "train loss:0.005289312454894342\n",
      "train loss:0.006374134052134187\n",
      "train loss:0.0009379049677087311\n",
      "train loss:0.004799465520834157\n",
      "train loss:0.0012122193688299812\n",
      "train loss:0.004356838771632446\n",
      "train loss:0.009854276998829887\n",
      "train loss:0.001936894957440451\n",
      "train loss:0.0006677681955527947\n",
      "train loss:0.014288931875459245\n",
      "train loss:0.0007926297876116838\n",
      "train loss:0.001836034816451401\n",
      "train loss:0.0030982608048545058\n",
      "train loss:0.008660245085412738\n",
      "train loss:0.00331219238302042\n",
      "train loss:0.002240073831932686\n",
      "train loss:0.03868042716863864\n",
      "train loss:0.0030747920275148583\n",
      "train loss:0.022933981789003383\n",
      "train loss:0.0004905483817278165\n",
      "train loss:0.009580551973304718\n",
      "train loss:0.000648310925894913\n",
      "train loss:0.0014168274617459824\n",
      "train loss:0.0035325304034526505\n",
      "train loss:0.005592740959823464\n",
      "train loss:0.0011349532473926551\n",
      "train loss:0.0019208967744747106\n",
      "train loss:0.0029521368507039445\n",
      "train loss:0.001912106310282124\n",
      "train loss:0.003965595665732794\n",
      "train loss:0.015025491653233827\n",
      "train loss:0.0234278172849178\n",
      "train loss:0.01143352601545448\n",
      "train loss:0.0015281230154987533\n",
      "train loss:0.007987686235772925\n",
      "train loss:0.0007038702349833361\n",
      "train loss:0.005861124766385602\n",
      "train loss:0.0038644164871819487\n",
      "train loss:0.0008569433890067438\n",
      "train loss:0.004246315577340858\n",
      "train loss:0.003074102190660804\n",
      "train loss:0.0015040958809539678\n",
      "train loss:0.007797367829317852\n",
      "train loss:0.0024608650489239057\n",
      "train loss:0.0059083802814913775\n",
      "train loss:0.006931795263738542\n",
      "train loss:0.005325526429361675\n",
      "train loss:0.007666147445967553\n",
      "train loss:0.0008474793359725837\n",
      "train loss:0.0015443241946301507\n",
      "train loss:0.008202217910661865\n",
      "train loss:0.007786328954636832\n",
      "train loss:0.057748670865068796\n",
      "train loss:0.007052943098517467\n",
      "train loss:0.0019512797503575098\n",
      "train loss:0.014503724290935929\n",
      "train loss:0.009493693084268123\n",
      "train loss:0.001066359555025726\n",
      "train loss:0.0052939116331103386\n",
      "train loss:0.0046702211671208835\n",
      "train loss:0.004471865036744649\n",
      "train loss:0.004279029167855454\n",
      "train loss:0.015792056736852616\n",
      "train loss:0.0027982035185178046\n",
      "train loss:0.04829208176140044\n",
      "train loss:0.010122094811880231\n",
      "train loss:0.0026040586571062356\n",
      "train loss:0.0077225759955850785\n",
      "train loss:0.0034998136857946806\n",
      "train loss:0.0016996103299184641\n",
      "train loss:0.012831038645728304\n",
      "train loss:0.0028237775139165595\n",
      "train loss:0.0017197625269281902\n",
      "train loss:0.002097872921243092\n",
      "train loss:0.0038773936578622033\n",
      "train loss:0.0027307621282001648\n",
      "train loss:0.014995840838933152\n",
      "train loss:0.010758744580198674\n",
      "train loss:0.005227300875605554\n",
      "train loss:0.005293339003894386\n",
      "train loss:0.0028493380981338924\n",
      "train loss:0.0011069813993934967\n",
      "train loss:0.007578911143849928\n",
      "train loss:0.00619052246910978\n",
      "train loss:0.007298219851153044\n",
      "train loss:0.012373490445506688\n",
      "train loss:0.009441789061399425\n",
      "train loss:0.005537298590638772\n",
      "train loss:0.0011802417090714422\n",
      "train loss:0.002086275407686797\n",
      "train loss:0.0024739264053517717\n",
      "train loss:0.0010943596421639757\n",
      "train loss:0.006474240040510305\n",
      "train loss:0.001947513760188895\n",
      "train loss:0.0029035494002313533\n",
      "train loss:0.00143467366617323\n",
      "train loss:0.0008190890343859204\n",
      "train loss:0.008705007150508403\n",
      "train loss:0.011000777396638278\n",
      "train loss:0.0372103194968585\n",
      "train loss:0.00908463720764226\n",
      "train loss:0.0002504879286620038\n",
      "train loss:0.0008506146736475891\n",
      "train loss:0.0007459593460195825\n",
      "train loss:0.005572400323565846\n",
      "train loss:0.001790380622000779\n",
      "train loss:0.009236540195812402\n",
      "train loss:0.004818666053446245\n",
      "train loss:0.0033993712583490626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018680665010444287\n",
      "train loss:0.00420273569326635\n",
      "train loss:0.004013868510990386\n",
      "train loss:0.052673857937884414\n",
      "train loss:0.04180497840745783\n",
      "train loss:0.0010759137863296509\n",
      "train loss:0.013686421425602257\n",
      "train loss:0.0023430459944029053\n",
      "train loss:0.003973290204671545\n",
      "train loss:0.02815896016230555\n",
      "train loss:0.006762701672937768\n",
      "train loss:0.00288192262982568\n",
      "train loss:0.004276510460592234\n",
      "train loss:0.002068598901553843\n",
      "train loss:0.006119925776431643\n",
      "train loss:0.013721063427205154\n",
      "train loss:0.006121794948181364\n",
      "train loss:0.002230604461851097\n",
      "train loss:0.0011986282909392338\n",
      "train loss:0.0034011986492181166\n",
      "train loss:0.002745891135667517\n",
      "train loss:0.019873235254545412\n",
      "train loss:0.0021855416759988837\n",
      "train loss:0.005414176261738354\n",
      "train loss:0.009948065150057092\n",
      "train loss:0.009799295371578549\n",
      "train loss:0.0036056220013766615\n",
      "train loss:0.02745365616199609\n",
      "train loss:0.0022713843923360525\n",
      "train loss:0.004406407969006058\n",
      "train loss:0.006858609899465859\n",
      "train loss:0.013114889449140594\n",
      "train loss:0.008121427557488015\n",
      "train loss:0.0039902825707482555\n",
      "train loss:0.000741604184367922\n",
      "train loss:0.017030014051251655\n",
      "train loss:0.0027243269349480465\n",
      "train loss:0.0010109943450720652\n",
      "train loss:0.0043035924072531324\n",
      "train loss:0.002724243429427483\n",
      "train loss:0.007749276680580866\n",
      "train loss:0.0020159948990009016\n",
      "train loss:0.016127632570580402\n",
      "train loss:0.0006942208669142109\n",
      "train loss:0.003268986012271748\n",
      "train loss:0.020479177448159837\n",
      "train loss:0.0062865004217200916\n",
      "train loss:0.01723565447134083\n",
      "train loss:0.0051764229876662985\n",
      "train loss:0.0014631492997585118\n",
      "train loss:0.0038389909079364227\n",
      "train loss:0.0065001352153844835\n",
      "train loss:0.0028943743743433674\n",
      "train loss:0.002307723372564411\n",
      "train loss:0.001588118130016774\n",
      "train loss:0.002119376174575528\n",
      "train loss:0.005295647085428508\n",
      "train loss:0.002360064300843936\n",
      "train loss:0.0011594736906608365\n",
      "train loss:0.002367452307367641\n",
      "train loss:0.004065396744963283\n",
      "train loss:0.0008033481505835868\n",
      "train loss:0.0012480879457441578\n",
      "train loss:0.0015885382061554194\n",
      "train loss:0.0034855338286449715\n",
      "train loss:0.0029233393442525267\n",
      "train loss:0.00041371119369992154\n",
      "train loss:0.0018944076768745164\n",
      "train loss:0.003319810877996495\n",
      "train loss:0.003861369392716902\n",
      "train loss:0.004294448294785107\n",
      "train loss:0.000998452000851603\n",
      "train loss:0.013462739826250333\n",
      "train loss:0.0008927767453891139\n",
      "train loss:0.007309716812886802\n",
      "train loss:0.003325420264084414\n",
      "train loss:0.001939590900307985\n",
      "train loss:0.005440048959274099\n",
      "train loss:0.013668237090284228\n",
      "train loss:0.0018000421021560297\n",
      "train loss:0.00192160699064953\n",
      "train loss:0.001688830728078571\n",
      "train loss:0.0016297626317287905\n",
      "train loss:0.002048465765687429\n",
      "train loss:0.0008406693002456109\n",
      "train loss:0.003501940618760444\n",
      "train loss:0.028308107598340272\n",
      "train loss:0.0003675735273345238\n",
      "train loss:0.0021884288100004466\n",
      "train loss:0.001998600890920881\n",
      "train loss:0.015251500047194217\n",
      "train loss:0.003866785859506229\n",
      "train loss:0.0020051416568889133\n",
      "train loss:0.0007896708257219961\n",
      "train loss:0.0365792512967326\n",
      "train loss:0.002034546915258519\n",
      "train loss:0.014172141886420332\n",
      "train loss:0.014539569907742703\n",
      "train loss:0.004205541419399822\n",
      "train loss:0.003632315864184622\n",
      "train loss:0.004724761234099245\n",
      "train loss:0.015743153780670826\n",
      "train loss:0.0007273884803865925\n",
      "train loss:0.008501070800091673\n",
      "train loss:0.010758130061106682\n",
      "train loss:0.0034859722534027727\n",
      "train loss:0.010759652128742754\n",
      "train loss:0.005446702888428745\n",
      "train loss:0.0027985032588166907\n",
      "train loss:0.0039354039901826725\n",
      "train loss:0.0031115624677155356\n",
      "train loss:0.004419789750066343\n",
      "train loss:0.0038175276863661872\n",
      "train loss:0.005765159300706706\n",
      "train loss:0.003191869774845687\n",
      "train loss:0.0018786445736145997\n",
      "train loss:0.005492949379827226\n",
      "train loss:0.02681032437835226\n",
      "train loss:0.004076877931963676\n",
      "train loss:0.002442919748241515\n",
      "train loss:0.0009779255497452972\n",
      "train loss:0.0011293587721258101\n",
      "train loss:0.0026184443586971416\n",
      "train loss:0.015035023468411656\n",
      "train loss:0.0014130221336778814\n",
      "train loss:0.005743947479070072\n",
      "train loss:0.007408698952723482\n",
      "train loss:0.024926677569952527\n",
      "train loss:0.011338777123062886\n",
      "train loss:0.0030846160713095174\n",
      "train loss:0.029165382817591082\n",
      "train loss:0.005024418913086236\n",
      "train loss:0.0033638265360861675\n",
      "train loss:0.002675013471992913\n",
      "train loss:0.01103982313592193\n",
      "train loss:0.005665917137880364\n",
      "train loss:0.001447988103344131\n",
      "train loss:0.00862546695567664\n",
      "train loss:0.010282723394722524\n",
      "train loss:0.008169631800109803\n",
      "train loss:0.0031565902971452727\n",
      "train loss:0.01743837638916919\n",
      "train loss:0.004585078190899799\n",
      "train loss:0.014452713498673919\n",
      "train loss:0.009886981590847187\n",
      "train loss:0.024333285217124655\n",
      "train loss:0.0038164898486629365\n",
      "train loss:0.011316841577493922\n",
      "train loss:0.00016641387810834517\n",
      "train loss:0.0032156336492394277\n",
      "train loss:0.02499387066760464\n",
      "train loss:0.008806800861132466\n",
      "train loss:0.0038455643162391318\n",
      "train loss:0.030918615073396286\n",
      "train loss:0.00029488211629837295\n",
      "train loss:0.0032373262098019267\n",
      "train loss:0.003988900795449306\n",
      "train loss:0.0015860761515122715\n",
      "train loss:0.0029417782467851443\n",
      "train loss:0.009051040676866686\n",
      "train loss:0.003583972195688742\n",
      "train loss:0.01092665155635912\n",
      "train loss:0.006605012754536808\n",
      "train loss:0.023258352453166323\n",
      "train loss:0.0005584005061544467\n",
      "train loss:0.0013975227383507406\n",
      "train loss:0.0024510940441905362\n",
      "train loss:0.004696333506538911\n",
      "train loss:0.0084978695786593\n",
      "train loss:0.0009806450356338514\n",
      "train loss:0.008233734581493131\n",
      "train loss:0.0073407125615081855\n",
      "train loss:0.011155527065443406\n",
      "train loss:0.0036093538993452095\n",
      "train loss:0.006733064789876819\n",
      "train loss:0.008645821073383363\n",
      "train loss:0.0007735978908137462\n",
      "train loss:0.005866804371675309\n",
      "train loss:0.008526680027805333\n",
      "train loss:0.002650231550017322\n",
      "train loss:0.0024892661510920334\n",
      "train loss:0.0014597130639925605\n",
      "train loss:0.005264505938591009\n",
      "train loss:0.0004885638972784064\n",
      "train loss:0.0043182071579218355\n",
      "train loss:0.019173746231666115\n",
      "train loss:0.007877182028660633\n",
      "train loss:0.012578337437361429\n",
      "train loss:0.0034074862323232903\n",
      "train loss:0.008873548147732079\n",
      "train loss:0.0024582104500320227\n",
      "train loss:0.02147690057688153\n",
      "train loss:0.015329235487496247\n",
      "train loss:0.0013734156152053843\n",
      "train loss:0.0010475040863180923\n",
      "train loss:0.006782571652104428\n",
      "train loss:0.0040315400977001545\n",
      "train loss:0.009449486557734772\n",
      "train loss:0.00037085359708041444\n",
      "train loss:0.005381466698701614\n",
      "train loss:0.010942281953594262\n",
      "train loss:0.012684287170451131\n",
      "train loss:0.012528876513304367\n",
      "train loss:0.005598083313563868\n",
      "train loss:0.0016645775520019357\n",
      "train loss:0.001221748700979603\n",
      "train loss:0.011196174219165593\n",
      "train loss:0.007912722471028913\n",
      "train loss:0.005812400771399266\n",
      "train loss:0.002439896358131813\n",
      "train loss:0.015984236202260253\n",
      "train loss:0.0031458279534597204\n",
      "train loss:0.000497661157808342\n",
      "train loss:0.0552791868215323\n",
      "train loss:0.0014506871358290247\n",
      "train loss:0.003612734095523885\n",
      "train loss:0.02234663002343645\n",
      "train loss:0.002639561326733389\n",
      "train loss:0.0014609981427128695\n",
      "train loss:0.0007102734741011427\n",
      "train loss:0.0001684345017682483\n",
      "train loss:0.014838140074326305\n",
      "train loss:0.0029593678999018298\n",
      "train loss:0.002511326888506601\n",
      "train loss:0.01644833395548837\n",
      "train loss:0.010928852771845497\n",
      "train loss:0.0021352165403499598\n",
      "train loss:0.003045445467472801\n",
      "train loss:0.0007205225196243354\n",
      "train loss:0.006480960702355861\n",
      "train loss:0.004474066004479366\n",
      "train loss:0.0047652558507014905\n",
      "train loss:0.003677753347260745\n",
      "train loss:0.0046810026816318075\n",
      "train loss:0.0034773643422489\n",
      "train loss:0.004517466082419855\n",
      "train loss:0.0028904511992980954\n",
      "train loss:0.004883532473578233\n",
      "train loss:0.010910591977707858\n",
      "train loss:0.0053309119778175195\n",
      "train loss:0.014797530513588874\n",
      "train loss:0.000734671646404474\n",
      "train loss:0.0008539732421467373\n",
      "train loss:0.00799296063272129\n",
      "train loss:0.00134459622514739\n",
      "train loss:0.01055391663345865\n",
      "train loss:0.024606475877458435\n",
      "train loss:0.0011037649179063734\n",
      "train loss:0.0002639090877197645\n",
      "train loss:0.0014567487634228595\n",
      "train loss:0.007654155408687068\n",
      "train loss:0.004061980359244053\n",
      "train loss:0.0018163752086048945\n",
      "train loss:0.008438563680646377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00782946468290857\n",
      "train loss:0.00863858728813826\n",
      "train loss:0.0004891530410694254\n",
      "train loss:0.004633994092037581\n",
      "train loss:0.0067379482024920116\n",
      "train loss:0.17131225487248475\n",
      "train loss:0.0005260221970332592\n",
      "train loss:0.006013560010130758\n",
      "train loss:0.02675890318991568\n",
      "train loss:0.005565206938775385\n",
      "train loss:0.008706339850146218\n",
      "train loss:0.0028028047940210766\n",
      "train loss:0.006880954641192382\n",
      "train loss:0.0038311763347334254\n",
      "train loss:0.0012339801862205884\n",
      "train loss:0.005109778877450335\n",
      "train loss:0.01101886934255938\n",
      "train loss:0.014331996186751288\n",
      "train loss:0.0057189290995302185\n",
      "train loss:0.006435811575244274\n",
      "train loss:0.004244058078051242\n",
      "train loss:0.0026243395072302962\n",
      "train loss:0.006120936061547722\n",
      "train loss:0.009112759890612042\n",
      "train loss:0.0013644658049678429\n",
      "train loss:0.026366235284733162\n",
      "train loss:0.0024713700930455054\n",
      "train loss:0.0012145096649925676\n",
      "train loss:0.003484580753229444\n",
      "train loss:0.0016420367512761421\n",
      "train loss:0.010007712287288391\n",
      "train loss:0.0005554674486858056\n",
      "train loss:0.0047621590849357956\n",
      "train loss:0.005047269137835434\n",
      "train loss:0.0023351113016652904\n",
      "train loss:0.0006583387759923293\n",
      "train loss:0.00384980660220564\n",
      "train loss:0.0022836918699800407\n",
      "train loss:0.0008576550572602131\n",
      "train loss:0.005492125882443252\n",
      "train loss:0.01214989998360952\n",
      "train loss:0.007248719240912234\n",
      "train loss:0.009517901852537647\n",
      "train loss:0.014909569014579233\n",
      "train loss:0.005146160016260579\n",
      "train loss:0.011344094406953498\n",
      "train loss:0.0012720437107183083\n",
      "train loss:0.0021784640836905\n",
      "train loss:0.0013811205266062079\n",
      "train loss:0.0010228231030889115\n",
      "train loss:0.0009002926719128156\n",
      "train loss:0.007266842323252663\n",
      "train loss:0.007160756051387381\n",
      "train loss:0.008379363275976208\n",
      "train loss:0.008555573069853458\n",
      "train loss:0.0018606501860075192\n",
      "train loss:0.005249309349421273\n",
      "train loss:0.0012428800356464615\n",
      "train loss:0.003359990101663956\n",
      "train loss:0.006949905993636478\n",
      "train loss:0.00034781892472261273\n",
      "train loss:0.0010721201818970913\n",
      "train loss:0.0023152767529798506\n",
      "train loss:0.11659440372531532\n",
      "train loss:0.03083903521869159\n",
      "train loss:0.006926634089810968\n",
      "train loss:0.0008168823712165256\n",
      "train loss:0.004470236130002873\n",
      "train loss:0.0029064645324950416\n",
      "train loss:0.07722379116884812\n",
      "train loss:0.003873269635206225\n",
      "train loss:0.003188598861345406\n",
      "train loss:0.0010277706790278618\n",
      "train loss:0.002600708670553378\n",
      "train loss:0.009024694749793777\n",
      "train loss:0.004226234121804134\n",
      "train loss:0.013227803069824497\n",
      "train loss:0.07381480904703853\n",
      "train loss:0.01619487222434548\n",
      "train loss:0.004771894551231885\n",
      "train loss:0.014742699450425896\n",
      "train loss:0.005952062156618887\n",
      "train loss:0.003523809209015783\n",
      "train loss:0.0053169089849599525\n",
      "train loss:0.0011016799660847037\n",
      "train loss:0.0035427169756366843\n",
      "train loss:0.006569687108609001\n",
      "train loss:0.002126377092390505\n",
      "train loss:0.0018270391613128562\n",
      "train loss:0.0043977596534508275\n",
      "train loss:0.004914243167107839\n",
      "train loss:0.002437541081783886\n",
      "train loss:0.0004774394213173936\n",
      "train loss:0.0023526187469104596\n",
      "train loss:0.02445149722867239\n",
      "train loss:0.003692791522930618\n",
      "train loss:0.0044571924793676354\n",
      "train loss:0.0033335304728494765\n",
      "train loss:0.005084683425693775\n",
      "train loss:0.0003882266437804998\n",
      "train loss:0.00926233153594405\n",
      "train loss:0.006411458710116986\n",
      "train loss:0.01160567785022197\n",
      "train loss:0.02266852858994831\n",
      "train loss:0.013982546209226043\n",
      "train loss:0.001985390523250128\n",
      "train loss:0.002344712305087902\n",
      "train loss:0.023037234181018842\n",
      "train loss:0.005729148608451169\n",
      "train loss:0.02158752109831354\n",
      "train loss:0.0010986669574610717\n",
      "train loss:0.004360422571895528\n",
      "train loss:0.01260683764119575\n",
      "train loss:0.0009640504723819397\n",
      "train loss:0.004408461748515276\n",
      "train loss:0.00042904568850763206\n",
      "train loss:0.004684628266734975\n",
      "train loss:0.005434445055376403\n",
      "train loss:0.007437521356046953\n",
      "train loss:0.0051742501518769034\n",
      "=== epoch:12, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0007566549941507666\n",
      "train loss:0.006821852954621463\n",
      "train loss:0.021015080912588593\n",
      "train loss:0.0019266194970378172\n",
      "train loss:0.0020560209969303924\n",
      "train loss:0.0019927515540029243\n",
      "train loss:0.007457093333945866\n",
      "train loss:0.007304284935607226\n",
      "train loss:0.0018553428957131246\n",
      "train loss:0.0022468250330325446\n",
      "train loss:0.03238346336273467\n",
      "train loss:0.002353691474584149\n",
      "train loss:0.0005557523899766826\n",
      "train loss:0.009662758970458074\n",
      "train loss:0.0263028707917365\n",
      "train loss:0.011026590091964461\n",
      "train loss:0.00017757222845556336\n",
      "train loss:0.004160221211378485\n",
      "train loss:0.0015950517760009045\n",
      "train loss:0.003316744918461882\n",
      "train loss:0.009608682936244166\n",
      "train loss:0.011254209462757687\n",
      "train loss:0.0031678886858403045\n",
      "train loss:0.002033531394794896\n",
      "train loss:0.002186315282002614\n",
      "train loss:0.0018838144427447152\n",
      "train loss:0.0014251572754158837\n",
      "train loss:0.00952835986346388\n",
      "train loss:0.013470147296681318\n",
      "train loss:0.0006632764029424192\n",
      "train loss:0.0011934906206851265\n",
      "train loss:0.005253989509825136\n",
      "train loss:0.010525557334474295\n",
      "train loss:0.011192548182155123\n",
      "train loss:0.001187664708464639\n",
      "train loss:0.016945817928870986\n",
      "train loss:0.0014891577686387014\n",
      "train loss:0.004628169086906949\n",
      "train loss:0.0044611207545178925\n",
      "train loss:0.00319307015738236\n",
      "train loss:0.005647739920081614\n",
      "train loss:0.0016676357947149028\n",
      "train loss:0.0007781250259257796\n",
      "train loss:0.07051317900860654\n",
      "train loss:0.0034123417637158403\n",
      "train loss:0.0026881749411651057\n",
      "train loss:0.0039637577204025545\n",
      "train loss:0.0065884098252718\n",
      "train loss:0.00038935973041227264\n",
      "train loss:0.0012430869634910851\n",
      "train loss:0.0010348164857631864\n",
      "train loss:0.005643724555458984\n",
      "train loss:0.0031849440972340076\n",
      "train loss:0.005286000700022259\n",
      "train loss:0.0028797377686836855\n",
      "train loss:0.008439886160254687\n",
      "train loss:0.0018560281034171345\n",
      "train loss:0.005886634199196933\n",
      "train loss:0.009222264521234045\n",
      "train loss:0.0017874649103110927\n",
      "train loss:0.0017328496896656632\n",
      "train loss:0.0030762595565309876\n",
      "train loss:0.0013141702887752252\n",
      "train loss:0.013929415801489646\n",
      "train loss:0.008459187575949621\n",
      "train loss:0.0043798369691782305\n",
      "train loss:0.0017742868904674048\n",
      "train loss:0.014800913989288058\n",
      "train loss:0.0019821156978855697\n",
      "train loss:0.005080333800052379\n",
      "train loss:0.0008333371598561139\n",
      "train loss:0.00312006427002117\n",
      "train loss:0.00037561466602317414\n",
      "train loss:0.00033138582970913653\n",
      "train loss:0.0056520979349732456\n",
      "train loss:0.001130375023767096\n",
      "train loss:0.0023931450535633796\n",
      "train loss:0.0018841189876922899\n",
      "train loss:0.0015416581870385097\n",
      "train loss:0.003912448000146081\n",
      "train loss:0.00216330003506272\n",
      "train loss:0.003518702697950017\n",
      "train loss:0.006537264087559206\n",
      "train loss:0.0031343090400280734\n",
      "train loss:0.0032209046703295025\n",
      "train loss:0.0004981351254967811\n",
      "train loss:0.001154636763603524\n",
      "train loss:0.0038614115151788912\n",
      "train loss:0.04502674538644639\n",
      "train loss:0.0028629052173473556\n",
      "train loss:0.0057131815400715494\n",
      "train loss:0.0013355906412287697\n",
      "train loss:0.0039533513491007664\n",
      "train loss:0.006043736320614861\n",
      "train loss:0.00013456322389359602\n",
      "train loss:0.0009067224042322647\n",
      "train loss:0.0041412465873137475\n",
      "train loss:0.001288212081616901\n",
      "train loss:0.0003305673556655391\n",
      "train loss:0.00036825745526349876\n",
      "train loss:0.0053592836661748725\n",
      "train loss:0.008157432759244503\n",
      "train loss:0.0009054109625147765\n",
      "train loss:0.007531432750539719\n",
      "train loss:0.0008595122654983542\n",
      "train loss:0.003094832137167352\n",
      "train loss:0.0006287293702588995\n",
      "train loss:0.001520632350229735\n",
      "train loss:0.0008896067906990124\n",
      "train loss:0.0018071055525152187\n",
      "train loss:0.023639017433915027\n",
      "train loss:0.0008632153150443274\n",
      "train loss:0.002119060144737379\n",
      "train loss:0.0013266082113209973\n",
      "train loss:0.009906124924682694\n",
      "train loss:0.0006751741246064529\n",
      "train loss:0.00032110607106465696\n",
      "train loss:0.001429823995825419\n",
      "train loss:0.020355905145536913\n",
      "train loss:0.0015504284055680103\n",
      "train loss:0.0006824100758785264\n",
      "train loss:0.001180954924548786\n",
      "train loss:0.0031362412113375765\n",
      "train loss:0.03991998153037066\n",
      "train loss:0.0054463033906199795\n",
      "train loss:0.004100882506825823\n",
      "train loss:0.09299320718996898\n",
      "train loss:0.0019886059583526174\n",
      "train loss:0.007340999416565396\n",
      "train loss:0.009309154734235148\n",
      "train loss:0.006021168131075778\n",
      "train loss:0.024237636917084117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0021418731745294663\n",
      "train loss:0.009179523309543202\n",
      "train loss:0.0018515835307789364\n",
      "train loss:0.002117476974100021\n",
      "train loss:0.002539003248133079\n",
      "train loss:0.0016898876410534934\n",
      "train loss:0.0007933859539969487\n",
      "train loss:0.0041276120386666984\n",
      "train loss:0.002472831636462383\n",
      "train loss:0.002102501461679175\n",
      "train loss:0.0038847099230598374\n",
      "train loss:0.001153933602367557\n",
      "train loss:0.00136691056013601\n",
      "train loss:0.0016362645639764598\n",
      "train loss:0.0034364699901622735\n",
      "train loss:0.007589914652633929\n",
      "train loss:0.0009828166476033163\n",
      "train loss:0.018045329306590835\n",
      "train loss:0.002911526370342376\n",
      "train loss:0.001025189022503387\n",
      "train loss:0.0032808613053074798\n",
      "train loss:0.003404994257943593\n",
      "train loss:0.0013079089366890356\n",
      "train loss:0.03580386893493705\n",
      "train loss:0.001605993328861076\n",
      "train loss:0.0009185789121704692\n",
      "train loss:0.0017681146869703952\n",
      "train loss:0.0006943280803090619\n",
      "train loss:0.007588074145337089\n",
      "train loss:0.024618798669332885\n",
      "train loss:0.018637866456892863\n",
      "train loss:0.0028131332220899287\n",
      "train loss:0.0030286963990035186\n",
      "train loss:0.001129346360147067\n",
      "train loss:0.009741207889343594\n",
      "train loss:0.03124646692454229\n",
      "train loss:0.003711009970116007\n",
      "train loss:0.005924568372570374\n",
      "train loss:0.009979478075000913\n",
      "train loss:0.0015751054974038534\n",
      "train loss:0.00037052237750185906\n",
      "train loss:0.014896954287434643\n",
      "train loss:0.014174029173244179\n",
      "train loss:0.011915989854930913\n",
      "train loss:0.0006856229291587032\n",
      "train loss:0.0009718350499825987\n",
      "train loss:0.0032589917823337296\n",
      "train loss:0.0022826738965288\n",
      "train loss:0.006194782888445823\n",
      "train loss:0.008238452622026101\n",
      "train loss:0.0017819472254459255\n",
      "train loss:0.0018601171897787525\n",
      "train loss:0.0015808260870328644\n",
      "train loss:0.0017809240798950562\n",
      "train loss:0.0013716177994635525\n",
      "train loss:0.004567993176350664\n",
      "train loss:0.02631656560854348\n",
      "train loss:0.010474021389813203\n",
      "train loss:0.008961878236615185\n",
      "train loss:0.029293989907387533\n",
      "train loss:0.0016350586127030844\n",
      "train loss:0.006238238577177023\n",
      "train loss:0.004643426151711777\n",
      "train loss:0.0024445852680770215\n",
      "train loss:0.0015605352339799114\n",
      "train loss:0.011704223341679788\n",
      "train loss:0.01147012183079279\n",
      "train loss:0.00555468659181857\n",
      "train loss:0.003992189756373339\n",
      "train loss:0.00219758311031666\n",
      "train loss:0.0013462092921598973\n",
      "train loss:0.0035657559368257874\n",
      "train loss:0.00023879721186192596\n",
      "train loss:0.003556587246321863\n",
      "train loss:0.010037368866110381\n",
      "train loss:0.002404351358258103\n",
      "train loss:0.021368653356372395\n",
      "train loss:0.004165746321935931\n",
      "train loss:0.004357660944465302\n",
      "train loss:0.0019166577535753414\n",
      "train loss:0.06028297378847172\n",
      "train loss:0.0007609377236370985\n",
      "train loss:0.006542988885708906\n",
      "train loss:0.004198053932654076\n",
      "train loss:0.006517691600617876\n",
      "train loss:0.001398809680787804\n",
      "train loss:0.01359968816422311\n",
      "train loss:0.005885015749311754\n",
      "train loss:0.0034923960738291386\n",
      "train loss:0.0053760883495878875\n",
      "train loss:0.002142203941420429\n",
      "train loss:0.00405381637587328\n",
      "train loss:0.003767388074924602\n",
      "train loss:0.0008193576436007549\n",
      "train loss:0.006712514147747318\n",
      "train loss:0.0028456070258893375\n",
      "train loss:0.00393043788190137\n",
      "train loss:0.0005686480972563044\n",
      "train loss:0.0015167028636633106\n",
      "train loss:0.0009645913862694729\n",
      "train loss:0.007363418687245905\n",
      "train loss:0.009743008776237277\n",
      "train loss:0.011937333904983215\n",
      "train loss:0.002836962626588408\n",
      "train loss:0.005299336971732535\n",
      "train loss:0.017329001887777803\n",
      "train loss:0.00026969583943908093\n",
      "train loss:0.011907818305524296\n",
      "train loss:0.003916835480037444\n",
      "train loss:0.0007699170990740662\n",
      "train loss:0.005912720023766469\n",
      "train loss:0.0014851040774357253\n",
      "train loss:0.020640605702919767\n",
      "train loss:0.003656402451649868\n",
      "train loss:0.004235447697899122\n",
      "train loss:0.0068765292887805595\n",
      "train loss:0.005667406257621556\n",
      "train loss:0.004730856815588907\n",
      "train loss:0.019055110386411847\n",
      "train loss:0.006238845933650584\n",
      "train loss:0.008032625039327407\n",
      "train loss:0.00542348906945987\n",
      "train loss:0.008404062806215482\n",
      "train loss:0.00554625582238073\n",
      "train loss:0.0019979973671472085\n",
      "train loss:0.005416320133849656\n",
      "train loss:0.030149052423610122\n",
      "train loss:0.0020704520324313987\n",
      "train loss:0.00839452214262356\n",
      "train loss:0.002806114178204992\n",
      "train loss:0.0035408879809281685\n",
      "train loss:0.0006656781655880021\n",
      "train loss:0.0007879888468000207\n",
      "train loss:0.0030575319928804103\n",
      "train loss:0.02231603012069702\n",
      "train loss:0.0007042646580082481\n",
      "train loss:0.016517755298104172\n",
      "train loss:0.027604442494645564\n",
      "train loss:0.0029711284407704895\n",
      "train loss:0.001283649468332301\n",
      "train loss:0.004108784784601375\n",
      "train loss:0.02048384730148876\n",
      "train loss:0.0033466069633539945\n",
      "train loss:0.0016465878810707608\n",
      "train loss:0.008040427055267892\n",
      "train loss:0.004280459758680933\n",
      "train loss:0.002945476765841996\n",
      "train loss:0.013910195007460897\n",
      "train loss:0.0175703330552651\n",
      "train loss:0.0017185184041626533\n",
      "train loss:0.004534030438851136\n",
      "train loss:0.00413908803432229\n",
      "train loss:0.00417705081852902\n",
      "train loss:0.00021700741682449567\n",
      "train loss:0.0015582812471019094\n",
      "train loss:0.017266328017210706\n",
      "train loss:0.003080579541639839\n",
      "train loss:0.003396489584151337\n",
      "train loss:0.00368962956335384\n",
      "train loss:0.03719757102229735\n",
      "train loss:0.0026528701541674647\n",
      "train loss:0.004741357820239409\n",
      "train loss:0.028817784102578695\n",
      "train loss:0.04202947674940662\n",
      "train loss:0.001614797706174079\n",
      "train loss:0.08560746544784496\n",
      "train loss:0.033534960127885684\n",
      "train loss:0.0025028063557426343\n",
      "train loss:0.006856571550861147\n",
      "train loss:0.003973119355475593\n",
      "train loss:0.0061336187775599925\n",
      "train loss:0.002551747136237632\n",
      "train loss:0.006684037815985492\n",
      "train loss:0.008206181376862064\n",
      "train loss:0.014743034563642564\n",
      "train loss:0.002734897434880305\n",
      "train loss:0.030356049709759497\n",
      "train loss:0.02487341290003762\n",
      "train loss:0.003341688065555933\n",
      "train loss:0.009500644651191171\n",
      "train loss:0.008515111374330994\n",
      "train loss:0.005172708684919644\n",
      "train loss:0.011701979419732762\n",
      "train loss:0.0031104168980037677\n",
      "train loss:0.0018708719839654261\n",
      "train loss:0.007504771051870708\n",
      "train loss:0.003296652260338006\n",
      "train loss:0.015204477720188998\n",
      "train loss:0.0014104615707150497\n",
      "train loss:0.011500581692511053\n",
      "train loss:0.0019064276804138672\n",
      "train loss:0.012438360184244681\n",
      "train loss:0.00871843584119305\n",
      "train loss:0.0013468001700620957\n",
      "train loss:0.010399937165334203\n",
      "train loss:0.008068674900177757\n",
      "train loss:0.0015134052329285933\n",
      "train loss:0.0023629513726622984\n",
      "train loss:0.004164421227929691\n",
      "train loss:0.014626619593749574\n",
      "train loss:0.0052053960138972065\n",
      "train loss:0.001821470354455061\n",
      "train loss:0.0013471281392925852\n",
      "train loss:0.0013884778285560512\n",
      "train loss:0.0005380824600829476\n",
      "train loss:0.004173007606791528\n",
      "train loss:0.004386951306141414\n",
      "train loss:0.0033717800055794306\n",
      "train loss:0.0005914117052638332\n",
      "train loss:0.0028705786574174095\n",
      "train loss:0.004861756721176642\n",
      "train loss:0.0049157907173242995\n",
      "train loss:0.003075906926910296\n",
      "train loss:0.003087497383690704\n",
      "train loss:8.843834931638952e-05\n",
      "train loss:0.009167100827382521\n",
      "train loss:0.001292173956370728\n",
      "train loss:0.0009055418964369684\n",
      "train loss:0.00697345597156778\n",
      "train loss:0.0009181037185405649\n",
      "train loss:0.002297069425439684\n",
      "train loss:0.0024714753833073714\n",
      "train loss:0.0021485870107738063\n",
      "train loss:0.0029558589057202935\n",
      "train loss:0.0025747386118201688\n",
      "train loss:0.005109606941262885\n",
      "train loss:0.013475789124601033\n",
      "train loss:0.01443179739555363\n",
      "train loss:7.356192695541108e-05\n",
      "train loss:0.002697900031404708\n",
      "train loss:0.006806091632857464\n",
      "train loss:0.005682192632363848\n",
      "train loss:0.005366940929086377\n",
      "train loss:0.009136020324808007\n",
      "train loss:0.008054660011159702\n",
      "train loss:0.005641815108084993\n",
      "train loss:0.0035804528528488276\n",
      "train loss:0.0009908976738949467\n",
      "train loss:0.0035977467239521606\n",
      "train loss:0.0024406515538166686\n",
      "train loss:0.00166859030389367\n",
      "train loss:0.003356400043960842\n",
      "train loss:0.0012511368774916465\n",
      "train loss:0.0020337761519683443\n",
      "train loss:0.004821718016321005\n",
      "train loss:0.001904725274309619\n",
      "train loss:0.0008485509996755739\n",
      "train loss:0.001852564392128577\n",
      "train loss:0.0006056909072431516\n",
      "train loss:0.0019029229666731417\n",
      "train loss:0.004193664411684741\n",
      "train loss:0.0002833734075342701\n",
      "train loss:0.006069866536945793\n",
      "train loss:0.0035872348082685184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016197154319358618\n",
      "train loss:0.006298148811446103\n",
      "train loss:0.005987299684295092\n",
      "train loss:0.017972375050954083\n",
      "train loss:0.00069456452503249\n",
      "train loss:0.0014422127931206653\n",
      "train loss:0.0009977987980201246\n",
      "train loss:0.00987208927044574\n",
      "train loss:0.0022717328415717323\n",
      "train loss:0.0020848239279171333\n",
      "train loss:0.0035570597746995207\n",
      "train loss:0.003429182660178276\n",
      "train loss:0.0006112244591644675\n",
      "train loss:0.002081898364961524\n",
      "train loss:0.004832422658672732\n",
      "train loss:0.006121756108657879\n",
      "train loss:0.007259596420474056\n",
      "train loss:0.0031343022259770568\n",
      "train loss:0.0020234921727760955\n",
      "train loss:0.002215977873878272\n",
      "train loss:0.002387538243100615\n",
      "train loss:0.00379250274962866\n",
      "train loss:0.016800167407151616\n",
      "train loss:0.013165974742870847\n",
      "train loss:0.0013622980506214633\n",
      "train loss:0.001083087042355893\n",
      "train loss:0.012450544206016927\n",
      "train loss:0.005537511135554321\n",
      "train loss:0.0009743358833117458\n",
      "train loss:0.0014878669726761887\n",
      "train loss:0.00991700914615246\n",
      "train loss:0.003202415631754191\n",
      "train loss:0.032170581097585534\n",
      "train loss:0.007856394520452267\n",
      "train loss:0.008485011457798923\n",
      "train loss:0.010004252586029643\n",
      "train loss:0.03893910152381867\n",
      "train loss:0.0020888232079331282\n",
      "train loss:0.0020606100401493817\n",
      "train loss:0.0017670917325312981\n",
      "train loss:0.0029847399487670317\n",
      "train loss:0.006043601887339084\n",
      "train loss:0.003939332089784538\n",
      "train loss:0.00422644203337797\n",
      "train loss:0.0014614460360603586\n",
      "train loss:0.02250244612356538\n",
      "train loss:0.0014036928975463786\n",
      "train loss:0.005182177495538862\n",
      "train loss:0.0045811239714772444\n",
      "train loss:0.004083447480816738\n",
      "train loss:0.000246970957761923\n",
      "train loss:0.0021568605751228105\n",
      "train loss:0.0006921515252199504\n",
      "train loss:0.0015303802922310508\n",
      "train loss:0.011287674015609643\n",
      "train loss:0.0019145345056247964\n",
      "train loss:0.005766003884741896\n",
      "train loss:0.007096361299985471\n",
      "train loss:0.00426013483556005\n",
      "train loss:0.015595108417004431\n",
      "train loss:0.005352340816467973\n",
      "train loss:0.004706695957889234\n",
      "train loss:0.003306202015136271\n",
      "train loss:0.0020622452344531738\n",
      "train loss:0.006718448414259651\n",
      "train loss:0.008758845235918454\n",
      "train loss:0.0012151223855078647\n",
      "train loss:0.01887895002723267\n",
      "train loss:0.0073552027992825056\n",
      "train loss:0.004333565744115024\n",
      "train loss:0.0059955099322626226\n",
      "train loss:0.0008470172425407315\n",
      "train loss:0.002198988840718238\n",
      "train loss:0.0039854597447380406\n",
      "train loss:0.0003456707777334762\n",
      "train loss:0.004004848758519472\n",
      "train loss:0.003036784944975721\n",
      "train loss:0.0027079239079347444\n",
      "train loss:0.003758337337781556\n",
      "train loss:0.005424301866222437\n",
      "train loss:0.003495984125222751\n",
      "train loss:0.004819691940975008\n",
      "train loss:0.00294162000492237\n",
      "train loss:0.0014020618978911011\n",
      "train loss:0.040263114335962705\n",
      "train loss:0.01026098679541821\n",
      "train loss:0.005486345727589821\n",
      "train loss:0.00086954237867835\n",
      "train loss:0.023480583925709654\n",
      "train loss:0.0017628848992871202\n",
      "train loss:0.003123457133915403\n",
      "train loss:0.0021202417283131734\n",
      "train loss:0.00417469174586079\n",
      "train loss:0.014777832896683284\n",
      "train loss:0.011406356888018152\n",
      "train loss:0.00541257327368613\n",
      "train loss:0.006324972969452013\n",
      "train loss:0.0009179639903607546\n",
      "train loss:0.0016968138474220409\n",
      "train loss:0.008785644323370501\n",
      "train loss:0.0005107147829386153\n",
      "train loss:0.013040560770709936\n",
      "train loss:0.0011463156894632065\n",
      "train loss:0.0007013313748202117\n",
      "train loss:0.016765714046424875\n",
      "train loss:0.0056174199984000564\n",
      "train loss:0.006045696382089218\n",
      "train loss:0.011570065168447597\n",
      "train loss:0.005054679012781198\n",
      "train loss:0.0037427995670379615\n",
      "train loss:0.001240608079762462\n",
      "train loss:0.01170241093599344\n",
      "train loss:0.0007574504866503455\n",
      "train loss:0.001905446351331197\n",
      "train loss:0.0008301424272121752\n",
      "train loss:0.006212213484778344\n",
      "train loss:0.0019815357236613457\n",
      "train loss:0.0014539065873935154\n",
      "train loss:0.0006320594873455709\n",
      "train loss:0.0009229233075190149\n",
      "train loss:0.005019669887628955\n",
      "train loss:0.01954159753449601\n",
      "train loss:0.008181309128182738\n",
      "train loss:0.01178796409348764\n",
      "train loss:0.005747135281772004\n",
      "train loss:0.0020091776380288195\n",
      "train loss:0.002967334517672851\n",
      "train loss:0.006839468421708721\n",
      "train loss:0.005960235797367568\n",
      "train loss:0.005121800361734747\n",
      "train loss:0.0011137661748616533\n",
      "train loss:0.0005975149369735966\n",
      "train loss:0.00015247082523847292\n",
      "train loss:0.06366881233313343\n",
      "train loss:0.020933663657603126\n",
      "train loss:0.0021255667670065045\n",
      "train loss:0.0006238262292376182\n",
      "train loss:0.004201168274506206\n",
      "train loss:0.004364141320983451\n",
      "train loss:0.00201183500749403\n",
      "train loss:0.00649852620834263\n",
      "train loss:0.0002403257111744464\n",
      "train loss:0.005871118640689572\n",
      "train loss:0.0035416668833904296\n",
      "train loss:0.0038478047059550607\n",
      "train loss:0.0002696472052310155\n",
      "train loss:0.0031995292268448437\n",
      "train loss:0.0017058615132530203\n",
      "train loss:0.04514011420104933\n",
      "train loss:0.001561384707884726\n",
      "train loss:0.0051467913495623656\n",
      "train loss:0.0033159661328679623\n",
      "train loss:0.0019578772043542646\n",
      "train loss:0.017464911528838986\n",
      "train loss:0.0059139803982286325\n",
      "train loss:0.001409094426696992\n",
      "train loss:0.006082617355655091\n",
      "train loss:0.004516484030906301\n",
      "train loss:0.0034655348943949476\n",
      "train loss:0.016894348369686094\n",
      "train loss:0.008050070034430973\n",
      "train loss:0.00036760533952712664\n",
      "train loss:0.0027203092100298244\n",
      "train loss:0.003650071833816003\n",
      "train loss:0.0003540102556827028\n",
      "train loss:0.00132028993255178\n",
      "train loss:0.0008789203123492282\n",
      "train loss:0.003420190463099062\n",
      "train loss:0.015009146206372172\n",
      "train loss:0.0008909437232659977\n",
      "train loss:0.004484258413669597\n",
      "train loss:0.0232409928680169\n",
      "train loss:0.001045233786990801\n",
      "train loss:0.0021815611447400084\n",
      "train loss:0.0036592070676115087\n",
      "train loss:0.018757515445699178\n",
      "train loss:0.017505772572659523\n",
      "train loss:0.0028970665502884877\n",
      "train loss:0.0021395931875411115\n",
      "train loss:0.007720995110530507\n",
      "train loss:0.0022388988052907824\n",
      "train loss:0.0011017209961329912\n",
      "train loss:0.0016247198116529577\n",
      "train loss:0.007510797809992904\n",
      "train loss:0.002556330334990018\n",
      "train loss:0.005234323372086065\n",
      "train loss:0.013344848537772276\n",
      "train loss:0.00885538832462337\n",
      "train loss:0.0018410043106036297\n",
      "train loss:0.010242256718705777\n",
      "train loss:0.0021864375916455705\n",
      "train loss:0.0006959858702888837\n",
      "train loss:0.0032827941044788443\n",
      "train loss:0.0033014128242731177\n",
      "train loss:0.002382939663928429\n",
      "train loss:0.005024175938499702\n",
      "train loss:0.00019440084802190398\n",
      "train loss:0.006874703328990088\n",
      "train loss:0.006288246523123404\n",
      "train loss:0.00016834699821141326\n",
      "train loss:0.0014713547819591377\n",
      "train loss:0.00200207716543412\n",
      "train loss:0.0033647495510182473\n",
      "train loss:0.0004227061391981457\n",
      "train loss:0.0022744529900573743\n",
      "train loss:0.0012090990979693717\n",
      "train loss:0.001819498298492086\n",
      "train loss:0.001244624847712427\n",
      "train loss:0.003572664188453985\n",
      "train loss:0.0020961771937430137\n",
      "train loss:0.014036797785171924\n",
      "train loss:0.002194686463063631\n",
      "train loss:0.0033870578221155538\n",
      "train loss:0.0019768597151348846\n",
      "=== epoch:13, train acc:0.995, test acc:0.989 ===\n",
      "train loss:0.005662271265726975\n",
      "train loss:0.0024404063876341526\n",
      "train loss:0.0025143267029964383\n",
      "train loss:0.008537438385830069\n",
      "train loss:0.0014048405915078107\n",
      "train loss:0.005146108128876536\n",
      "train loss:0.00576150900828366\n",
      "train loss:0.0005943868023140361\n",
      "train loss:0.0025899015550154302\n",
      "train loss:0.004524221930418255\n",
      "train loss:0.0022768191968734063\n",
      "train loss:0.001119418385451231\n",
      "train loss:0.0016741955150123091\n",
      "train loss:0.0026518206303493964\n",
      "train loss:0.034908024194684535\n",
      "train loss:0.0011362408034242683\n",
      "train loss:0.007912955263582416\n",
      "train loss:0.002254545865417019\n",
      "train loss:0.0010969062991903\n",
      "train loss:0.0022869266592435017\n",
      "train loss:0.0006669006281602962\n",
      "train loss:0.0004027704389260093\n",
      "train loss:0.0012652227471624997\n",
      "train loss:0.0008643601593311802\n",
      "train loss:0.00513810913270915\n",
      "train loss:0.0035805556552408733\n",
      "train loss:0.006172711029695977\n",
      "train loss:0.004580372965143717\n",
      "train loss:0.008688170241263258\n",
      "train loss:0.00208728912410759\n",
      "train loss:0.020618471498580454\n",
      "train loss:0.03922218062745422\n",
      "train loss:0.004739324272505111\n",
      "train loss:0.000931491008598728\n",
      "train loss:0.0038628094959354364\n",
      "train loss:0.0004514425958689481\n",
      "train loss:0.0006949609486063943\n",
      "train loss:0.003497693883494541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002589554419800599\n",
      "train loss:0.0014777082498264587\n",
      "train loss:0.010629384191323511\n",
      "train loss:0.00025212595180391706\n",
      "train loss:0.0020580354892723064\n",
      "train loss:0.0026031651969191994\n",
      "train loss:0.01880116071675617\n",
      "train loss:0.002565868222538615\n",
      "train loss:0.0023562866013538053\n",
      "train loss:0.002163687851205966\n",
      "train loss:0.0006739859405282439\n",
      "train loss:0.017921822571951858\n",
      "train loss:0.000735267536147477\n",
      "train loss:0.0013670132640003845\n",
      "train loss:0.003050080029707638\n",
      "train loss:0.003903282402843085\n",
      "train loss:0.0063082740590320475\n",
      "train loss:0.0005960889654252409\n",
      "train loss:0.002569557024810091\n",
      "train loss:0.00022057134273295272\n",
      "train loss:0.0026944046094958037\n",
      "train loss:0.0029930016166525397\n",
      "train loss:0.0003159750722060068\n",
      "train loss:0.0024307679546360737\n",
      "train loss:0.004389198253402437\n",
      "train loss:0.0021493052894881186\n",
      "train loss:0.06004292975182445\n",
      "train loss:0.0002391668031983317\n",
      "train loss:0.0011287332569824941\n",
      "train loss:0.0004204387147841514\n",
      "train loss:0.001099923719385597\n",
      "train loss:0.002181766682272707\n",
      "train loss:0.00020052219989814487\n",
      "train loss:0.0017741572677658852\n",
      "train loss:0.0010863474361623075\n",
      "train loss:0.0014251954168451168\n",
      "train loss:0.0023505065615525146\n",
      "train loss:0.0012732729044030533\n",
      "train loss:0.0035972376975793065\n",
      "train loss:0.010552349236145026\n",
      "train loss:0.0029109218290296834\n",
      "train loss:0.0006319453671196257\n",
      "train loss:0.009260140806254574\n",
      "train loss:0.0015767325098613213\n",
      "train loss:0.0016110826642544774\n",
      "train loss:0.002532628716645145\n",
      "train loss:0.004599156839466392\n",
      "train loss:0.012586407987622304\n",
      "train loss:0.0009090857094841371\n",
      "train loss:0.0009190894550360301\n",
      "train loss:0.0018578260883577052\n",
      "train loss:0.004481355361462927\n",
      "train loss:0.0010534181829132917\n",
      "train loss:0.004560537039468649\n",
      "train loss:0.000528783485714364\n",
      "train loss:0.0026313088985512336\n",
      "train loss:0.007190335014871365\n",
      "train loss:0.0012867129671663153\n",
      "train loss:0.007121226185734426\n",
      "train loss:0.0012840719245975547\n",
      "train loss:0.0010353473118567605\n",
      "train loss:0.0022051881813392417\n",
      "train loss:0.0017146889204770865\n",
      "train loss:0.013502231993711606\n",
      "train loss:0.014768967135693162\n",
      "train loss:0.0014813896557909615\n",
      "train loss:0.00126286707772753\n",
      "train loss:0.0024687526734792713\n",
      "train loss:0.010477462178088403\n",
      "train loss:0.00023915779729271995\n",
      "train loss:0.001477029074291939\n",
      "train loss:0.03622463440599592\n",
      "train loss:0.001403659291871227\n",
      "train loss:0.00036535845580070857\n",
      "train loss:0.00021726243224134666\n",
      "train loss:0.005595065499202555\n",
      "train loss:0.000622436317680223\n",
      "train loss:0.0054840593505358325\n",
      "train loss:0.021579580011956718\n",
      "train loss:0.0030304152549562213\n",
      "train loss:0.002325091981158437\n",
      "train loss:0.00367789772514791\n",
      "train loss:0.007224136629800891\n",
      "train loss:0.008104927331897648\n",
      "train loss:0.009374390096635099\n",
      "train loss:0.0013348641327084374\n",
      "train loss:0.00500732907141315\n",
      "train loss:0.0051481470912300995\n",
      "train loss:0.0010989618608020825\n",
      "train loss:0.0016751298337571636\n",
      "train loss:0.016290637949874332\n",
      "train loss:0.00014735510381149613\n",
      "train loss:0.003249854738007652\n",
      "train loss:0.006391272245361666\n",
      "train loss:0.0014237120380330244\n",
      "train loss:0.04766822711589476\n",
      "train loss:0.019022125461760953\n",
      "train loss:0.0035885189530603543\n",
      "train loss:0.008523420933679445\n",
      "train loss:0.006726828211978563\n",
      "train loss:0.001915108800686591\n",
      "train loss:0.0009948313989078643\n",
      "train loss:0.001571278539695854\n",
      "train loss:0.0537429237034211\n",
      "train loss:0.015322140915382263\n",
      "train loss:0.0022640515749199727\n",
      "train loss:0.01170282870076895\n",
      "train loss:0.006377120818284426\n",
      "train loss:0.0007188036635369094\n",
      "train loss:0.0008955366363319573\n",
      "train loss:0.000451296440224667\n",
      "train loss:0.0015708201977179554\n",
      "train loss:0.0007152487512413388\n",
      "train loss:0.0004485478530898827\n",
      "train loss:0.0006670828324464881\n",
      "train loss:0.005245543652520451\n",
      "train loss:0.006575483470259266\n",
      "train loss:0.00245998584731786\n",
      "train loss:0.001266207629160827\n",
      "train loss:0.00349761399547453\n",
      "train loss:0.0014591621960036015\n",
      "train loss:0.0017607370841031694\n",
      "train loss:0.0017885642800401314\n",
      "train loss:0.0018547348357724448\n",
      "train loss:0.043662936699295066\n",
      "train loss:0.001692775303561951\n",
      "train loss:0.0007159702127081643\n",
      "train loss:0.0018733169047768859\n",
      "train loss:0.012733788371444925\n",
      "train loss:0.0019326491851469755\n",
      "train loss:0.003506403303089095\n",
      "train loss:0.0024296210937783135\n",
      "train loss:0.0005352392472228788\n",
      "train loss:0.019515545980690063\n",
      "train loss:0.00483604069862153\n",
      "train loss:0.004292133109296771\n",
      "train loss:0.0011415325215629938\n",
      "train loss:0.0041522000713582405\n",
      "train loss:0.0016246743381663764\n",
      "train loss:0.002323108842080663\n",
      "train loss:0.0074779415314639676\n",
      "train loss:0.005213982036124067\n",
      "train loss:0.00028156870843628267\n",
      "train loss:0.0031768966280530304\n",
      "train loss:0.0020729851252949895\n",
      "train loss:0.0036911522690725\n",
      "train loss:0.0014029753949967136\n",
      "train loss:0.001990904576387287\n",
      "train loss:0.0043473167616830425\n",
      "train loss:0.014623099581265895\n",
      "train loss:0.006836876803040315\n",
      "train loss:0.005082096161149151\n",
      "train loss:0.000858391285861519\n",
      "train loss:0.001370274572451308\n",
      "train loss:0.010849995693130214\n",
      "train loss:0.00851380284666891\n",
      "train loss:0.00035269315117864865\n",
      "train loss:0.0006969324603573948\n",
      "train loss:0.00024278663991205384\n",
      "train loss:0.007673439957917527\n",
      "train loss:0.0012209066471061871\n",
      "train loss:0.0010191747563776902\n",
      "train loss:0.0020797617421172004\n",
      "train loss:0.0038426548202248473\n",
      "train loss:0.0009431211787041639\n",
      "train loss:0.0011690152875044396\n",
      "train loss:0.008474459731153232\n",
      "train loss:0.0019708966292274143\n",
      "train loss:0.012689317547189334\n",
      "train loss:0.016057655902414706\n",
      "train loss:0.0005039565319332934\n",
      "train loss:0.0015230302294164519\n",
      "train loss:0.002273459464969779\n",
      "train loss:0.0007263672676088312\n",
      "train loss:0.0012583643837429542\n",
      "train loss:0.0003269168757320591\n",
      "train loss:0.0005498974075853341\n",
      "train loss:0.0008110825768685545\n",
      "train loss:0.004626411588590344\n",
      "train loss:0.002487406566359735\n",
      "train loss:0.006278550724318742\n",
      "train loss:0.0006959366749853782\n",
      "train loss:0.0023683595853919103\n",
      "train loss:0.00011342745074911949\n",
      "train loss:0.000645325359611337\n",
      "train loss:0.0056958826492110644\n",
      "train loss:0.0010499202209994644\n",
      "train loss:0.013298165055727952\n",
      "train loss:0.0026353384106922277\n",
      "train loss:0.0010863461279584771\n",
      "train loss:0.004216632634665555\n",
      "train loss:0.0011610877925501304\n",
      "train loss:0.00315353752150899\n",
      "train loss:0.00914213038175703\n",
      "train loss:0.003165183264086881\n",
      "train loss:0.0030896927315326567\n",
      "train loss:0.001897130397714529\n",
      "train loss:0.0009370416865673313\n",
      "train loss:0.006176127366296302\n",
      "train loss:0.0016847878667109043\n",
      "train loss:0.003195495459891217\n",
      "train loss:0.0023870902519914795\n",
      "train loss:0.0019713657408053477\n",
      "train loss:0.002478533149316994\n",
      "train loss:0.008128201430250486\n",
      "train loss:0.002625623666529193\n",
      "train loss:0.004313902179856989\n",
      "train loss:0.006451727521920216\n",
      "train loss:0.0006886757945540315\n",
      "train loss:0.004279102643616866\n",
      "train loss:0.0031982378891690037\n",
      "train loss:0.0058105246726230944\n",
      "train loss:0.002418817917396071\n",
      "train loss:0.004244732175351062\n",
      "train loss:0.0038480924083081386\n",
      "train loss:0.0019089921032594747\n",
      "train loss:0.0023075439988896303\n",
      "train loss:0.004614856528891224\n",
      "train loss:0.0021711290181252504\n",
      "train loss:0.003436190633555025\n",
      "train loss:0.00412013257428208\n",
      "train loss:0.06631332974723278\n",
      "train loss:0.002153374318202125\n",
      "train loss:0.01089030525342652\n",
      "train loss:0.00014830950094109766\n",
      "train loss:0.003488926064085921\n",
      "train loss:0.001585446502756737\n",
      "train loss:0.03172532217512606\n",
      "train loss:0.0028932035356114705\n",
      "train loss:0.003459568535605626\n",
      "train loss:0.001325881460204629\n",
      "train loss:0.005277594557880747\n",
      "train loss:0.003564886979121561\n",
      "train loss:0.0032874710052735205\n",
      "train loss:0.0012708664631881459\n",
      "train loss:0.0029723497874586985\n",
      "train loss:0.0004343370910802791\n",
      "train loss:0.0034033613058953326\n",
      "train loss:0.003449794765820259\n",
      "train loss:0.023693403096827114\n",
      "train loss:0.0013100536957352856\n",
      "train loss:0.004813419714024741\n",
      "train loss:0.0037539105549007417\n",
      "train loss:0.0025631332509518613\n",
      "train loss:0.007388633454248592\n",
      "train loss:0.0010788040384220284\n",
      "train loss:0.01570240110150861\n",
      "train loss:0.0021346726293917746\n",
      "train loss:0.00868382958770779\n",
      "train loss:0.0007732614002394192\n",
      "train loss:0.0035554713609247945\n",
      "train loss:0.009244866705466261\n",
      "train loss:0.008546579936875676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001164572523852034\n",
      "train loss:0.01691555188285223\n",
      "train loss:0.0008318517373020172\n",
      "train loss:0.018792273401256745\n",
      "train loss:0.0025070477635411002\n",
      "train loss:0.0004640891408385674\n",
      "train loss:0.0014400340428841652\n",
      "train loss:0.0006274803419664073\n",
      "train loss:0.0016708973789518646\n",
      "train loss:0.007757209771381368\n",
      "train loss:0.0015624521824685116\n",
      "train loss:0.0003629368191909009\n",
      "train loss:0.002933843165922281\n",
      "train loss:0.0005318377882290151\n",
      "train loss:0.024948348865433765\n",
      "train loss:0.012874623604488378\n",
      "train loss:0.0015735818947496393\n",
      "train loss:0.005432179834623428\n",
      "train loss:0.007225114130010074\n",
      "train loss:0.005069296390346581\n",
      "train loss:0.0012850577479550337\n",
      "train loss:0.0029277202995584783\n",
      "train loss:0.00720391899275822\n",
      "train loss:0.002742716386769048\n",
      "train loss:0.0027489682347975352\n",
      "train loss:0.006887125103573077\n",
      "train loss:0.00010593413890480594\n",
      "train loss:0.0029735391950956626\n",
      "train loss:0.0007786079637024804\n",
      "train loss:0.004093017965710199\n",
      "train loss:0.003611922827455533\n",
      "train loss:0.0003300712948532859\n",
      "train loss:0.003224205286301789\n",
      "train loss:0.0006018085322812352\n",
      "train loss:0.009548559778755105\n",
      "train loss:0.004303284439476129\n",
      "train loss:0.005873363973195176\n",
      "train loss:0.001334459831880379\n",
      "train loss:0.0019692453379791456\n",
      "train loss:0.0007261344856823354\n",
      "train loss:0.0017572478088374874\n",
      "train loss:0.0014841452284135406\n",
      "train loss:0.00047881132896806844\n",
      "train loss:0.00401816456513476\n",
      "train loss:0.007540047716210109\n",
      "train loss:0.001370200765048509\n",
      "train loss:0.010432721864659145\n",
      "train loss:0.0019232217465093727\n",
      "train loss:0.0019380183120980216\n",
      "train loss:0.0010505624248516126\n",
      "train loss:0.002465279220472468\n",
      "train loss:0.00942249630113134\n",
      "train loss:0.0030916875517705573\n",
      "train loss:0.005569713254371836\n",
      "train loss:0.007813147910901543\n",
      "train loss:0.003131470921891065\n",
      "train loss:0.0015215365582340718\n",
      "train loss:0.0017958261909769443\n",
      "train loss:0.0011734233290707245\n",
      "train loss:0.004180963337545601\n",
      "train loss:0.0011590947998876434\n",
      "train loss:0.002316320444234619\n",
      "train loss:0.00011111721928230962\n",
      "train loss:0.003503215368214585\n",
      "train loss:0.002370272957376468\n",
      "train loss:0.0036817458379549495\n",
      "train loss:0.004875920181822153\n",
      "train loss:0.0006071579866296091\n",
      "train loss:0.010029204217700212\n",
      "train loss:0.004240593245670949\n",
      "train loss:0.002084327125907623\n",
      "train loss:0.011559641777309474\n",
      "train loss:0.0006752594550292875\n",
      "train loss:0.0016431623979087135\n",
      "train loss:0.0006845305576268984\n",
      "train loss:0.0008680467234331704\n",
      "train loss:0.013739783959561006\n",
      "train loss:0.005266270386266022\n",
      "train loss:0.0048086086619638325\n",
      "train loss:0.005592673587191156\n",
      "train loss:0.007051880441022229\n",
      "train loss:0.002227851422319375\n",
      "train loss:0.0004931994321112305\n",
      "train loss:7.621175715401557e-05\n",
      "train loss:0.0027105702591642173\n",
      "train loss:0.0007779543108653051\n",
      "train loss:0.020609562176191566\n",
      "train loss:0.0005668520482110183\n",
      "train loss:0.0003606661776924224\n",
      "train loss:0.0008625023163371586\n",
      "train loss:0.0004976645347700534\n",
      "train loss:0.001062923429034732\n",
      "train loss:0.0005411078934437318\n",
      "train loss:0.010740543992864237\n",
      "train loss:0.00446020755584268\n",
      "train loss:0.0027608019423920956\n",
      "train loss:0.0033370802424927504\n",
      "train loss:0.010342099979873813\n",
      "train loss:0.0009130026148526958\n",
      "train loss:0.004759653685094007\n",
      "train loss:0.001847511732460517\n",
      "train loss:0.015872125039025985\n",
      "train loss:0.00016938844470081637\n",
      "train loss:0.0012479573335810706\n",
      "train loss:0.0014773258435431041\n",
      "train loss:0.006023278200330354\n",
      "train loss:0.0135134374046545\n",
      "train loss:0.001327188150683903\n",
      "train loss:0.0024368680788847373\n",
      "train loss:0.0014427569151613331\n",
      "train loss:0.005947115966230255\n",
      "train loss:0.0004173716801896476\n",
      "train loss:0.006877327147711983\n",
      "train loss:0.0011648091245855428\n",
      "train loss:0.0123114201206365\n",
      "train loss:0.0034650259218815156\n",
      "train loss:0.00029148661993386497\n",
      "train loss:0.005608460565677577\n",
      "train loss:9.906530363264388e-05\n",
      "train loss:0.0076059786788633225\n",
      "train loss:0.01113439272495671\n",
      "train loss:0.003962181992116595\n",
      "train loss:0.00332261118281142\n",
      "train loss:0.006067936744360764\n",
      "train loss:0.010003086432438722\n",
      "train loss:0.004048277477610742\n",
      "train loss:0.0013245323296015258\n",
      "train loss:0.015456217765168458\n",
      "train loss:0.00434872630149446\n",
      "train loss:0.0006308655158601028\n",
      "train loss:0.002785087887145145\n",
      "train loss:0.012714316310505574\n",
      "train loss:0.002276026773975307\n",
      "train loss:0.005214507740258664\n",
      "train loss:0.06934850203569697\n",
      "train loss:0.0029264794797307027\n",
      "train loss:0.0024152452750913446\n",
      "train loss:0.004145810760128701\n",
      "train loss:0.0005070442800111489\n",
      "train loss:0.003610060823519856\n",
      "train loss:0.002292305885141507\n",
      "train loss:0.006220324713327412\n",
      "train loss:0.000470260862066974\n",
      "train loss:0.0009835180100713323\n",
      "train loss:0.0009663302562546554\n",
      "train loss:0.002714610206527749\n",
      "train loss:0.010141396137800693\n",
      "train loss:0.00395163066398892\n",
      "train loss:7.481171438444702e-05\n",
      "train loss:0.005025892518419065\n",
      "train loss:0.003486663034437744\n",
      "train loss:0.001320365790276815\n",
      "train loss:0.012748469460841431\n",
      "train loss:0.007872112862262968\n",
      "train loss:0.013469745244280972\n",
      "train loss:0.0011089785293715159\n",
      "train loss:0.0028598970278705953\n",
      "train loss:0.0014933697418243624\n",
      "train loss:0.006482889770644575\n",
      "train loss:0.0035245246740863243\n",
      "train loss:0.0003353907909558109\n",
      "train loss:0.0021745690634233246\n",
      "train loss:0.004471078015380929\n",
      "train loss:0.01717473567766704\n",
      "train loss:0.0005022332018094435\n",
      "train loss:0.0006174593374176793\n",
      "train loss:0.0027277965964911223\n",
      "train loss:0.0013074725098309542\n",
      "train loss:0.004703794684338075\n",
      "train loss:0.004839003061347039\n",
      "train loss:0.010866569393456068\n",
      "train loss:0.00862612953023003\n",
      "train loss:0.009817407688845573\n",
      "train loss:0.002121139673201664\n",
      "train loss:0.010331536689814527\n",
      "train loss:0.0005802548736965319\n",
      "train loss:0.005110241264268824\n",
      "train loss:0.009307019328246522\n",
      "train loss:0.0002490230686880181\n",
      "train loss:0.003297589468974981\n",
      "train loss:0.0026692511914748955\n",
      "train loss:0.003781863263861029\n",
      "train loss:0.0009523136131911955\n",
      "train loss:0.01534076893109241\n",
      "train loss:0.017424551784514762\n",
      "train loss:0.0016106585910026202\n",
      "train loss:0.0037626568369616064\n",
      "train loss:0.0008499138666665947\n",
      "train loss:0.0009332186830022912\n",
      "train loss:0.00033539249411682835\n",
      "train loss:0.0011931118275914252\n",
      "train loss:0.0012631427805736661\n",
      "train loss:0.004566543169840523\n",
      "train loss:0.02119297270284752\n",
      "train loss:0.002750632239404605\n",
      "train loss:0.006779836134712458\n",
      "train loss:0.0038629069013976615\n",
      "train loss:0.0069674800859670935\n",
      "train loss:0.0028186169028840886\n",
      "train loss:0.0011120389846341742\n",
      "train loss:0.0032415396985443455\n",
      "train loss:0.005648902905960505\n",
      "train loss:0.00046089847071255005\n",
      "train loss:0.005880600273416743\n",
      "train loss:0.004318909270042516\n",
      "train loss:0.0016756397110448734\n",
      "train loss:0.0010177230828605107\n",
      "train loss:0.008437807626276422\n",
      "train loss:0.002241352229127883\n",
      "train loss:0.0006983230831994698\n",
      "train loss:0.0005120457990757445\n",
      "train loss:0.0063210200552305095\n",
      "train loss:0.0027971047561490014\n",
      "train loss:0.004523289025687417\n",
      "train loss:0.0012921138231662928\n",
      "train loss:0.00867147465984109\n",
      "train loss:0.00025643711248126745\n",
      "train loss:0.0024348682711704418\n",
      "train loss:0.0007731487745638925\n",
      "train loss:0.004131740920384983\n",
      "train loss:0.0016508395095234019\n",
      "train loss:0.018105667756500615\n",
      "train loss:0.037266242378969236\n",
      "train loss:0.004769601205509213\n",
      "train loss:0.0021620231604421304\n",
      "train loss:0.002941951353025726\n",
      "train loss:0.000338794016206563\n",
      "train loss:0.0016226208238962997\n",
      "train loss:0.002844928975231016\n",
      "train loss:0.0011971240893339779\n",
      "train loss:0.0023673058666926535\n",
      "train loss:0.0025470097521260978\n",
      "train loss:0.0025313607385413273\n",
      "train loss:0.0030638941981826766\n",
      "train loss:0.0024862830385615816\n",
      "train loss:0.002579566776210947\n",
      "train loss:0.0066601465454688156\n",
      "train loss:0.035862181178279856\n",
      "train loss:0.0038682670095575088\n",
      "train loss:0.0007908074375981193\n",
      "train loss:0.0003870768485378792\n",
      "train loss:0.0024502624222656473\n",
      "train loss:0.001993876142589\n",
      "train loss:0.013094492216673994\n",
      "train loss:0.009156527526607816\n",
      "train loss:0.0023188258802013667\n",
      "train loss:0.004732425451061551\n",
      "train loss:0.014797857649022274\n",
      "train loss:0.0003637046310319976\n",
      "train loss:0.0012135556968045935\n",
      "train loss:0.012481868787852082\n",
      "train loss:0.0008599092089263186\n",
      "train loss:0.006039798389412963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003352783892310239\n",
      "train loss:0.0012950541126724247\n",
      "train loss:0.000830391739957439\n",
      "train loss:0.0008741861409441493\n",
      "train loss:0.0015282564911096093\n",
      "train loss:0.012320160851057731\n",
      "train loss:0.0028635152011230167\n",
      "train loss:0.017073672716048708\n",
      "train loss:0.0027044830096340775\n",
      "train loss:0.0035485327871834322\n",
      "train loss:0.0006121276558596733\n",
      "train loss:0.0005098292964718163\n",
      "train loss:0.0021456637468083616\n",
      "train loss:0.002191343171936844\n",
      "train loss:0.003829408296488921\n",
      "train loss:0.0003406855786714266\n",
      "train loss:0.03675464940862931\n",
      "train loss:0.006193997817314089\n",
      "train loss:0.002485713247172915\n",
      "train loss:0.00448004802202913\n",
      "train loss:0.000707800711147885\n",
      "train loss:0.001319054969631433\n",
      "train loss:0.024648103834504904\n",
      "train loss:0.0015198083942827866\n",
      "train loss:0.0026795985171804803\n",
      "train loss:0.011544204351375063\n",
      "train loss:0.0006228069731931565\n",
      "train loss:0.0008340242097468292\n",
      "train loss:0.0011560449951314477\n",
      "train loss:0.010364689356948292\n",
      "train loss:0.0015559199787554504\n",
      "train loss:0.004246133892454593\n",
      "train loss:0.0014216572850982321\n",
      "train loss:0.0016115469263855403\n",
      "train loss:0.007835796837859364\n",
      "train loss:0.0014608989583271548\n",
      "train loss:0.01048386894107053\n",
      "train loss:0.004253058982792131\n",
      "train loss:0.0008144255359266979\n",
      "train loss:0.0284723236284315\n",
      "train loss:0.0003241047983581308\n",
      "train loss:0.004318729855247683\n",
      "train loss:0.007549063084460514\n",
      "train loss:0.004326847185484161\n",
      "train loss:0.00025779038049105385\n",
      "train loss:0.003047185363594987\n",
      "train loss:0.0032411012901782136\n",
      "train loss:0.001028175275505963\n",
      "train loss:0.0009861525214361884\n",
      "train loss:0.0009693124441691489\n",
      "train loss:0.0011297173849358015\n",
      "train loss:0.000945113411491241\n",
      "train loss:0.007225324929158394\n",
      "train loss:0.004122445317238971\n",
      "train loss:0.0027369966682277724\n",
      "train loss:0.0032029920589847667\n",
      "=== epoch:14, train acc:0.995, test acc:0.987 ===\n",
      "train loss:0.0004500160487915402\n",
      "train loss:0.011409221428557256\n",
      "train loss:0.0033852781697028184\n",
      "train loss:0.001373986428914038\n",
      "train loss:0.0001485768939827627\n",
      "train loss:0.00025188109099347146\n",
      "train loss:0.00022174167423262672\n",
      "train loss:0.0056815213641486385\n",
      "train loss:0.0030688530910747097\n",
      "train loss:0.002492129282398156\n",
      "train loss:0.007580490752114917\n",
      "train loss:0.0005349787624094196\n",
      "train loss:0.002221078380885236\n",
      "train loss:0.0019851882407722807\n",
      "train loss:0.0003370362499631939\n",
      "train loss:0.004532093115700603\n",
      "train loss:0.0014759698999564908\n",
      "train loss:0.0011062335049609481\n",
      "train loss:0.0033737967347426314\n",
      "train loss:0.0006079192615817814\n",
      "train loss:0.0010637206584818556\n",
      "train loss:0.0015120390108918863\n",
      "train loss:0.0010269054439999395\n",
      "train loss:0.006753605400779924\n",
      "train loss:0.0011802030962869438\n",
      "train loss:0.0022921173487485224\n",
      "train loss:0.009115645536297056\n",
      "train loss:0.0001998616796722625\n",
      "train loss:0.0015564523412310918\n",
      "train loss:0.041257791012489206\n",
      "train loss:0.00277217516424679\n",
      "train loss:0.0070461431220968825\n",
      "train loss:0.0008960126059171836\n",
      "train loss:0.0006066682666185185\n",
      "train loss:0.0019861614193375653\n",
      "train loss:0.00749139150681621\n",
      "train loss:0.0016753430457160298\n",
      "train loss:0.0005474836815538113\n",
      "train loss:0.01635289306697004\n",
      "train loss:0.007135721000828563\n",
      "train loss:0.004996092490070458\n",
      "train loss:0.0016655833526240881\n",
      "train loss:0.006685265640606594\n",
      "train loss:0.0037595823135980555\n",
      "train loss:0.001803831881539235\n",
      "train loss:0.007758835025161441\n",
      "train loss:0.006346860225352482\n",
      "train loss:0.0007047270262820892\n",
      "train loss:0.0013387052354268097\n",
      "train loss:0.0006000584428119297\n",
      "train loss:0.0018141887541797547\n",
      "train loss:0.013233187054684063\n",
      "train loss:0.001874810644005796\n",
      "train loss:0.0011532735433228897\n",
      "train loss:0.0034434010823022067\n",
      "train loss:0.011552926195639834\n",
      "train loss:0.023863809393639676\n",
      "train loss:0.01925432740651812\n",
      "train loss:0.0036182863079420712\n",
      "train loss:0.0006584282787368966\n",
      "train loss:0.00117526576500463\n",
      "train loss:0.018439621472672446\n",
      "train loss:0.000691940296046317\n",
      "train loss:0.00534361435166155\n",
      "train loss:0.009403492165035502\n",
      "train loss:0.0007626038579435491\n",
      "train loss:0.006898514737746554\n",
      "train loss:0.0021730670125240828\n",
      "train loss:0.021120962349309536\n",
      "train loss:0.0002676178521387985\n",
      "train loss:0.0007839818846357985\n",
      "train loss:0.0010931396326202\n",
      "train loss:9.095811198436734e-05\n",
      "train loss:0.0015015380223121913\n",
      "train loss:0.0035605517808899954\n",
      "train loss:0.008012291655335369\n",
      "train loss:0.004800121339382739\n",
      "train loss:0.0011049818022669385\n",
      "train loss:0.0006342819133840624\n",
      "train loss:0.005751725038902867\n",
      "train loss:0.0005411291441074948\n",
      "train loss:0.0032618577967011113\n",
      "train loss:0.009952540869790227\n",
      "train loss:0.005536048765777573\n",
      "train loss:0.00251823356251022\n",
      "train loss:0.0016162041853946963\n",
      "train loss:0.002796807077464431\n",
      "train loss:0.00967149615258544\n",
      "train loss:0.001039288389447524\n",
      "train loss:0.000658313544338584\n",
      "train loss:0.003213619464355561\n",
      "train loss:0.04010731916287899\n",
      "train loss:0.013159498653115725\n",
      "train loss:0.0018241949432273661\n",
      "train loss:0.00733778671869516\n",
      "train loss:0.005530615000930899\n",
      "train loss:0.009757417516180658\n",
      "train loss:0.0028579450995529616\n",
      "train loss:0.002604697884196994\n",
      "train loss:0.0014351339439100169\n",
      "train loss:0.005859366153159209\n",
      "train loss:0.0015585195977210677\n",
      "train loss:0.00815715244933004\n",
      "train loss:0.0019887263745894017\n",
      "train loss:0.02943390932158333\n",
      "train loss:0.013907617808490123\n",
      "train loss:0.009736995744129626\n",
      "train loss:0.0015945262142274977\n",
      "train loss:0.0017565069630754828\n",
      "train loss:0.0007988760181825163\n",
      "train loss:0.0023697703686346543\n",
      "train loss:0.003658517146159315\n",
      "train loss:0.003629463698249147\n",
      "train loss:0.0008141011705777333\n",
      "train loss:0.0015709303542137262\n",
      "train loss:0.010335252304696493\n",
      "train loss:0.001137939948783479\n",
      "train loss:0.00013762437466377882\n",
      "train loss:0.00019704684949911408\n",
      "train loss:0.007959509395512664\n",
      "train loss:0.0019626029658994914\n",
      "train loss:0.0009542069701850312\n",
      "train loss:0.031067364414586223\n",
      "train loss:0.0003411344988681169\n",
      "train loss:0.0034568534455683784\n",
      "train loss:0.007556669645068432\n",
      "train loss:0.004078625400335332\n",
      "train loss:0.014531586482935037\n",
      "train loss:0.0031312363683156617\n",
      "train loss:0.0015771088993729232\n",
      "train loss:0.008263757122379546\n",
      "train loss:0.00011565930045545558\n",
      "train loss:0.0013385748852203878\n",
      "train loss:0.0025906987696565215\n",
      "train loss:0.012312714276872326\n",
      "train loss:0.0009181511862291468\n",
      "train loss:0.002641122927139645\n",
      "train loss:0.0025446776163375205\n",
      "train loss:0.13642498855177604\n",
      "train loss:0.000902824689048601\n",
      "train loss:0.0017320006088606997\n",
      "train loss:0.008307693033866003\n",
      "train loss:0.0013782822296543548\n",
      "train loss:0.000993218038475516\n",
      "train loss:0.03942027506788807\n",
      "train loss:0.002310104052056145\n",
      "train loss:0.0016550961143377496\n",
      "train loss:0.002703914709209706\n",
      "train loss:0.0010490263666963864\n",
      "train loss:0.007593114151790619\n",
      "train loss:0.002890932805289204\n",
      "train loss:0.0004402725112059313\n",
      "train loss:0.004719967690361159\n",
      "train loss:0.0037783310779853727\n",
      "train loss:0.0034357220949674844\n",
      "train loss:0.014104875190363358\n",
      "train loss:0.0014139596622340742\n",
      "train loss:0.004008182468254844\n",
      "train loss:0.002150031906091748\n",
      "train loss:0.006715010432319212\n",
      "train loss:0.0007425985312250459\n",
      "train loss:0.0005217021094898505\n",
      "train loss:0.002807158008029597\n",
      "train loss:0.0002842535782203359\n",
      "train loss:0.001004350862963863\n",
      "train loss:0.0031345099465088966\n",
      "train loss:8.451680343664797e-05\n",
      "train loss:0.0035880173288245555\n",
      "train loss:0.000889932056432475\n",
      "train loss:0.01284858046109635\n",
      "train loss:0.0015603961965944498\n",
      "train loss:0.004269841552842354\n",
      "train loss:0.004119262331327425\n",
      "train loss:0.0065137362604380635\n",
      "train loss:0.00019593136551395034\n",
      "train loss:0.012194319174937563\n",
      "train loss:0.0012498379672608864\n",
      "train loss:0.0004691752680223614\n",
      "train loss:0.002332770147581654\n",
      "train loss:0.004309465099714032\n",
      "train loss:0.003392315598367696\n",
      "train loss:0.00030077761793330816\n",
      "train loss:0.002025861409750806\n",
      "train loss:0.00415882918578463\n",
      "train loss:0.0004135143132617924\n",
      "train loss:0.004180522879750502\n",
      "train loss:0.0003930504920862946\n",
      "train loss:0.0013361910491323811\n",
      "train loss:0.0024048081496064423\n",
      "train loss:0.002601196696315865\n",
      "train loss:0.00283668447821114\n",
      "train loss:0.0030782506656205993\n",
      "train loss:0.0018174625345204944\n",
      "train loss:0.0071322837244502234\n",
      "train loss:0.0021781693145138167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008757236880791709\n",
      "train loss:0.001165200186159423\n",
      "train loss:0.0014505944839308524\n",
      "train loss:0.00603452598482713\n",
      "train loss:0.00021989625728490082\n",
      "train loss:0.0017310940084923222\n",
      "train loss:0.009365075248001162\n",
      "train loss:0.02694796477284075\n",
      "train loss:0.0020822318754102295\n",
      "train loss:0.005845964453940013\n",
      "train loss:0.0007769826607015354\n",
      "train loss:0.0003802211798148233\n",
      "train loss:0.0053857613672152645\n",
      "train loss:0.040001806678786916\n",
      "train loss:0.0008813337182392953\n",
      "train loss:0.003971465753788361\n",
      "train loss:0.004855113641603973\n",
      "train loss:0.009726668481224592\n",
      "train loss:0.004099023080992896\n",
      "train loss:0.0017377587046280868\n",
      "train loss:0.0007300388588821319\n",
      "train loss:0.003154009590890528\n",
      "train loss:0.0007889917635862402\n",
      "train loss:0.0013567414367983762\n",
      "train loss:0.0071071683810004635\n",
      "train loss:0.0052578402487514974\n",
      "train loss:0.0005574631042990434\n",
      "train loss:0.0032459757916752548\n",
      "train loss:0.002059961320735323\n",
      "train loss:0.00025425634955166963\n",
      "train loss:0.0003980645501093964\n",
      "train loss:0.004414662477906265\n",
      "train loss:0.0014459651722218115\n",
      "train loss:0.01005849002842639\n",
      "train loss:0.003430781491970909\n",
      "train loss:0.00237678575188324\n",
      "train loss:0.008434900683542069\n",
      "train loss:0.00557654352716921\n",
      "train loss:0.0017943058318632492\n",
      "train loss:0.0016619243158311442\n",
      "train loss:0.00021896180845159914\n",
      "train loss:0.0031405651179146066\n",
      "train loss:0.0005917126737050849\n",
      "train loss:0.000274863803500104\n",
      "train loss:0.0033125475079064898\n",
      "train loss:0.0034848540889236656\n",
      "train loss:0.0250392723176012\n",
      "train loss:0.00972033215584038\n",
      "train loss:0.008402930838668825\n",
      "train loss:0.003142368177941505\n",
      "train loss:0.010372133864478153\n",
      "train loss:0.0331690681831505\n",
      "train loss:0.005153371372387258\n",
      "train loss:0.0022885762277248703\n",
      "train loss:0.0035496888316714826\n",
      "train loss:0.00022749288608209462\n",
      "train loss:0.007383933956027902\n",
      "train loss:0.001114288741023358\n",
      "train loss:0.0030784472750807063\n",
      "train loss:0.0019310495121333876\n",
      "train loss:0.0035659094455982314\n",
      "train loss:0.01983783079349681\n",
      "train loss:0.00271973866502773\n",
      "train loss:0.0013998570526080642\n",
      "train loss:0.001441206729254286\n",
      "train loss:0.0009403743503317015\n",
      "train loss:0.0029382660661748583\n",
      "train loss:0.0005660008826447353\n",
      "train loss:0.0073364540989008485\n",
      "train loss:0.002272870770712563\n",
      "train loss:0.0001962840812557233\n",
      "train loss:0.0007541835791421312\n",
      "train loss:0.00028122567244146635\n",
      "train loss:0.004694150395025595\n",
      "train loss:0.0006292384468954251\n",
      "train loss:0.004563560103024943\n",
      "train loss:0.001749375080988758\n",
      "train loss:0.008992747135472653\n",
      "train loss:0.0020494234312790276\n",
      "train loss:0.004090050656785185\n",
      "train loss:0.003890737859074434\n",
      "train loss:7.144277133802505e-05\n",
      "train loss:0.0031834475751996616\n",
      "train loss:0.00041440850420685504\n",
      "train loss:0.002163786188310319\n",
      "train loss:0.0007985195008574818\n",
      "train loss:0.01268771249910789\n",
      "train loss:0.007153794200453214\n",
      "train loss:0.003800238499337073\n",
      "train loss:0.0001552411838057497\n",
      "train loss:0.007957369323258547\n",
      "train loss:0.0011817646707462908\n",
      "train loss:0.0025747876734329854\n",
      "train loss:0.002502449374310495\n",
      "train loss:0.0016590419174133746\n",
      "train loss:0.006900736714914797\n",
      "train loss:0.00047679039336816865\n",
      "train loss:0.00027532906585800866\n",
      "train loss:0.0014113407932027776\n",
      "train loss:0.003555847175906609\n",
      "train loss:0.002504246873323934\n",
      "train loss:0.002095844965532892\n",
      "train loss:0.004476363935347237\n",
      "train loss:0.0024001218187021055\n",
      "train loss:0.0020744999918039233\n",
      "train loss:0.0009481594060480676\n",
      "train loss:0.0011725816181016888\n",
      "train loss:0.0012153586941310082\n",
      "train loss:0.0037021970976221937\n",
      "train loss:0.0013453544504208731\n",
      "train loss:0.004567406695624361\n",
      "train loss:0.003723740690252646\n",
      "train loss:0.08572919593885593\n",
      "train loss:0.0015574687194895675\n",
      "train loss:0.0003909809947628939\n",
      "train loss:0.004572252634055578\n",
      "train loss:0.017597215702604183\n",
      "train loss:0.0012295218316008617\n",
      "train loss:0.04368384151099771\n",
      "train loss:0.0007561169971042075\n",
      "train loss:0.0041301055092031885\n",
      "train loss:0.0030323310947982466\n",
      "train loss:0.0005795803814054314\n",
      "train loss:0.0066415688291215184\n",
      "train loss:0.002366795488261514\n",
      "train loss:0.00395998411143256\n",
      "train loss:0.0014035212589329287\n",
      "train loss:0.0025758475430754098\n",
      "train loss:0.0013635379145378152\n",
      "train loss:0.0039294528037468\n",
      "train loss:0.0012874807179565986\n",
      "train loss:0.0016461983755338611\n",
      "train loss:0.003113236717250835\n",
      "train loss:0.0008051656322448194\n",
      "train loss:0.009484260782661263\n",
      "train loss:0.0024060197768022533\n",
      "train loss:0.0016213849720282622\n",
      "train loss:0.002549596114450101\n",
      "train loss:0.0022021484044206217\n",
      "train loss:0.000203802744175754\n",
      "train loss:0.004805002010114893\n",
      "train loss:0.017193954714390294\n",
      "train loss:0.0026495346888185433\n",
      "train loss:0.0027103415578358593\n",
      "train loss:0.008926669446893173\n",
      "train loss:0.0022721521904706583\n",
      "train loss:0.002750652765175391\n",
      "train loss:0.004904586796795138\n",
      "train loss:0.0018183779453855007\n",
      "train loss:0.00325344430182572\n",
      "train loss:0.000469372420367915\n",
      "train loss:0.002084307586425568\n",
      "train loss:0.007710146228106681\n",
      "train loss:0.0075341350121066915\n",
      "train loss:0.0002945975543349223\n",
      "train loss:0.015843235021085623\n",
      "train loss:0.0004930703591331484\n",
      "train loss:0.0012755014424188308\n",
      "train loss:0.0007383441681452084\n",
      "train loss:0.0008574383963073985\n",
      "train loss:0.0038931033778477776\n",
      "train loss:0.0003944894910645022\n",
      "train loss:0.002535125938364371\n",
      "train loss:0.003143782845721667\n",
      "train loss:0.011467490336620726\n",
      "train loss:0.002906478345935059\n",
      "train loss:0.0004910230013049799\n",
      "train loss:0.0019210936545054657\n",
      "train loss:0.006940040894744207\n",
      "train loss:0.00048700595243465213\n",
      "train loss:0.0006260257786416848\n",
      "train loss:0.00448929123600754\n",
      "train loss:0.0007332981884913263\n",
      "train loss:0.0004982927077266204\n",
      "train loss:0.0058795110942479155\n",
      "train loss:0.003774555973174878\n",
      "train loss:0.0019037785227433782\n",
      "train loss:0.0017840204461352313\n",
      "train loss:0.0007081389772344944\n",
      "train loss:0.003388242697854914\n",
      "train loss:0.0028906040884395657\n",
      "train loss:0.00161882381536123\n",
      "train loss:0.004586180806332039\n",
      "train loss:0.002131370196923089\n",
      "train loss:0.004210244178178477\n",
      "train loss:0.0021052460988931643\n",
      "train loss:0.0007955678474618616\n",
      "train loss:0.0036162478549844877\n",
      "train loss:0.002395164896586223\n",
      "train loss:0.0066123368654749815\n",
      "train loss:0.003025790458210524\n",
      "train loss:0.00100858377353797\n",
      "train loss:0.0005368521646150193\n",
      "train loss:0.009695054346807898\n",
      "train loss:0.0022497838847988214\n",
      "train loss:0.001199052988341154\n",
      "train loss:0.008388067963455682\n",
      "train loss:0.008021126654165784\n",
      "train loss:0.0003525827124683911\n",
      "train loss:0.001315537493485143\n",
      "train loss:0.00946920102784532\n",
      "train loss:0.003791932619753038\n",
      "train loss:0.0034476191537142105\n",
      "train loss:0.0006922512681003684\n",
      "train loss:0.010734865978629134\n",
      "train loss:0.0036603596683243557\n",
      "train loss:0.0006148123218846789\n",
      "train loss:0.007663109441132805\n",
      "train loss:0.0006479812596173425\n",
      "train loss:0.00011163819358660709\n",
      "train loss:0.000766927642030139\n",
      "train loss:0.0007854250824962825\n",
      "train loss:0.003522928332344104\n",
      "train loss:0.0010025921136084866\n",
      "train loss:0.003791698227130093\n",
      "train loss:0.0017201016789826912\n",
      "train loss:0.002427467211994846\n",
      "train loss:0.004404567452409752\n",
      "train loss:0.0022009566770190376\n",
      "train loss:0.0002064163506268386\n",
      "train loss:0.0009049603501727711\n",
      "train loss:0.00025754964981856325\n",
      "train loss:0.002309841922683103\n",
      "train loss:0.005045247870047695\n",
      "train loss:0.001631853537406555\n",
      "train loss:1.5893366113758523e-05\n",
      "train loss:0.0002467529701308311\n",
      "train loss:0.0017984223840045764\n",
      "train loss:0.0006273598573063245\n",
      "train loss:0.0027537428000678037\n",
      "train loss:0.0009131036473872629\n",
      "train loss:0.0003791952166215828\n",
      "train loss:0.005156083409495268\n",
      "train loss:0.0012105807819090889\n",
      "train loss:0.0015513238902931338\n",
      "train loss:0.0029387042349280396\n",
      "train loss:0.001511755575869127\n",
      "train loss:0.002475676637856861\n",
      "train loss:0.0018443072842800985\n",
      "train loss:0.0004637045749768605\n",
      "train loss:0.001676869807931133\n",
      "train loss:0.0012857236524356308\n",
      "train loss:0.0008489423481785805\n",
      "train loss:0.010587365315204404\n",
      "train loss:0.0008883200249158302\n",
      "train loss:0.002443784101990238\n",
      "train loss:0.0025422362128539465\n",
      "train loss:0.0018326412279716397\n",
      "train loss:0.0020459408959686274\n",
      "train loss:0.00047542762089148005\n",
      "train loss:0.0012483307920020709\n",
      "train loss:0.0007045223232864987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008306041728458774\n",
      "train loss:0.0005888871406064254\n",
      "train loss:0.002944699675362551\n",
      "train loss:0.0001362422705117386\n",
      "train loss:0.0010781586235486704\n",
      "train loss:0.0017029092411005153\n",
      "train loss:0.005719433959613905\n",
      "train loss:0.002200184167120729\n",
      "train loss:0.00037049422580886436\n",
      "train loss:0.01876103053487528\n",
      "train loss:0.0425359390281491\n",
      "train loss:0.00027148294260930314\n",
      "train loss:0.0002569213344820126\n",
      "train loss:0.004042588853683626\n",
      "train loss:0.0031377691330916886\n",
      "train loss:0.0005189217819295034\n",
      "train loss:0.0020161153759793047\n",
      "train loss:0.0010975620543161933\n",
      "train loss:0.005163878523311111\n",
      "train loss:0.0033027446319144164\n",
      "train loss:0.0002734914202064452\n",
      "train loss:0.0011876921816007665\n",
      "train loss:0.0008994497173547051\n",
      "train loss:0.000802801145057557\n",
      "train loss:0.003243104834496247\n",
      "train loss:0.006681431004405072\n",
      "train loss:0.02795862166081164\n",
      "train loss:0.00017642630975065187\n",
      "train loss:0.0011882466312910338\n",
      "train loss:0.00340125335460402\n",
      "train loss:0.0006000154328780425\n",
      "train loss:0.000586400739799939\n",
      "train loss:0.007035739661553776\n",
      "train loss:0.004170260789861115\n",
      "train loss:0.0028691491438655693\n",
      "train loss:0.0008383373638659518\n",
      "train loss:0.0021934969955496168\n",
      "train loss:0.0010862220563718447\n",
      "train loss:0.004383130255928682\n",
      "train loss:0.00036757889366940337\n",
      "train loss:0.0002937254503194625\n",
      "train loss:0.005690176040165061\n",
      "train loss:0.0009714856863762516\n",
      "train loss:0.051080119988085725\n",
      "train loss:0.000822656708731797\n",
      "train loss:0.001996105654987749\n",
      "train loss:0.005527840266719359\n",
      "train loss:0.001192804516530292\n",
      "train loss:0.002798669136828271\n",
      "train loss:0.01038337839868379\n",
      "train loss:0.001172511868234308\n",
      "train loss:0.0012203741828169155\n",
      "train loss:0.003899722222404362\n",
      "train loss:0.011104870969456379\n",
      "train loss:0.00027064268374604614\n",
      "train loss:0.0191377646375981\n",
      "train loss:0.006491916403808962\n",
      "train loss:0.005110888984472476\n",
      "train loss:0.0008693791018871058\n",
      "train loss:0.003003553111802649\n",
      "train loss:0.008136448224890057\n",
      "train loss:0.0008580505704488704\n",
      "train loss:0.00700595907268398\n",
      "train loss:0.003288274481245531\n",
      "train loss:0.0011232340029169584\n",
      "train loss:0.0038398132976369863\n",
      "train loss:0.0031185583443721493\n",
      "train loss:0.016914587013705466\n",
      "train loss:0.0021744887917969414\n",
      "train loss:0.0004652109650460544\n",
      "train loss:0.004419289052804748\n",
      "train loss:0.004333429485008645\n",
      "train loss:0.00011842723669609977\n",
      "train loss:0.0013703087738841848\n",
      "train loss:0.0006623448760795245\n",
      "train loss:0.0006560849345195268\n",
      "train loss:0.007277308738909539\n",
      "train loss:0.0020205936308993716\n",
      "train loss:0.00035954900759320755\n",
      "train loss:0.0031901538010466555\n",
      "train loss:0.001976141406866479\n",
      "train loss:0.006485123186486295\n",
      "train loss:0.0011308689397987667\n",
      "train loss:0.00038528244662359003\n",
      "train loss:0.000999693618658313\n",
      "train loss:0.00011477149430813757\n",
      "train loss:0.0011367982868322182\n",
      "train loss:0.00027075760629420456\n",
      "train loss:0.00040515611832478703\n",
      "train loss:0.0016818531800929725\n",
      "train loss:0.0004887608930266842\n",
      "train loss:0.0015309447902025044\n",
      "train loss:0.0008959012796849069\n",
      "train loss:0.0030598908191955365\n",
      "train loss:0.0002610931874631406\n",
      "train loss:0.0015932778563675742\n",
      "train loss:0.0002678891883199317\n",
      "train loss:0.005234005538823049\n",
      "train loss:0.0008781479709215217\n",
      "train loss:0.00043620923522993293\n",
      "train loss:0.00016197461798726518\n",
      "train loss:0.0004199925155574654\n",
      "train loss:0.000580432795417827\n",
      "train loss:0.0034289483205924326\n",
      "train loss:0.0018311012972719448\n",
      "train loss:0.0036341277484534286\n",
      "train loss:0.0002686722786884628\n",
      "train loss:0.0062396438992021516\n",
      "train loss:0.0009981615724713186\n",
      "train loss:0.0003620108310126012\n",
      "train loss:0.0026089457276757943\n",
      "train loss:0.0013202186061581436\n",
      "train loss:0.0015504527027539342\n",
      "train loss:0.0005691498417411832\n",
      "train loss:0.0035440449578956444\n",
      "train loss:0.00304124905207581\n",
      "train loss:0.0014396518773982126\n",
      "train loss:0.0025981959232923334\n",
      "train loss:0.0004349203345714941\n",
      "train loss:0.00035038880281646785\n",
      "train loss:0.0019930776255773423\n",
      "train loss:0.003823623991660903\n",
      "train loss:0.00079575413875735\n",
      "train loss:0.0014422193685987195\n",
      "train loss:0.00041967454307620915\n",
      "train loss:0.007595967019564235\n",
      "train loss:0.0014384520232077638\n",
      "train loss:0.004293121120447568\n",
      "train loss:0.00225947473970565\n",
      "train loss:0.00026191741884427563\n",
      "train loss:0.001212965291896717\n",
      "train loss:0.0019581875710096594\n",
      "train loss:0.031026726804253647\n",
      "train loss:0.001406185033967591\n",
      "train loss:0.0016561278875189059\n",
      "train loss:0.0004208179451236881\n",
      "train loss:0.003231536634042441\n",
      "train loss:0.00047240291577439227\n",
      "train loss:0.0017277757550817649\n",
      "train loss:0.007942206641962182\n",
      "train loss:0.001019081537340272\n",
      "train loss:0.004442949644364855\n",
      "train loss:0.011793284192161739\n",
      "train loss:0.0009023023692496299\n",
      "train loss:0.0036063540381972453\n",
      "train loss:0.0011503847556553343\n",
      "train loss:0.00038962714454894993\n",
      "train loss:0.0011384879065708376\n",
      "train loss:0.00023288667733695122\n",
      "train loss:0.01806488030386748\n",
      "train loss:0.003578160984761398\n",
      "train loss:0.005824998939462724\n",
      "train loss:0.02117996942425185\n",
      "=== epoch:15, train acc:0.998, test acc:0.984 ===\n",
      "train loss:0.009006632893874022\n",
      "train loss:0.0034972008461527414\n",
      "train loss:0.0018406510575608816\n",
      "train loss:0.007455893060369061\n",
      "train loss:0.0033213295152160643\n",
      "train loss:0.004423107407527043\n",
      "train loss:0.027655426124380184\n",
      "train loss:0.0017806256759229824\n",
      "train loss:0.0020117597754995336\n",
      "train loss:0.0005045828806573943\n",
      "train loss:0.005153478450357146\n",
      "train loss:0.002085297946251189\n",
      "train loss:0.00046551251843839146\n",
      "train loss:0.003770278668060916\n",
      "train loss:8.894587017296252e-05\n",
      "train loss:0.004092586756522691\n",
      "train loss:0.0011460283741123413\n",
      "train loss:0.0010633913831503492\n",
      "train loss:0.006454194659114565\n",
      "train loss:0.00461213113277943\n",
      "train loss:0.0010195169846498122\n",
      "train loss:0.001313492026979511\n",
      "train loss:0.004824062928415312\n",
      "train loss:0.0007556138840688753\n",
      "train loss:0.0005831981042336629\n",
      "train loss:0.0005547286283047096\n",
      "train loss:0.006178273641599447\n",
      "train loss:0.002107319903607647\n",
      "train loss:0.002318658401606019\n",
      "train loss:0.0020994183473611806\n",
      "train loss:0.002132273920291558\n",
      "train loss:0.004086078478790992\n",
      "train loss:0.03569229123634768\n",
      "train loss:0.0021729349631441435\n",
      "train loss:0.003650982543635685\n",
      "train loss:0.0030483329725938986\n",
      "train loss:0.0005511867481165512\n",
      "train loss:0.0019489847661305747\n",
      "train loss:0.0028857026502672922\n",
      "train loss:0.03203725498722468\n",
      "train loss:0.0028698323242343417\n",
      "train loss:0.026501282882110223\n",
      "train loss:0.001022611394047267\n",
      "train loss:0.0013263869506631354\n",
      "train loss:0.006951352819742969\n",
      "train loss:0.00041140966047984573\n",
      "train loss:0.0019390306522934686\n",
      "train loss:0.002141791315618457\n",
      "train loss:0.0032996760097546746\n",
      "train loss:0.005434972671776086\n",
      "train loss:0.002460548174812383\n",
      "train loss:0.0028492874806019365\n",
      "train loss:0.0013540894752764579\n",
      "train loss:0.0007688632302395588\n",
      "train loss:0.0019944167955774413\n",
      "train loss:0.00036691061336824115\n",
      "train loss:0.004031080155535824\n",
      "train loss:0.0019760471663218125\n",
      "train loss:0.003306005673311058\n",
      "train loss:0.0004685415419018336\n",
      "train loss:0.00034855779967547345\n",
      "train loss:0.0028896072725952226\n",
      "train loss:0.0004697441254182075\n",
      "train loss:0.004290753928810887\n",
      "train loss:0.005052272359683561\n",
      "train loss:0.006533377332202789\n",
      "train loss:0.0010238455294247228\n",
      "train loss:0.019716752722194694\n",
      "train loss:0.0005930892380405726\n",
      "train loss:0.0007853888281292749\n",
      "train loss:0.005885842235097397\n",
      "train loss:0.004251886392923222\n",
      "train loss:0.0033696313684856488\n",
      "train loss:0.0013233011011792395\n",
      "train loss:0.004884923626078021\n",
      "train loss:0.001958035800135977\n",
      "train loss:0.003720561336449021\n",
      "train loss:0.002428906196942192\n",
      "train loss:0.0032591190412953673\n",
      "train loss:0.000694188973907908\n",
      "train loss:0.0007476082570319906\n",
      "train loss:0.003589452096058967\n",
      "train loss:0.003231179789463751\n",
      "train loss:0.003814582433870988\n",
      "train loss:0.000662659961614005\n",
      "train loss:0.0011481540086998223\n",
      "train loss:0.0021097876898270667\n",
      "train loss:0.000723293527200671\n",
      "train loss:0.0002410003751618897\n",
      "train loss:0.004774848687628618\n",
      "train loss:0.0016429142121600398\n",
      "train loss:0.0016171987580237267\n",
      "train loss:0.0013037797989028438\n",
      "train loss:0.001425847853804456\n",
      "train loss:0.0035017115875096223\n",
      "train loss:0.0003678945746153063\n",
      "train loss:0.0016031881733339576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009760654511223052\n",
      "train loss:0.006579902992151842\n",
      "train loss:0.0029119876702798624\n",
      "train loss:0.004573233847947705\n",
      "train loss:0.0013248855808204985\n",
      "train loss:0.0001171128961641809\n",
      "train loss:0.0006641845237992493\n",
      "train loss:0.0039056194285131346\n",
      "train loss:0.0019328343454761774\n",
      "train loss:0.006303176887492671\n",
      "train loss:0.0049327985728641124\n",
      "train loss:0.0011427769877242581\n",
      "train loss:0.004241790588336732\n",
      "train loss:0.000719467927294218\n",
      "train loss:0.0022065404001209024\n",
      "train loss:0.002001736445612692\n",
      "train loss:0.0015612295594490241\n",
      "train loss:0.003388564518492688\n",
      "train loss:0.0003759801742627949\n",
      "train loss:0.0006780847517059651\n",
      "train loss:0.0029054365828984473\n",
      "train loss:0.0005972428750189701\n",
      "train loss:0.0015505506120043692\n",
      "train loss:0.004415387708076535\n",
      "train loss:0.0013227675136427228\n",
      "train loss:0.0035797955379348956\n",
      "train loss:0.001910618125173642\n",
      "train loss:0.006643294721828424\n",
      "train loss:0.00026377578954847944\n",
      "train loss:0.00077317892822126\n",
      "train loss:0.00034147806754344717\n",
      "train loss:0.00018665381747313937\n",
      "train loss:0.0003202303861097716\n",
      "train loss:0.01203400737634845\n",
      "train loss:0.007162809919858052\n",
      "train loss:0.0026343512513901275\n",
      "train loss:0.0028648123252434103\n",
      "train loss:0.0028521865195519657\n",
      "train loss:0.004806547686516217\n",
      "train loss:0.0004936777741443252\n",
      "train loss:0.0012388394799142416\n",
      "train loss:0.0017937680250942332\n",
      "train loss:4.54901570279458e-05\n",
      "train loss:0.0002910473859257095\n",
      "train loss:0.0023569713452954405\n",
      "train loss:0.0027162576379664155\n",
      "train loss:0.00021066446512701788\n",
      "train loss:0.0005401524238414815\n",
      "train loss:0.004994603634922106\n",
      "train loss:0.0017831498987158792\n",
      "train loss:0.0023411216652543675\n",
      "train loss:0.0024178372508265734\n",
      "train loss:0.0024327299987289813\n",
      "train loss:0.0032188740931536684\n",
      "train loss:0.0006946838352323083\n",
      "train loss:0.0005441804695026232\n",
      "train loss:0.00048305416292519576\n",
      "train loss:0.0008693772427404924\n",
      "train loss:0.0007508025011733337\n",
      "train loss:0.0001632780102906844\n",
      "train loss:0.0018346370183653137\n",
      "train loss:0.0052616070106003285\n",
      "train loss:0.0007449241059992094\n",
      "train loss:0.026297464110817678\n",
      "train loss:0.001669238160765453\n",
      "train loss:0.00014735777949990444\n",
      "train loss:0.00106863287472139\n",
      "train loss:0.0033568627898378734\n",
      "train loss:0.004261665000544856\n",
      "train loss:0.0011057998443665701\n",
      "train loss:0.0017464550073410662\n",
      "train loss:0.022187653060742725\n",
      "train loss:0.006672244674257338\n",
      "train loss:0.003819088295160549\n",
      "train loss:0.0036167515045112063\n",
      "train loss:0.01109376827892517\n",
      "train loss:0.005688039617917076\n",
      "train loss:0.002464044359171272\n",
      "train loss:0.0009541535350976249\n",
      "train loss:0.04333262192428319\n",
      "train loss:0.0005983080314178432\n",
      "train loss:0.0018385598075193806\n",
      "train loss:0.0012373822371461805\n",
      "train loss:0.004961775076603972\n",
      "train loss:0.0009793857674068346\n",
      "train loss:0.00038713841765583416\n",
      "train loss:0.002519653264737152\n",
      "train loss:0.0014984778442918112\n",
      "train loss:0.006581053865310226\n",
      "train loss:0.0046736564352199686\n",
      "train loss:0.011406931669146282\n",
      "train loss:0.006284342650836582\n",
      "train loss:0.00044446373059015053\n",
      "train loss:0.002091407102988585\n",
      "train loss:0.0009097801092220247\n",
      "train loss:0.00024014810476712535\n",
      "train loss:0.0003175454315272462\n",
      "train loss:0.0002377017743073654\n",
      "train loss:0.011599128029415116\n",
      "train loss:0.0005053596015825382\n",
      "train loss:0.006367479233787839\n",
      "train loss:0.005608124670145581\n",
      "train loss:0.001879840165932095\n",
      "train loss:0.002422446506379965\n",
      "train loss:0.007154602010893273\n",
      "train loss:0.0020076637593550934\n",
      "train loss:0.0009982064881185007\n",
      "train loss:0.0040536795735215845\n",
      "train loss:0.0004961564591258626\n",
      "train loss:0.002211000752504605\n",
      "train loss:0.00012271791248529777\n",
      "train loss:0.0016881224316477417\n",
      "train loss:0.0019045361053657694\n",
      "train loss:0.003393208642025778\n",
      "train loss:0.004014041404266939\n",
      "train loss:0.00041540698770799693\n",
      "train loss:0.003867077200113556\n",
      "train loss:0.0002822136713513265\n",
      "train loss:0.0025153606958067815\n",
      "train loss:0.0024429441591998905\n",
      "train loss:0.0019884065714844286\n",
      "train loss:0.0032269379564226403\n",
      "train loss:0.004922486086883523\n",
      "train loss:0.004651437790329975\n",
      "train loss:0.0015612356511614741\n",
      "train loss:0.0009536450195832667\n",
      "train loss:0.000297023570348255\n",
      "train loss:0.001295770347138635\n",
      "train loss:0.0012340842276872643\n",
      "train loss:0.0017849064008420427\n",
      "train loss:0.0005967139663895708\n",
      "train loss:0.0032777794077879507\n",
      "train loss:0.002166997537508507\n",
      "train loss:0.006112135134083788\n",
      "train loss:0.0011904190932647935\n",
      "train loss:0.0004803815301566324\n",
      "train loss:0.0019945957403023126\n",
      "train loss:0.0007624078153475556\n",
      "train loss:0.0002445313749813875\n",
      "train loss:0.004132810429286917\n",
      "train loss:0.0003497644357455898\n",
      "train loss:0.0005900307762994697\n",
      "train loss:0.004601832661275696\n",
      "train loss:0.0003445523691231025\n",
      "train loss:0.002118998029946403\n",
      "train loss:0.007238439128767998\n",
      "train loss:0.0026747322610391213\n",
      "train loss:0.004245661679857142\n",
      "train loss:0.0006720891617450263\n",
      "train loss:0.0002779309741796421\n",
      "train loss:0.0030324010143140023\n",
      "train loss:0.002119462756271678\n",
      "train loss:0.0038654385498314986\n",
      "train loss:0.0007081082777522547\n",
      "train loss:0.010770249343274516\n",
      "train loss:0.0016972189395136781\n",
      "train loss:0.004424667067880469\n",
      "train loss:0.00035840277276906474\n",
      "train loss:0.001601762109997177\n",
      "train loss:0.00016334804720670557\n",
      "train loss:0.0030163472517822087\n",
      "train loss:0.0008345092228778556\n",
      "train loss:0.0009163441865280357\n",
      "train loss:0.0011831492395366144\n",
      "train loss:0.0002821255504704025\n",
      "train loss:0.0012029379132235992\n",
      "train loss:0.002532539339110639\n",
      "train loss:0.03293014938784524\n",
      "train loss:0.005441208129357381\n",
      "train loss:0.005624051877877691\n",
      "train loss:0.002086780927221849\n",
      "train loss:0.0021344634628843524\n",
      "train loss:0.007577578240917366\n",
      "train loss:0.007238060803038867\n",
      "train loss:0.0004097051398560031\n",
      "train loss:0.009836484296191305\n",
      "train loss:0.00047456691938127965\n",
      "train loss:0.0017401595893592697\n",
      "train loss:0.00021739584057528635\n",
      "train loss:0.02351450990228338\n",
      "train loss:0.0008278785254414768\n",
      "train loss:0.004500768735222239\n",
      "train loss:0.0004538960721416209\n",
      "train loss:0.001964869806964297\n",
      "train loss:0.0038282332571051305\n",
      "train loss:0.0015788289411920728\n",
      "train loss:0.0006106206314541759\n",
      "train loss:0.0012406109877766522\n",
      "train loss:0.0013335154210716007\n",
      "train loss:0.0014978967049200848\n",
      "train loss:0.004157585107058507\n",
      "train loss:0.005176958839733581\n",
      "train loss:0.00013289105656072708\n",
      "train loss:0.005314246669577673\n",
      "train loss:0.00033287087831355137\n",
      "train loss:0.003538746594157012\n",
      "train loss:0.005945088871373832\n",
      "train loss:0.0003761616017454887\n",
      "train loss:0.0008115698769074705\n",
      "train loss:0.0019176940052103653\n",
      "train loss:0.0036537592968502513\n",
      "train loss:0.0017814905924321914\n",
      "train loss:0.004833836070485261\n",
      "train loss:0.001332258670342662\n",
      "train loss:0.0022237476893738036\n",
      "train loss:0.09336368396572929\n",
      "train loss:0.0004949997070367606\n",
      "train loss:0.008023408788234352\n",
      "train loss:0.001832932526243343\n",
      "train loss:0.004095484192179682\n",
      "train loss:0.0026583964481827027\n",
      "train loss:0.0018717984986734728\n",
      "train loss:0.007017646646657664\n",
      "train loss:0.00017007891841281994\n",
      "train loss:0.0029170349568296977\n",
      "train loss:0.002123814467959831\n",
      "train loss:0.025719065660489013\n",
      "train loss:0.005190365394897866\n",
      "train loss:0.0012330115831644026\n",
      "train loss:0.000803596225996392\n",
      "train loss:0.003627041254376741\n",
      "train loss:0.0017619142456005161\n",
      "train loss:0.0016546421305259778\n",
      "train loss:0.008455120796134693\n",
      "train loss:0.001728760357525182\n",
      "train loss:0.001799052430489384\n",
      "train loss:0.002747740109914893\n",
      "train loss:0.00172183802381318\n",
      "train loss:0.0013017368339450586\n",
      "train loss:0.000802335300088622\n",
      "train loss:0.0005201227307731727\n",
      "train loss:0.00045074598195583333\n",
      "train loss:0.00028576339970471927\n",
      "train loss:0.009655036266889596\n",
      "train loss:0.0018926682671448994\n",
      "train loss:0.004661983079605904\n",
      "train loss:0.0025046109319435627\n",
      "train loss:0.005192639977890903\n",
      "train loss:0.0032962214524186345\n",
      "train loss:0.004059139845173275\n",
      "train loss:0.0006895870798357856\n",
      "train loss:0.0024607927430559664\n",
      "train loss:0.00054471180191223\n",
      "train loss:0.007089112347435869\n",
      "train loss:0.0014272422149758967\n",
      "train loss:0.012602204322384163\n",
      "train loss:0.0010040731672150416\n",
      "train loss:0.0026707525453886836\n",
      "train loss:0.001274089512360771\n",
      "train loss:0.00016697775871427005\n",
      "train loss:0.0033251196764718157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008540975300881463\n",
      "train loss:0.002751066004167714\n",
      "train loss:0.011411777041529568\n",
      "train loss:0.0012857055330197464\n",
      "train loss:0.0012709079698119713\n",
      "train loss:0.0002592614388709237\n",
      "train loss:0.0008871456139673475\n",
      "train loss:0.01453940505074329\n",
      "train loss:0.01432393008910839\n",
      "train loss:0.0038350138384367375\n",
      "train loss:0.00043279212200499566\n",
      "train loss:0.0001529149392843649\n",
      "train loss:0.0009086613566050124\n",
      "train loss:0.0004944076126236587\n",
      "train loss:0.0008112557400048474\n",
      "train loss:0.0033742200186471687\n",
      "train loss:0.003167515406935761\n",
      "train loss:0.0022026802885497495\n",
      "train loss:0.0012738404131444373\n",
      "train loss:0.0012493175419161476\n",
      "train loss:0.02496089004962605\n",
      "train loss:0.0019988639787002324\n",
      "train loss:0.0010444260761435682\n",
      "train loss:0.005371748121377926\n",
      "train loss:0.0006358985267511856\n",
      "train loss:0.004884722997167881\n",
      "train loss:0.0008810568924565021\n",
      "train loss:0.03793154260535038\n",
      "train loss:0.006468613470955964\n",
      "train loss:0.008085858834630243\n",
      "train loss:0.0017430708828971879\n",
      "train loss:0.0024674262828330924\n",
      "train loss:0.0006816378834651148\n",
      "train loss:0.0029594705055528874\n",
      "train loss:0.0008902602547416469\n",
      "train loss:0.0022008013540878633\n",
      "train loss:0.00023518215666296479\n",
      "train loss:0.0034092652788854654\n",
      "train loss:0.0007596140906210254\n",
      "train loss:0.003914679526316404\n",
      "train loss:0.004114353998916931\n",
      "train loss:0.000633461865618406\n",
      "train loss:0.0026192762313251004\n",
      "train loss:0.000654819274985583\n",
      "train loss:4.6421238598411104e-05\n",
      "train loss:0.021020287106934484\n",
      "train loss:0.0012476301527967865\n",
      "train loss:0.0037869954982053737\n",
      "train loss:0.0060791159231427085\n",
      "train loss:0.000339841482594125\n",
      "train loss:0.0029109537776054245\n",
      "train loss:0.00026840761309994865\n",
      "train loss:0.0032726275812309034\n",
      "train loss:0.004467391942088631\n",
      "train loss:0.007484307054284347\n",
      "train loss:0.0033971830277276754\n",
      "train loss:0.0030144433787852704\n",
      "train loss:0.006334228551887245\n",
      "train loss:0.0034870647687156235\n",
      "train loss:0.000877974336522734\n",
      "train loss:0.0030885550153678366\n",
      "train loss:0.00020974388862535898\n",
      "train loss:0.003924052758665417\n",
      "train loss:0.0007395555373800298\n",
      "train loss:0.005977024795515881\n",
      "train loss:0.0030095790276041933\n",
      "train loss:0.0009668691682769212\n",
      "train loss:0.0008972393395961391\n",
      "train loss:0.004255989199305079\n",
      "train loss:0.00356987781173883\n",
      "train loss:0.0030914896938472273\n",
      "train loss:0.0006571460166652344\n",
      "train loss:0.005070267035348631\n",
      "train loss:0.018184089158250358\n",
      "train loss:0.0027018749382667134\n",
      "train loss:0.003437801276784933\n",
      "train loss:0.003715161320846643\n",
      "train loss:0.0016560517532230065\n",
      "train loss:0.0013280477158567271\n",
      "train loss:0.0026836900460622203\n",
      "train loss:0.0017077126483659238\n",
      "train loss:0.0022125776142182625\n",
      "train loss:0.002073720600115141\n",
      "train loss:0.00513182269941838\n",
      "train loss:0.0030839991947152114\n",
      "train loss:0.009054202492090883\n",
      "train loss:0.0009635959470200736\n",
      "train loss:0.00048669555442919314\n",
      "train loss:0.01441777834239151\n",
      "train loss:0.001296940053382338\n",
      "train loss:0.00019852626470253453\n",
      "train loss:0.0025543323037024684\n",
      "train loss:0.002837155110403242\n",
      "train loss:0.0016344606031279834\n",
      "train loss:0.002264517134163839\n",
      "train loss:0.0068808103034844435\n",
      "train loss:0.001573387247599156\n",
      "train loss:0.0009040564221330168\n",
      "train loss:0.0018149482502522493\n",
      "train loss:0.0036381266961772163\n",
      "train loss:0.004538015319359916\n",
      "train loss:0.005035891621576984\n",
      "train loss:0.0019907269935276746\n",
      "train loss:0.002017632868427638\n",
      "train loss:0.0003376395129164223\n",
      "train loss:0.004250414471279204\n",
      "train loss:0.00073649227709334\n",
      "train loss:0.004072942081152537\n",
      "train loss:0.00618400245567664\n",
      "train loss:0.001719801428661401\n",
      "train loss:0.0003067662656803358\n",
      "train loss:0.0012239768016223957\n",
      "train loss:0.0010729633963915673\n",
      "train loss:0.0009552372492707318\n",
      "train loss:0.002307163882238578\n",
      "train loss:0.001950342202761692\n",
      "train loss:0.002411957461374364\n",
      "train loss:0.0016378748792065983\n",
      "train loss:0.0009546285867475505\n",
      "train loss:0.0006214702291959857\n",
      "train loss:0.0010001905335265012\n",
      "train loss:0.0008204077118675751\n",
      "train loss:0.009755450580512855\n",
      "train loss:0.0001903123891727927\n",
      "train loss:0.004200354628980375\n",
      "train loss:0.0027604361660688633\n",
      "train loss:0.00029286042827938227\n",
      "train loss:0.0005516966256994563\n",
      "train loss:0.0014559826882547993\n",
      "train loss:0.00257684105621633\n",
      "train loss:0.0005651024011021923\n",
      "train loss:0.0018291877188759745\n",
      "train loss:0.0007087506808554704\n",
      "train loss:7.468837267471559e-05\n",
      "train loss:0.0032640617906304764\n",
      "train loss:0.002967506111034057\n",
      "train loss:0.0080830267723143\n",
      "train loss:0.004210038088338538\n",
      "train loss:0.0006411091677718731\n",
      "train loss:0.0120474050501828\n",
      "train loss:0.00035965416821417186\n",
      "train loss:0.0028987700975845274\n",
      "train loss:0.00018021232721220383\n",
      "train loss:0.00042437764722072014\n",
      "train loss:0.00024181133837879507\n",
      "train loss:0.01142722196238535\n",
      "train loss:0.0012314548229350095\n",
      "train loss:0.0009499771522179592\n",
      "train loss:0.006243112298255499\n",
      "train loss:0.002362383396634422\n",
      "train loss:0.0020787905891596157\n",
      "train loss:0.0005510104956152554\n",
      "train loss:0.006439275463046853\n",
      "train loss:0.0005515276789791316\n",
      "train loss:0.0013443931343504803\n",
      "train loss:0.001062121411094596\n",
      "train loss:0.006743778839509994\n",
      "train loss:0.0013028554846842494\n",
      "train loss:0.0008597388523818709\n",
      "train loss:0.0013673791792008214\n",
      "train loss:0.0037063689345883414\n",
      "train loss:0.004719732518764432\n",
      "train loss:0.0064264208086367205\n",
      "train loss:0.0031352809116310305\n",
      "train loss:0.0008546214349820076\n",
      "train loss:0.0060670760309599015\n",
      "train loss:0.00035446268236900076\n",
      "train loss:0.0014030218854820175\n",
      "train loss:0.0016821737120807595\n",
      "train loss:0.001726611722175618\n",
      "train loss:0.003917351477840687\n",
      "train loss:0.001525536483720045\n",
      "train loss:0.00014522941547607\n",
      "train loss:0.0015244848978759821\n",
      "train loss:0.0013706269844927252\n",
      "train loss:0.0037154497503124094\n",
      "train loss:0.003505832866147948\n",
      "train loss:0.005305322656371237\n",
      "train loss:0.0002735722288329778\n",
      "train loss:0.0003064370559184792\n",
      "train loss:0.0006929560842212662\n",
      "train loss:0.00377547035161062\n",
      "train loss:0.0006747642866752328\n",
      "train loss:0.004359187437711667\n",
      "train loss:0.00014342558948673252\n",
      "train loss:0.01111712413121891\n",
      "train loss:0.006947137436348666\n",
      "train loss:0.00038265969843203707\n",
      "train loss:0.0139033224169101\n",
      "train loss:0.04044170984124208\n",
      "train loss:0.0015554742453320347\n",
      "train loss:0.00406172460560505\n",
      "train loss:0.007849014669595464\n",
      "train loss:0.004256754544050466\n",
      "train loss:0.001866666711561495\n",
      "train loss:0.0008261941700896475\n",
      "train loss:0.008367512473671424\n",
      "train loss:0.002150767015195526\n",
      "train loss:0.005457283425336241\n",
      "train loss:0.0012301394610151146\n",
      "train loss:0.0041831036897274805\n",
      "train loss:0.0028716120890742393\n",
      "train loss:0.0012715427837023772\n",
      "train loss:0.006865436908539366\n",
      "train loss:0.003915332581682841\n",
      "train loss:0.0008578910308330535\n",
      "train loss:0.001559247895371291\n",
      "train loss:0.0194029531357241\n",
      "train loss:0.00034660598961739546\n",
      "train loss:0.0028219334386352024\n",
      "train loss:0.030317096445354536\n",
      "train loss:0.006241760572641995\n",
      "train loss:0.008856730500684308\n",
      "train loss:0.0010355349035072218\n",
      "train loss:0.07664395691264204\n",
      "train loss:0.005982806238212651\n",
      "train loss:0.001054270985224933\n",
      "train loss:0.004915320897193953\n",
      "train loss:0.002375332238082219\n",
      "train loss:0.018517285378494154\n",
      "train loss:0.00039945998008179335\n",
      "train loss:0.0031172503228736603\n",
      "train loss:0.00685809081829597\n",
      "train loss:0.0008906255536665012\n",
      "train loss:0.004670305409112224\n",
      "train loss:0.005110897633670572\n",
      "train loss:0.005927498966507604\n",
      "train loss:0.0008753323203562186\n",
      "train loss:0.0028703465515918084\n",
      "train loss:0.002826277545825203\n",
      "train loss:0.0007383282095294297\n",
      "train loss:0.004579270360499909\n",
      "train loss:0.010730614890492597\n",
      "train loss:0.002956811837082489\n",
      "train loss:0.0013804295920137538\n",
      "train loss:0.00048127408714177244\n",
      "train loss:0.003892787760036635\n",
      "train loss:0.0014909684202491337\n",
      "train loss:0.004653264071544886\n",
      "train loss:0.0005508720276984834\n",
      "train loss:4.080528487769631e-05\n",
      "train loss:0.0019427598433642756\n",
      "train loss:0.00037318687617258535\n",
      "train loss:0.006762485816914914\n",
      "train loss:0.0033551626267391875\n",
      "train loss:0.00040476629361894614\n",
      "train loss:0.0022507491226568003\n",
      "train loss:0.0009950024615091705\n",
      "train loss:0.002343916022206016\n",
      "train loss:0.00026093850546072953\n",
      "train loss:0.0005960526870583321\n",
      "train loss:0.0010317717762118473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:16, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.00021993808061083778\n",
      "train loss:0.0026040145438072197\n",
      "train loss:0.0004588038002154221\n",
      "train loss:0.0002507158916296612\n",
      "train loss:0.0024834534951051483\n",
      "train loss:0.001979689649364427\n",
      "train loss:0.005333937116549368\n",
      "train loss:0.0016063539822083204\n",
      "train loss:0.023428197071957205\n",
      "train loss:0.00026124399985685815\n",
      "train loss:0.0014030226705324619\n",
      "train loss:0.010066467105780736\n",
      "train loss:0.013027343644329482\n",
      "train loss:0.019604779421165754\n",
      "train loss:0.005449719112877369\n",
      "train loss:0.0028663456512019636\n",
      "train loss:0.003914366507483588\n",
      "train loss:0.0019982719723071578\n",
      "train loss:0.0015329619682800922\n",
      "train loss:0.004289453146980721\n",
      "train loss:0.0003885563480340664\n",
      "train loss:0.001504600149519598\n",
      "train loss:0.012096158567894113\n",
      "train loss:0.005410677354805053\n",
      "train loss:0.002093584532863001\n",
      "train loss:0.002924299993767099\n",
      "train loss:0.002888329796969945\n",
      "train loss:0.0014406468571364728\n",
      "train loss:0.0013967551030979466\n",
      "train loss:0.004171934228158234\n",
      "train loss:0.0017997002472310269\n",
      "train loss:0.0035086343656249032\n",
      "train loss:0.0032024264398669883\n",
      "train loss:0.001718217102779713\n",
      "train loss:0.0012644050408931887\n",
      "train loss:0.0046115556354083785\n",
      "train loss:0.005460031765126035\n",
      "train loss:0.001726100585468978\n",
      "train loss:0.0008766973094255059\n",
      "train loss:0.003895129265500817\n",
      "train loss:0.016676587554520644\n",
      "train loss:0.0028170614784591218\n",
      "train loss:0.012701298477503432\n",
      "train loss:0.0017533323563955184\n",
      "train loss:0.0002077837784349639\n",
      "train loss:0.001451362924113595\n",
      "train loss:0.0016494031134269775\n",
      "train loss:0.0004358035119104862\n",
      "train loss:0.0005639132280606078\n",
      "train loss:0.0006351755774369733\n",
      "train loss:0.002215695979433144\n",
      "train loss:0.0017867860904446306\n",
      "train loss:0.0017545383703612676\n",
      "train loss:0.0021982504242423788\n",
      "train loss:0.0006710381821120117\n",
      "train loss:0.00047215770975980807\n",
      "train loss:0.0013696321633744595\n",
      "train loss:0.0017134879371714126\n",
      "train loss:0.00222990560761093\n",
      "train loss:0.01313327515748739\n",
      "train loss:0.0011302271032770845\n",
      "train loss:0.0018276856245243835\n",
      "train loss:0.003266732648133214\n",
      "train loss:0.0001087347402002432\n",
      "train loss:0.011261185312181832\n",
      "train loss:0.006491341881747905\n",
      "train loss:0.0022823378290523634\n",
      "train loss:0.0006812632495669835\n",
      "train loss:0.0012845415744001496\n",
      "train loss:0.002013914769281021\n",
      "train loss:0.00470089824312327\n",
      "train loss:0.0016794939096534149\n",
      "train loss:0.0021277327470245948\n",
      "train loss:0.0009670613364715585\n",
      "train loss:0.0008327482187327966\n",
      "train loss:0.00035112146923338113\n",
      "train loss:0.0040267756921085925\n",
      "train loss:0.0036415556335039987\n",
      "train loss:0.03868631209101954\n",
      "train loss:0.001120689136648819\n",
      "train loss:0.0015820882959438414\n",
      "train loss:0.0008518204460739\n",
      "train loss:0.000892279398301361\n",
      "train loss:0.008646428830869458\n",
      "train loss:0.001772993915458206\n",
      "train loss:0.010287608663758606\n",
      "train loss:0.00014905007809865145\n",
      "train loss:0.0043805203608217776\n",
      "train loss:0.0035022278839105213\n",
      "train loss:0.002599856873149722\n",
      "train loss:0.0003649965866972875\n",
      "train loss:0.042416712773116406\n",
      "train loss:0.003284127552358123\n",
      "train loss:0.0007970871563303904\n",
      "train loss:0.0016168462344661927\n",
      "train loss:0.0009892435261318968\n",
      "train loss:0.013549932999011152\n",
      "train loss:0.00040708524984101936\n",
      "train loss:0.0023017452757069738\n",
      "train loss:0.0023874496001936776\n",
      "train loss:0.0025691154120607174\n",
      "train loss:0.001058478156559057\n",
      "train loss:0.003089626030685212\n",
      "train loss:0.002519839216208404\n",
      "train loss:0.004934918045468109\n",
      "train loss:0.0035035354336871182\n",
      "train loss:0.002829456196716118\n",
      "train loss:0.0012103042168941124\n",
      "train loss:0.0005077527649460728\n",
      "train loss:0.0009602063053215649\n",
      "train loss:0.003205489842532681\n",
      "train loss:0.0009491788970328104\n",
      "train loss:0.0013631668551294844\n",
      "train loss:0.005998547521296583\n",
      "train loss:0.00288008016821763\n",
      "train loss:0.00029579866386237366\n",
      "train loss:8.653380871432918e-05\n",
      "train loss:0.0002609892119284724\n",
      "train loss:0.0003581248217241487\n",
      "train loss:0.002318349815013145\n",
      "train loss:0.035193373777879615\n",
      "train loss:0.004535153427994935\n",
      "train loss:0.0002950592515347248\n",
      "train loss:0.0008123147380057801\n",
      "train loss:0.001781203836801775\n",
      "train loss:0.0006781198499849688\n",
      "train loss:0.001147442865232743\n",
      "train loss:0.001718145364960978\n",
      "train loss:0.004275653014773578\n",
      "train loss:0.011233595354678091\n",
      "train loss:0.0011377492638343718\n",
      "train loss:0.014902403370608868\n",
      "train loss:0.0015512481013801253\n",
      "train loss:0.0025997111087305118\n",
      "train loss:0.0010314536299656318\n",
      "train loss:0.003894281218826577\n",
      "train loss:0.008688573171515298\n",
      "train loss:0.0015761207541291464\n",
      "train loss:0.00030799546663868926\n",
      "train loss:0.00028489437069106183\n",
      "train loss:0.000374730386080022\n",
      "train loss:0.0031223555524727744\n",
      "train loss:0.0008848074912745962\n",
      "train loss:0.0015119370430504815\n",
      "train loss:0.007364053158575344\n",
      "train loss:0.005730373932917715\n",
      "train loss:0.0025180169456554486\n",
      "train loss:0.000845893549411747\n",
      "train loss:0.0022128878527262114\n",
      "train loss:0.0006793517142892025\n",
      "train loss:0.0054461207956953105\n",
      "train loss:0.0013825336604114757\n",
      "train loss:0.022879491974815477\n",
      "train loss:0.005130295571409247\n",
      "train loss:0.03210646130519594\n",
      "train loss:0.001158621720187301\n",
      "train loss:0.00025856627011118895\n",
      "train loss:0.020504677158221688\n",
      "train loss:0.0009756881072964721\n",
      "train loss:0.004079948568847479\n",
      "train loss:0.002363601257694748\n",
      "train loss:0.0020791592786237796\n",
      "train loss:0.0005314711621161665\n",
      "train loss:0.0004512032721088039\n",
      "train loss:0.000426261119743849\n",
      "train loss:0.0001728105164597904\n",
      "train loss:0.0007119801567559092\n",
      "train loss:0.0016139954160252932\n",
      "train loss:0.0008497789798176556\n",
      "train loss:0.005939406531146757\n",
      "train loss:0.0012106510284791974\n",
      "train loss:0.0013517494732352994\n",
      "train loss:0.009365066599856474\n",
      "train loss:0.013067530508871585\n",
      "train loss:0.03137301992146477\n",
      "train loss:0.0028874730851534873\n",
      "train loss:0.0024393133686260626\n",
      "train loss:0.0006128172126175127\n",
      "train loss:0.0003959094893787745\n",
      "train loss:0.0030939023966626766\n",
      "train loss:0.0016879882977041106\n",
      "train loss:0.002078799839499212\n",
      "train loss:0.0014832877074872294\n",
      "train loss:0.00015252219446101726\n",
      "train loss:0.004645897797868178\n",
      "train loss:0.05491390904571616\n",
      "train loss:0.004601600189469974\n",
      "train loss:0.001758624146237144\n",
      "train loss:0.009129270023001977\n",
      "train loss:0.009517433518776118\n",
      "train loss:0.004130653555206685\n",
      "train loss:0.006298694807661252\n",
      "train loss:0.0031359639127360277\n",
      "train loss:0.0002497229575768996\n",
      "train loss:0.0029881122467700773\n",
      "train loss:0.0020911406137866127\n",
      "train loss:0.000830427568990786\n",
      "train loss:0.002573033187249781\n",
      "train loss:9.908141474608003e-05\n",
      "train loss:0.00024626730056130777\n",
      "train loss:0.00118461849609536\n",
      "train loss:0.0036533506904600417\n",
      "train loss:0.005005055677233623\n",
      "train loss:0.0025553719656794343\n",
      "train loss:0.0034888391690770016\n",
      "train loss:0.003885076264601287\n",
      "train loss:0.0008762596828006014\n",
      "train loss:0.0007046459105012388\n",
      "train loss:0.0015656908524074088\n",
      "train loss:0.0011932586811794143\n",
      "train loss:0.00256784163486974\n",
      "train loss:0.0012835938088145624\n",
      "train loss:0.007082029273025415\n",
      "train loss:0.0012190114012060914\n",
      "train loss:0.000869058131430155\n",
      "train loss:0.0010953870092744932\n",
      "train loss:0.009929220459234278\n",
      "train loss:0.003980806537600547\n",
      "train loss:0.0005570598354182668\n",
      "train loss:0.004134836752639599\n",
      "train loss:0.0014857167209111166\n",
      "train loss:0.003205659437773026\n",
      "train loss:0.001216980320272112\n",
      "train loss:0.0003734296490924929\n",
      "train loss:0.0001284134450974924\n",
      "train loss:0.0026214093212839715\n",
      "train loss:0.002563948232776741\n",
      "train loss:0.0001735200950852791\n",
      "train loss:0.0008425355212744353\n",
      "train loss:0.005952166714304449\n",
      "train loss:0.0015192829017820822\n",
      "train loss:0.00021402221381712925\n",
      "train loss:0.004987008382796574\n",
      "train loss:0.003845086205048121\n",
      "train loss:0.002199361916823661\n",
      "train loss:0.00029140236388625144\n",
      "train loss:0.0012660337792161152\n",
      "train loss:0.0014626876159240284\n",
      "train loss:0.0008331210294567796\n",
      "train loss:0.005862690949926559\n",
      "train loss:0.0009396235912155533\n",
      "train loss:0.0017445494264112528\n",
      "train loss:0.0013618204914599323\n",
      "train loss:0.0006940978711873168\n",
      "train loss:0.010364423688178153\n",
      "train loss:0.0008757522386766052\n",
      "train loss:0.00112862659962036\n",
      "train loss:0.007513887262721793\n",
      "train loss:0.0017927854111298473\n",
      "train loss:0.002773615092329545\n",
      "train loss:0.005084930108166637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00033988344576192577\n",
      "train loss:0.0006969825617432113\n",
      "train loss:0.0044130450973617966\n",
      "train loss:0.005901466075349194\n",
      "train loss:0.029554770935387248\n",
      "train loss:0.001315829775462526\n",
      "train loss:0.0017066900916333633\n",
      "train loss:0.0009166992830980946\n",
      "train loss:0.0012515937983303515\n",
      "train loss:0.003185586008810916\n",
      "train loss:0.002029785356588937\n",
      "train loss:0.0008802432055818775\n",
      "train loss:0.0017192095398360033\n",
      "train loss:0.00039429548018577766\n",
      "train loss:0.003682295887988925\n",
      "train loss:0.0002708487741791454\n",
      "train loss:0.0008249940102666917\n",
      "train loss:0.0016343983682078516\n",
      "train loss:0.00013618739094439618\n",
      "train loss:0.0013637699959908505\n",
      "train loss:0.0014611178777614805\n",
      "train loss:0.00019829174471418885\n",
      "train loss:0.0009533756855872533\n",
      "train loss:8.73589709507312e-05\n",
      "train loss:0.003119708088978643\n",
      "train loss:0.0013441898861672975\n",
      "train loss:0.0005040632394434255\n",
      "train loss:0.0004392091673689006\n",
      "train loss:0.0002163988414586644\n",
      "train loss:0.00034884479742289633\n",
      "train loss:0.002754620586296695\n",
      "train loss:0.003822694159862555\n",
      "train loss:0.00017597102734121688\n",
      "train loss:0.002291850932653785\n",
      "train loss:0.00021405268317216703\n",
      "train loss:0.00032274019883232844\n",
      "train loss:0.0014317837879690642\n",
      "train loss:0.0006298674184041702\n",
      "train loss:0.0014464033124961877\n",
      "train loss:0.0013942294477138073\n",
      "train loss:0.0013244947438695535\n",
      "train loss:0.0008699231901899494\n",
      "train loss:0.0005036955966343896\n",
      "train loss:0.00074588265349481\n",
      "train loss:0.0030327578351496574\n",
      "train loss:0.0039045220568027315\n",
      "train loss:0.006172371520239969\n",
      "train loss:0.00271899235330571\n",
      "train loss:0.0004926558218103556\n",
      "train loss:0.001022799168748667\n",
      "train loss:0.001233853289988695\n",
      "train loss:0.0014463941350573249\n",
      "train loss:0.0005397094770088767\n",
      "train loss:0.0005161982411404244\n",
      "train loss:0.0033351502379482573\n",
      "train loss:0.0017188365656169576\n",
      "train loss:0.0011725144305544538\n",
      "train loss:0.00037677170814277643\n",
      "train loss:0.002760014541626253\n",
      "train loss:0.01681278175560087\n",
      "train loss:0.0019590209482139224\n",
      "train loss:0.004094106011346151\n",
      "train loss:0.003648302703253804\n",
      "train loss:0.0007579392663881786\n",
      "train loss:0.005815932695236908\n",
      "train loss:0.005332289377757239\n",
      "train loss:0.00010977301744086854\n",
      "train loss:0.0016007109784599534\n",
      "train loss:0.0006195524029228118\n",
      "train loss:0.003533333645131151\n",
      "train loss:0.001524050434769864\n",
      "train loss:0.002512021304652491\n",
      "train loss:0.0009584537549081617\n",
      "train loss:0.0024371143864839223\n",
      "train loss:0.00029921366013493174\n",
      "train loss:0.0005717771088393111\n",
      "train loss:0.0010507032102352906\n",
      "train loss:6.766479164174999e-05\n",
      "train loss:0.0003955807093848614\n",
      "train loss:0.0009837700540532655\n",
      "train loss:0.011327874641892237\n",
      "train loss:0.003041823128419564\n",
      "train loss:0.0019297557300956597\n",
      "train loss:0.0032600563206798988\n",
      "train loss:0.0014238080360951403\n",
      "train loss:0.0004960783451325358\n",
      "train loss:0.001684956432478131\n",
      "train loss:0.002003724183023423\n",
      "train loss:0.0002254980818643876\n",
      "train loss:0.0016893246011118268\n",
      "train loss:0.003943907141631756\n",
      "train loss:0.0009258792479020698\n",
      "train loss:0.00097875570692751\n",
      "train loss:0.00021351711417283198\n",
      "train loss:0.002410294756220823\n",
      "train loss:0.002152560050214564\n",
      "train loss:0.0021588125632855705\n",
      "train loss:0.00041955103428131324\n",
      "train loss:0.010909229040055604\n",
      "train loss:0.0010052233496536489\n",
      "train loss:0.0002761753833506332\n",
      "train loss:0.0012961231670606222\n",
      "train loss:0.009284044443624797\n",
      "train loss:0.00018421390794096443\n",
      "train loss:0.00021785134625071985\n",
      "train loss:0.004365987093174491\n",
      "train loss:0.00103247775052347\n",
      "train loss:0.005015493386303137\n",
      "train loss:0.0011365829733311864\n",
      "train loss:0.0042165584580561785\n",
      "train loss:0.000325446979550046\n",
      "train loss:0.0023368134258030912\n",
      "train loss:0.004238011705653377\n",
      "train loss:0.0008131680728917112\n",
      "train loss:0.0001824518482000988\n",
      "train loss:0.0017471966145353784\n",
      "train loss:0.015205199835899724\n",
      "train loss:0.0010163581717641378\n",
      "train loss:0.0028946383341051122\n",
      "train loss:0.004558322632380993\n",
      "train loss:0.001935845083441733\n",
      "train loss:0.0015679921266305646\n",
      "train loss:0.006870405981310113\n",
      "train loss:0.006932879339984717\n",
      "train loss:0.0029686629789524265\n",
      "train loss:0.0030938930621850404\n",
      "train loss:0.0019973135298004784\n",
      "train loss:0.002998853636076995\n",
      "train loss:0.0022200992912436994\n",
      "train loss:0.0010620417554029577\n",
      "train loss:0.0006390195077535962\n",
      "train loss:0.002722246275302464\n",
      "train loss:0.0035555274797207216\n",
      "train loss:0.004373859610197104\n",
      "train loss:9.218815963344864e-05\n",
      "train loss:0.0030896529747157985\n",
      "train loss:0.00213950512091964\n",
      "train loss:0.0003900291701546659\n",
      "train loss:0.0009547299588127487\n",
      "train loss:0.0018499710283797427\n",
      "train loss:7.923821554792497e-05\n",
      "train loss:0.0013657193725869746\n",
      "train loss:0.00248567194141853\n",
      "train loss:0.007100566515019942\n",
      "train loss:0.003278330541252051\n",
      "train loss:0.0008091913352446113\n",
      "train loss:0.0020175743652621073\n",
      "train loss:0.0017840158318581953\n",
      "train loss:4.673261304049042e-05\n",
      "train loss:0.0009716310698894346\n",
      "train loss:0.0033346220236092293\n",
      "train loss:0.0005573718399377108\n",
      "train loss:0.0022128142018026527\n",
      "train loss:9.557164020698324e-05\n",
      "train loss:0.002099666787471866\n",
      "train loss:0.00023573025937613116\n",
      "train loss:0.00021634215729608914\n",
      "train loss:0.0016985186846435276\n",
      "train loss:0.0004494298734842928\n",
      "train loss:0.00024405212829508433\n",
      "train loss:0.001580753311511443\n",
      "train loss:0.0025959787469585455\n",
      "train loss:0.0015665792345950999\n",
      "train loss:0.0012824577570113432\n",
      "train loss:0.0011343626088532758\n",
      "train loss:0.0020120743817899625\n",
      "train loss:0.002314958472654763\n",
      "train loss:0.002326435040424211\n",
      "train loss:0.0020415012518164256\n",
      "train loss:0.0014360695638727088\n",
      "train loss:0.00035646962516218064\n",
      "train loss:0.031079740114351214\n",
      "train loss:0.00366575047130507\n",
      "train loss:0.001304856186639078\n",
      "train loss:0.001405534485645623\n",
      "train loss:0.0007541146833907545\n",
      "train loss:0.001730666850404293\n",
      "train loss:9.670884027267813e-05\n",
      "train loss:0.00015800835372577375\n",
      "train loss:0.0050046909008099215\n",
      "train loss:0.002226610495607033\n",
      "train loss:0.0016959694158992697\n",
      "train loss:0.006733210057955357\n",
      "train loss:0.002352498003840028\n",
      "train loss:0.00011642441364185317\n",
      "train loss:0.0035475954369715125\n",
      "train loss:0.00417725160497045\n",
      "train loss:0.0028253246550807047\n",
      "train loss:0.003768754953830962\n",
      "train loss:7.262859875080027e-05\n",
      "train loss:0.0023175958113088794\n",
      "train loss:5.624804708737752e-05\n",
      "train loss:0.0001964667557815624\n",
      "train loss:0.0019253881903733801\n",
      "train loss:0.0017107191364228755\n",
      "train loss:0.0013127166109261972\n",
      "train loss:0.00285472910162112\n",
      "train loss:0.0007858750979341858\n",
      "train loss:0.002191514811112196\n",
      "train loss:0.001293922691341676\n",
      "train loss:0.0006802929606741036\n",
      "train loss:0.0005632898744014218\n",
      "train loss:0.0012533215212775434\n",
      "train loss:0.00021911319627682902\n",
      "train loss:0.001139300297042814\n",
      "train loss:0.0012724960939696772\n",
      "train loss:0.00021714793386059337\n",
      "train loss:0.003969673455794993\n",
      "train loss:0.002084385807756291\n",
      "train loss:0.0033369082037497957\n",
      "train loss:0.003551211452580015\n",
      "train loss:0.0038305354391661816\n",
      "train loss:0.00022532713098047624\n",
      "train loss:0.005013824544830161\n",
      "train loss:0.003192526969430241\n",
      "train loss:0.0023717927323396574\n",
      "train loss:0.0009033592688909393\n",
      "train loss:0.0005959435293899748\n",
      "train loss:0.0041978142071980515\n",
      "train loss:0.00044027400356234735\n",
      "train loss:0.0005769875455592302\n",
      "train loss:0.0010693067874341002\n",
      "train loss:0.005132731665445342\n",
      "train loss:0.0013440789287362948\n",
      "train loss:0.003052848091057985\n",
      "train loss:0.0029688099204460538\n",
      "train loss:0.004515035158828059\n",
      "train loss:0.0012190889357055034\n",
      "train loss:0.00547303531631099\n",
      "train loss:0.0005721496078820281\n",
      "train loss:0.00327370274277115\n",
      "train loss:0.014022629728313831\n",
      "train loss:0.0003155117372610153\n",
      "train loss:0.0067226281047787625\n",
      "train loss:0.003051135774269933\n",
      "train loss:0.007350961112278374\n",
      "train loss:0.0021139023225962717\n",
      "train loss:0.000960139577387961\n",
      "train loss:0.0006014774797227552\n",
      "train loss:0.0029900104194198235\n",
      "train loss:0.018678049256204407\n",
      "train loss:0.0003329464846927814\n",
      "train loss:0.0008876334725625725\n",
      "train loss:0.0006936089539139985\n",
      "train loss:0.0015031838457848093\n",
      "train loss:0.0009048737174584321\n",
      "train loss:0.005537360517350215\n",
      "train loss:0.0033394114695612593\n",
      "train loss:0.001268803903359034\n",
      "train loss:0.004045457272254474\n",
      "train loss:0.0038308094261982235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003661861073617033\n",
      "train loss:0.00275572743720884\n",
      "train loss:0.0005937825618985687\n",
      "train loss:0.0015343410456570106\n",
      "train loss:0.001829398312305061\n",
      "train loss:0.000888661581418924\n",
      "train loss:0.0028262469974280175\n",
      "train loss:0.001121022485375303\n",
      "train loss:0.0009144686563414685\n",
      "train loss:0.0006238285851749064\n",
      "train loss:0.04362299354636257\n",
      "train loss:0.0030562157158552676\n",
      "train loss:0.001817771796562657\n",
      "train loss:0.0013081997554423267\n",
      "train loss:0.0037101223714441412\n",
      "train loss:0.00040293343881603604\n",
      "train loss:0.007949644272790952\n",
      "train loss:0.0010942527877626914\n",
      "train loss:0.0012000698469182083\n",
      "train loss:0.0011538517704118116\n",
      "train loss:0.00153429628479998\n",
      "train loss:0.004630220711392281\n",
      "train loss:0.00448613902866286\n",
      "train loss:0.010879330829965207\n",
      "train loss:0.000422296588665453\n",
      "train loss:0.0016718763012114096\n",
      "train loss:0.0018033825913486932\n",
      "train loss:0.004554706765240914\n",
      "train loss:0.013080191905151773\n",
      "train loss:0.0005858066249743579\n",
      "train loss:0.0014586957682171404\n",
      "train loss:0.0026797034932270498\n",
      "train loss:3.657408426587153e-05\n",
      "train loss:0.004285338855688706\n",
      "train loss:0.006693673730744377\n",
      "train loss:0.007563600567480907\n",
      "train loss:0.0013171329733462174\n",
      "train loss:0.0022154240465205952\n",
      "train loss:0.0002726276319045068\n",
      "train loss:0.0005557824579142753\n",
      "train loss:0.00012020102218731282\n",
      "train loss:0.004178123216846453\n",
      "train loss:0.0010239503836894758\n",
      "train loss:0.012280779636377663\n",
      "train loss:0.0019676269142277023\n",
      "train loss:0.0047941117213882115\n",
      "train loss:0.0014203737644191855\n",
      "train loss:0.0024901976210681283\n",
      "train loss:0.011652747939148597\n",
      "train loss:0.00010562820707915074\n",
      "train loss:0.0014800543032402371\n",
      "train loss:0.0009373696953099132\n",
      "train loss:0.0009650050301359472\n",
      "train loss:0.0013811048556878003\n",
      "train loss:0.0014485968302828743\n",
      "train loss:0.003556478635766208\n",
      "train loss:0.006860295638858209\n",
      "train loss:0.0015537320033425272\n",
      "train loss:0.003171768832968484\n",
      "train loss:0.0023635741420199976\n",
      "train loss:0.001469387730585663\n",
      "train loss:0.00533376518252803\n",
      "train loss:0.001361540709184725\n",
      "train loss:0.002147279564411406\n",
      "train loss:0.0009638219833538741\n",
      "train loss:0.0021238166672563567\n",
      "train loss:0.0020271242209629666\n",
      "train loss:0.0015248169960406163\n",
      "train loss:0.0005883591200337669\n",
      "train loss:0.0028976674049217806\n",
      "train loss:0.0008231552048359032\n",
      "train loss:0.007567863758098246\n",
      "train loss:0.000878547047086837\n",
      "train loss:0.00034981907254876606\n",
      "train loss:0.0037958374777118096\n",
      "train loss:0.0004769950099024453\n",
      "train loss:0.0026536143895292603\n",
      "train loss:0.010173386506597437\n",
      "train loss:0.0021585274062099185\n",
      "train loss:0.0012115393913238839\n",
      "train loss:0.00015256730944197212\n",
      "train loss:0.01808058547094266\n",
      "train loss:0.0007182843066620731\n",
      "train loss:0.0004598305515617946\n",
      "train loss:0.00193466461895661\n",
      "train loss:0.00046563023154370156\n",
      "train loss:0.005197244308820319\n",
      "train loss:0.0036772680355047992\n",
      "train loss:0.00014393586395756178\n",
      "train loss:0.0022933041963218662\n",
      "train loss:0.0019926172302552098\n",
      "train loss:0.0015556701742511989\n",
      "train loss:0.0011848589856154575\n",
      "train loss:0.0022120570859163564\n",
      "train loss:0.0033423685661870413\n",
      "train loss:0.00019422514179168293\n",
      "train loss:0.001967686177690928\n",
      "train loss:0.003663577598796638\n",
      "=== epoch:17, train acc:0.993, test acc:0.984 ===\n",
      "train loss:0.020670966211730965\n",
      "train loss:0.0017798898469821168\n",
      "train loss:0.004436343620608782\n",
      "train loss:0.0012614662751613765\n",
      "train loss:0.00041890986589578213\n",
      "train loss:0.002430124407932997\n",
      "train loss:0.001108668830495926\n",
      "train loss:0.002650096964665641\n",
      "train loss:0.002311495517400472\n",
      "train loss:0.0003413544589691361\n",
      "train loss:0.0008217437592115536\n",
      "train loss:0.0004185626812419866\n",
      "train loss:0.0057706573592051\n",
      "train loss:0.012781943599009188\n",
      "train loss:0.00854325116050724\n",
      "train loss:0.004917608655353839\n",
      "train loss:0.0004301678061127199\n",
      "train loss:0.0022708257043299435\n",
      "train loss:0.0017447942675737217\n",
      "train loss:0.0033514059096988987\n",
      "train loss:0.0026902166703352314\n",
      "train loss:0.006980752026296527\n",
      "train loss:0.0027517675936013907\n",
      "train loss:0.03243255393853692\n",
      "train loss:0.0007778787702751724\n",
      "train loss:0.0013121940086597778\n",
      "train loss:0.003194604049552275\n",
      "train loss:0.000670713719878322\n",
      "train loss:0.004168251419962212\n",
      "train loss:0.0003057020989625085\n",
      "train loss:0.001049760956627475\n",
      "train loss:0.007007974958973908\n",
      "train loss:0.0008647802715477782\n",
      "train loss:0.0036449433426206136\n",
      "train loss:0.003135204564064622\n",
      "train loss:0.0022440165544335114\n",
      "train loss:0.0018612554953596975\n",
      "train loss:0.0010975729627349972\n",
      "train loss:0.00016415654399659432\n",
      "train loss:0.006987908232259191\n",
      "train loss:0.0010990089395800354\n",
      "train loss:0.015651838432362175\n",
      "train loss:0.0008953986233035277\n",
      "train loss:0.0003515075560766776\n",
      "train loss:0.02096627187917712\n",
      "train loss:0.0031387187928152865\n",
      "train loss:0.0002449216946535919\n",
      "train loss:0.0007005597358212577\n",
      "train loss:0.004786444860854885\n",
      "train loss:0.0030523044064112966\n",
      "train loss:0.0007361998949831556\n",
      "train loss:0.0067607410167501445\n",
      "train loss:0.0010213592427180819\n",
      "train loss:0.0016002230850041246\n",
      "train loss:0.0016395174248787956\n",
      "train loss:0.0017139069310774643\n",
      "train loss:0.001568221353300461\n",
      "train loss:0.007393784989283415\n",
      "train loss:0.0064844178507039284\n",
      "train loss:0.003603413875187676\n",
      "train loss:0.014677212550724066\n",
      "train loss:0.0018565165494198784\n",
      "train loss:0.008944681808551576\n",
      "train loss:0.003988789327685953\n",
      "train loss:0.0012650827809455787\n",
      "train loss:0.009040913062392814\n",
      "train loss:0.0010368453549244089\n",
      "train loss:0.006632066244170599\n",
      "train loss:0.005642769351918402\n",
      "train loss:0.0001737587670938635\n",
      "train loss:0.00011323782424145702\n",
      "train loss:0.001262044746677757\n",
      "train loss:0.004744747989886292\n",
      "train loss:0.003433298608583261\n",
      "train loss:0.0009717779251607368\n",
      "train loss:0.0009683203623730741\n",
      "train loss:0.0016733272712507342\n",
      "train loss:0.0012919319625777088\n",
      "train loss:6.193572242022836e-05\n",
      "train loss:0.00023760137476158298\n",
      "train loss:0.002179186397167839\n",
      "train loss:0.002564847313822703\n",
      "train loss:0.000935024410501025\n",
      "train loss:0.0037481984266373365\n",
      "train loss:0.00018941870290946537\n",
      "train loss:0.0008160674111409753\n",
      "train loss:0.001568974531504177\n",
      "train loss:0.003284741159768062\n",
      "train loss:0.03911856598083036\n",
      "train loss:0.00015133296195903744\n",
      "train loss:0.00026460165778576574\n",
      "train loss:0.003337916073175787\n",
      "train loss:3.797712434888225e-05\n",
      "train loss:0.0015665376292918727\n",
      "train loss:0.0050869981559906585\n",
      "train loss:6.087694566504542e-05\n",
      "train loss:0.0011724302053256696\n",
      "train loss:0.0032624030130090436\n",
      "train loss:0.0007176706126358349\n",
      "train loss:0.0009503191861398317\n",
      "train loss:0.0017807212612857045\n",
      "train loss:0.0037258294011720183\n",
      "train loss:0.0038662545030983815\n",
      "train loss:0.0009676021839573994\n",
      "train loss:6.702636690259818e-05\n",
      "train loss:0.002709685008798362\n",
      "train loss:0.0026009791080721734\n",
      "train loss:0.00027436636951201854\n",
      "train loss:0.002162087143649014\n",
      "train loss:0.00013542644649523137\n",
      "train loss:0.0016930462551492443\n",
      "train loss:0.0027423764490349858\n",
      "train loss:0.0005751396520745981\n",
      "train loss:0.012035042598644258\n",
      "train loss:0.001100664012044914\n",
      "train loss:0.0007867411236477138\n",
      "train loss:0.0029218042155976197\n",
      "train loss:0.003498227982032699\n",
      "train loss:0.0004884369122347674\n",
      "train loss:0.0007246658356696007\n",
      "train loss:0.0009749716482702856\n",
      "train loss:0.0023818989875212587\n",
      "train loss:0.00044870195871592395\n",
      "train loss:0.0006684057118250153\n",
      "train loss:0.0016413233354085589\n",
      "train loss:0.0002480750528387129\n",
      "train loss:0.003857470957637394\n",
      "train loss:0.0014981562444209492\n",
      "train loss:0.0011002636416039906\n",
      "train loss:0.0005116882071340605\n",
      "train loss:0.003782512251270667\n",
      "train loss:0.0032287626890389483\n",
      "train loss:0.005027399352009286\n",
      "train loss:0.0008721700495095696\n",
      "train loss:0.018584072771230257\n",
      "train loss:0.006346423709777944\n",
      "train loss:0.00044497305012207965\n",
      "train loss:0.0012874601183981687\n",
      "train loss:0.0023077689684322424\n",
      "train loss:0.004270787510175119\n",
      "train loss:0.000413920430550551\n",
      "train loss:0.0032942986913975436\n",
      "train loss:0.01983508448995014\n",
      "train loss:0.002763082162366369\n",
      "train loss:0.0004515937754032452\n",
      "train loss:0.0018198448829693376\n",
      "train loss:0.0035018879515871775\n",
      "train loss:0.0031041318710341393\n",
      "train loss:0.000612836798077826\n",
      "train loss:0.002345948483406716\n",
      "train loss:0.0029144187033039184\n",
      "train loss:0.0025922328222384664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0018491744482354118\n",
      "train loss:0.00038779606686801567\n",
      "train loss:0.000619057964092762\n",
      "train loss:0.00023834219666389475\n",
      "train loss:0.018790289398294815\n",
      "train loss:0.0013605747960873092\n",
      "train loss:0.0007717559325873168\n",
      "train loss:0.004815855431655567\n",
      "train loss:0.001762988357786941\n",
      "train loss:0.0028966865204394674\n",
      "train loss:0.0009372941425574313\n",
      "train loss:0.002908102539176023\n",
      "train loss:0.003428895705179902\n",
      "train loss:0.000241198373554724\n",
      "train loss:0.00010675595618629123\n",
      "train loss:0.0005533247315097347\n",
      "train loss:0.0001457037726576917\n",
      "train loss:0.0008868849159142375\n",
      "train loss:9.40140497602119e-05\n",
      "train loss:0.0008852353941607514\n",
      "train loss:0.00846526171245524\n",
      "train loss:0.0002646332357936166\n",
      "train loss:0.002762952673103439\n",
      "train loss:0.0009088354708966482\n",
      "train loss:0.0006147829053324007\n",
      "train loss:5.9874158044552695e-05\n",
      "train loss:0.0004373528103424678\n",
      "train loss:0.0007036623844090013\n",
      "train loss:0.0005796968151778327\n",
      "train loss:0.0001225418764566962\n",
      "train loss:0.002044348794915439\n",
      "train loss:0.0005589750425093025\n",
      "train loss:0.0005550366855288189\n",
      "train loss:0.009668231157036628\n",
      "train loss:0.0027867249531921268\n",
      "train loss:0.000512368805809672\n",
      "train loss:0.0003010670050352337\n",
      "train loss:0.0008108097069861315\n",
      "train loss:0.0008069152538125414\n",
      "train loss:0.0005049448947335488\n",
      "train loss:0.000787927496732302\n",
      "train loss:0.0018172405796548388\n",
      "train loss:0.001971292318720309\n",
      "train loss:0.004464985250231878\n",
      "train loss:0.0017365767346025553\n",
      "train loss:0.004126117386774999\n",
      "train loss:0.0007969197527799327\n",
      "train loss:0.002196449439384659\n",
      "train loss:0.002804158465254643\n",
      "train loss:0.0007657552025421759\n",
      "train loss:0.00017735460366237465\n",
      "train loss:0.0011466716265039444\n",
      "train loss:0.0009015409520197833\n",
      "train loss:0.007442797924943132\n",
      "train loss:0.0007910251240319139\n",
      "train loss:0.00012908006073842504\n",
      "train loss:0.0013128411618980509\n",
      "train loss:0.005411426878412761\n",
      "train loss:0.0015685133219487221\n",
      "train loss:0.00041862940921567123\n",
      "train loss:0.0004893932135125451\n",
      "train loss:0.006327629029247071\n",
      "train loss:0.0007009063049725335\n",
      "train loss:0.041275304594469396\n",
      "train loss:0.0011946768937402994\n",
      "train loss:0.002131208382537032\n",
      "train loss:0.0026901807743689317\n",
      "train loss:0.00012715998543515045\n",
      "train loss:0.0007709284497654897\n",
      "train loss:0.0003619065206090636\n",
      "train loss:0.0004861825416891671\n",
      "train loss:0.0007211626472856593\n",
      "train loss:0.00021451742883837655\n",
      "train loss:0.0012060738324818467\n",
      "train loss:0.0001988842773197978\n",
      "train loss:0.000591221114592753\n",
      "train loss:0.0010381272448384893\n",
      "train loss:0.0033004231270351786\n",
      "train loss:0.00011295451729702164\n",
      "train loss:0.00030735822121053126\n",
      "train loss:0.0014012180453685278\n",
      "train loss:0.0002182108447370858\n",
      "train loss:0.00011401947273651423\n",
      "train loss:0.0014576231477711225\n",
      "train loss:0.00884710876909415\n",
      "train loss:0.0004891562237635343\n",
      "train loss:0.002242614514846271\n",
      "train loss:0.0014935257285084186\n",
      "train loss:0.0022146520392053778\n",
      "train loss:0.0026356104005542703\n",
      "train loss:0.0007082220996276563\n",
      "train loss:0.0009740884706457057\n",
      "train loss:0.005175123040851666\n",
      "train loss:0.017453424304627707\n",
      "train loss:0.00030959954334177324\n",
      "train loss:0.0007770006587495711\n",
      "train loss:0.0008326555605808522\n",
      "train loss:0.0032821920805273857\n",
      "train loss:0.0003707738333110324\n",
      "train loss:0.0009935353429656243\n",
      "train loss:0.0006464859351260195\n",
      "train loss:0.0004987781046131723\n",
      "train loss:0.0028105194784941914\n",
      "train loss:0.0027279131770629934\n",
      "train loss:0.0001206579426477874\n",
      "train loss:0.0023354599621573783\n",
      "train loss:0.0040615710621837225\n",
      "train loss:0.0011804920697930993\n",
      "train loss:0.0003427573412032091\n",
      "train loss:0.00017604202011101927\n",
      "train loss:0.0007540003207170415\n",
      "train loss:0.002224000148409999\n",
      "train loss:0.001497784603103661\n",
      "train loss:0.002942915551842065\n",
      "train loss:0.003501045518274814\n",
      "train loss:0.006337374048412563\n",
      "train loss:0.002079942891360388\n",
      "train loss:0.0002796849152602624\n",
      "train loss:0.0009768497799520848\n",
      "train loss:0.0024020812110452806\n",
      "train loss:0.001586928126733756\n",
      "train loss:0.00016826083316446544\n",
      "train loss:0.0005399619867229485\n",
      "train loss:0.0012505794363049068\n",
      "train loss:0.0002979553988355558\n",
      "train loss:9.13935897588771e-05\n",
      "train loss:0.0020982578296215924\n",
      "train loss:0.0007953366525032335\n",
      "train loss:0.0004489727182195739\n",
      "train loss:0.003401057240391728\n",
      "train loss:0.00017762114759956908\n",
      "train loss:0.0016771611555222402\n",
      "train loss:0.0001740812060341071\n",
      "train loss:0.002312892300940602\n",
      "train loss:0.000772968725265753\n",
      "train loss:0.008336381065769984\n",
      "train loss:0.0017065324351854877\n",
      "train loss:0.0009455850983483073\n",
      "train loss:0.0003077414134711521\n",
      "train loss:0.0016881035202402637\n",
      "train loss:0.0008048750660911585\n",
      "train loss:0.001058126010467116\n",
      "train loss:0.001040978891860881\n",
      "train loss:0.004794373904259913\n",
      "train loss:0.0037434846427001106\n",
      "train loss:0.0037400420138978905\n",
      "train loss:0.009076111571426635\n",
      "train loss:0.0002494933269897007\n",
      "train loss:0.0006383697224958583\n",
      "train loss:0.0010162814040806877\n",
      "train loss:8.03420221821295e-05\n",
      "train loss:0.0002508493823614713\n",
      "train loss:0.0010029296756502264\n",
      "train loss:0.002500318393043389\n",
      "train loss:0.0014729534760256435\n",
      "train loss:0.002349774370688884\n",
      "train loss:0.00312234118290363\n",
      "train loss:0.0008609645564227\n",
      "train loss:0.0037887674813173013\n",
      "train loss:0.0016537295853807418\n",
      "train loss:9.287262079003762e-05\n",
      "train loss:0.0004959435098415571\n",
      "train loss:0.0052706016591844785\n",
      "train loss:0.0028863098735955896\n",
      "train loss:0.00012800808252995359\n",
      "train loss:0.0013805966483672973\n",
      "train loss:0.0003660040594266693\n",
      "train loss:0.0003254169103439751\n",
      "train loss:0.0006020893495031481\n",
      "train loss:0.0010460036106213202\n",
      "train loss:0.0017144443492929243\n",
      "train loss:0.0016252952997466248\n",
      "train loss:0.0030901644913149473\n",
      "train loss:0.0013834457763514424\n",
      "train loss:0.05163681045880932\n",
      "train loss:0.00575670203120342\n",
      "train loss:0.0071259561644046905\n",
      "train loss:0.002920441548476454\n",
      "train loss:0.00481296559063934\n",
      "train loss:0.0037368565775955874\n",
      "train loss:0.00018255191578932825\n",
      "train loss:0.0007695052599103569\n",
      "train loss:0.00047553169082648685\n",
      "train loss:0.00015980622323743716\n",
      "train loss:0.0003301946539600524\n",
      "train loss:0.001068397123222504\n",
      "train loss:0.0018956893152809017\n",
      "train loss:0.0034462105016316645\n",
      "train loss:0.0023545500829265705\n",
      "train loss:0.00013088311961024978\n",
      "train loss:0.0008286766771534417\n",
      "train loss:0.0007077687730208109\n",
      "train loss:0.0014881778122654732\n",
      "train loss:0.0015336790528083478\n",
      "train loss:0.0006747894850994967\n",
      "train loss:0.0028049709964659887\n",
      "train loss:0.001600336248817437\n",
      "train loss:0.0005710869189600324\n",
      "train loss:0.0019445104716416548\n",
      "train loss:2.176320999209431e-05\n",
      "train loss:0.002523448965641867\n",
      "train loss:0.0012962407593133983\n",
      "train loss:0.0022427512463945865\n",
      "train loss:0.001347634351147341\n",
      "train loss:0.0003221232836730283\n",
      "train loss:0.0024161206880740768\n",
      "train loss:0.0009658550165648627\n",
      "train loss:0.019009897738691925\n",
      "train loss:0.0007877006237259245\n",
      "train loss:0.005886343624124994\n",
      "train loss:0.0006282291317708513\n",
      "train loss:0.003392670764491562\n",
      "train loss:0.007706803752629829\n",
      "train loss:0.004852631730537439\n",
      "train loss:0.00048383421165308643\n",
      "train loss:0.000832424961805564\n",
      "train loss:0.0007741616692488866\n",
      "train loss:0.005487509153258685\n",
      "train loss:0.0014547240186804414\n",
      "train loss:3.2184667768762305e-05\n",
      "train loss:0.0017277933558686731\n",
      "train loss:0.005072695937454654\n",
      "train loss:0.002365631045354442\n",
      "train loss:0.00040818565838925423\n",
      "train loss:0.0007743161639740764\n",
      "train loss:0.00016012948323205093\n",
      "train loss:0.0053943611570771224\n",
      "train loss:0.006784136525943669\n",
      "train loss:0.010017461751180106\n",
      "train loss:0.006455633999746529\n",
      "train loss:0.00045522584248125763\n",
      "train loss:0.013047594690292508\n",
      "train loss:0.0017582234476562228\n",
      "train loss:0.0013311329263745455\n",
      "train loss:0.0035356017633904973\n",
      "train loss:0.004074352060874732\n",
      "train loss:0.0025667283699622808\n",
      "train loss:0.0027986005685304953\n",
      "train loss:0.00024973797760168297\n",
      "train loss:0.0017719834585732317\n",
      "train loss:0.0011015407158457542\n",
      "train loss:0.0016772699712250714\n",
      "train loss:0.0015712381575089408\n",
      "train loss:0.009741984974460834\n",
      "train loss:0.001956246853275775\n",
      "train loss:0.002632618585985668\n",
      "train loss:0.0014998409242404748\n",
      "train loss:0.0003595537155592939\n",
      "train loss:0.00293620382763299\n",
      "train loss:0.001214752536679555\n",
      "train loss:0.0013295919913002164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009728828421290621\n",
      "train loss:0.003098425607601055\n",
      "train loss:0.0012652688771812221\n",
      "train loss:0.0010994542593004857\n",
      "train loss:0.009418548638566218\n",
      "train loss:0.005359607685731967\n",
      "train loss:9.385429778091653e-05\n",
      "train loss:0.0005532069172034388\n",
      "train loss:0.00036598315543298426\n",
      "train loss:0.00018727592602039484\n",
      "train loss:0.001563079519373119\n",
      "train loss:0.001286163751282001\n",
      "train loss:0.002257232070457281\n",
      "train loss:0.002324418675875779\n",
      "train loss:0.0020061069415651185\n",
      "train loss:0.0024338978605037485\n",
      "train loss:0.0007045405589585285\n",
      "train loss:0.0010595225493736451\n",
      "train loss:0.004017247430318133\n",
      "train loss:0.0013649756436786879\n",
      "train loss:0.000911565517097344\n",
      "train loss:0.0007318351010507887\n",
      "train loss:0.0011898574932206931\n",
      "train loss:0.0009692597103991878\n",
      "train loss:0.0006534176139342215\n",
      "train loss:0.0002846334780981114\n",
      "train loss:0.00019966520128847484\n",
      "train loss:0.0019255159704073693\n",
      "train loss:0.00013280139682447204\n",
      "train loss:0.0016396245604903715\n",
      "train loss:0.0019023811350600997\n",
      "train loss:0.00010753007053890207\n",
      "train loss:0.0038760156638184516\n",
      "train loss:0.00905534174219912\n",
      "train loss:0.0038517104024679144\n",
      "train loss:0.00019674418902415028\n",
      "train loss:0.0016364390391582105\n",
      "train loss:0.004065895277930138\n",
      "train loss:0.0031026181160631167\n",
      "train loss:0.0006906890776530981\n",
      "train loss:0.0026821983756321246\n",
      "train loss:0.0012276485038372278\n",
      "train loss:0.002337738473357436\n",
      "train loss:0.00044989492038553303\n",
      "train loss:0.000304183905034414\n",
      "train loss:0.0029978657927281498\n",
      "train loss:0.0018835411123305737\n",
      "train loss:0.0039142918530326145\n",
      "train loss:0.0016284988724645448\n",
      "train loss:0.0016540135230818382\n",
      "train loss:0.0006981936514532966\n",
      "train loss:0.001825621995269449\n",
      "train loss:0.00031099396498161997\n",
      "train loss:0.002325502297436121\n",
      "train loss:0.0007429280844019712\n",
      "train loss:0.0014676724800952862\n",
      "train loss:0.0002871973834009572\n",
      "train loss:0.001280158728942506\n",
      "train loss:0.0029157927812428603\n",
      "train loss:0.0004431357285511483\n",
      "train loss:0.0012044963920157042\n",
      "train loss:0.008246885037271135\n",
      "train loss:0.0003801067563794725\n",
      "train loss:0.011154065237720225\n",
      "train loss:0.00019328279999916012\n",
      "train loss:0.00011811098675283533\n",
      "train loss:0.00047274698717533693\n",
      "train loss:0.0003398399969783229\n",
      "train loss:0.0004333962294246628\n",
      "train loss:0.0010831009012924025\n",
      "train loss:0.00010409735689856099\n",
      "train loss:0.0019490993924478033\n",
      "train loss:0.0007991307716566842\n",
      "train loss:0.0015126429025335377\n",
      "train loss:0.002211691975687076\n",
      "train loss:7.382690195563215e-05\n",
      "train loss:6.193345101281179e-05\n",
      "train loss:0.0034047464942788303\n",
      "train loss:0.00019144684437904285\n",
      "train loss:0.002021704508178169\n",
      "train loss:0.00011398610231247021\n",
      "train loss:0.001151361175531842\n",
      "train loss:0.00042175826938057795\n",
      "train loss:0.00015325043083227335\n",
      "train loss:0.007194646649069539\n",
      "train loss:0.003957028687632333\n",
      "train loss:0.0001927108219448685\n",
      "train loss:0.0006099200157620188\n",
      "train loss:0.00045723878056537666\n",
      "train loss:0.002706303870300281\n",
      "train loss:0.0018532656566076077\n",
      "train loss:0.001767429240238462\n",
      "train loss:0.002325268872324857\n",
      "train loss:0.0025948223144309007\n",
      "train loss:0.0017558657815153434\n",
      "train loss:0.0018941412786346269\n",
      "train loss:0.0002776974095589839\n",
      "train loss:0.001048020260235095\n",
      "train loss:0.0019631903258894388\n",
      "train loss:0.005296639447531742\n",
      "train loss:0.00018211516868141598\n",
      "train loss:0.0008436774619505734\n",
      "train loss:0.0012620606508836698\n",
      "train loss:0.00032230636974679624\n",
      "train loss:0.0016517104912639794\n",
      "train loss:9.437685772651227e-05\n",
      "train loss:0.00028204846832914144\n",
      "train loss:5.801872550595558e-05\n",
      "train loss:0.011335504292876199\n",
      "train loss:0.0004195282693750779\n",
      "train loss:0.0016389847482658607\n",
      "train loss:0.0010944428956308906\n",
      "train loss:0.00023705128140228763\n",
      "train loss:0.0002715241747769761\n",
      "train loss:2.383709546087321e-05\n",
      "train loss:0.0015306202883589568\n",
      "train loss:0.0017707057993267845\n",
      "train loss:0.0022147809611553003\n",
      "train loss:0.0008612400802798633\n",
      "train loss:0.00016816547375147486\n",
      "train loss:0.001490051900477139\n",
      "train loss:0.004711530595381887\n",
      "train loss:0.001267588197328449\n",
      "train loss:0.0013819582980948398\n",
      "train loss:0.002666418853798865\n",
      "train loss:0.0019472151383220077\n",
      "train loss:0.0013238470561639296\n",
      "train loss:0.00029726561642649314\n",
      "train loss:0.007454473190345763\n",
      "train loss:0.0032036285162041437\n",
      "train loss:0.0008589989446580453\n",
      "train loss:0.00397998394870763\n",
      "train loss:0.0003592506839728588\n",
      "train loss:9.652795835539494e-05\n",
      "train loss:0.0025101232101739177\n",
      "train loss:0.011878704727404035\n",
      "train loss:0.0010347315604585742\n",
      "train loss:0.0005646187311879355\n",
      "train loss:0.007028169325566028\n",
      "train loss:0.0021797296588588373\n",
      "train loss:0.0003177073909741481\n",
      "train loss:0.0006138323708731457\n",
      "train loss:0.00025846041382625843\n",
      "train loss:0.00010974784703820727\n",
      "train loss:0.001843695963372416\n",
      "train loss:0.00041131451934490234\n",
      "train loss:9.01082631538209e-05\n",
      "train loss:8.210793480217019e-05\n",
      "train loss:0.0016333636080574853\n",
      "train loss:0.0018227414002131683\n",
      "train loss:2.160747965852662e-05\n",
      "train loss:0.004614060360945468\n",
      "train loss:0.0011343637760611364\n",
      "train loss:0.00011761802978552402\n",
      "train loss:0.0015329233103847332\n",
      "train loss:0.0008510802479030082\n",
      "train loss:0.000583275348983493\n",
      "train loss:0.0003566615346160676\n",
      "train loss:0.00018224286826928635\n",
      "train loss:0.0006716683106741242\n",
      "train loss:0.0001994654374070432\n",
      "train loss:0.0007763070087152174\n",
      "train loss:0.00560147873850816\n",
      "train loss:0.00019398200331310412\n",
      "train loss:0.0012916372559731038\n",
      "train loss:0.0004933797789701051\n",
      "train loss:0.003318350626588362\n",
      "train loss:0.0005408953040449308\n",
      "train loss:0.00243817538519231\n",
      "train loss:0.0006163939851443965\n",
      "train loss:0.0008247650616323086\n",
      "train loss:0.002654541515553562\n",
      "train loss:0.00024017817683297685\n",
      "train loss:0.0005288171052666066\n",
      "train loss:0.0009983711924750895\n",
      "train loss:0.0017201400875054263\n",
      "train loss:0.0020250901705207163\n",
      "train loss:0.0003042290235505689\n",
      "train loss:0.0025174816041551524\n",
      "train loss:0.0014884660862809068\n",
      "train loss:0.0003523486471002495\n",
      "train loss:0.0002669401515137665\n",
      "train loss:0.0042986600594911726\n",
      "train loss:0.002975684759477685\n",
      "train loss:0.0005907451610950101\n",
      "train loss:0.0007870497166104117\n",
      "train loss:0.00031979542588657785\n",
      "train loss:0.001902485505404657\n",
      "train loss:0.000661220674387242\n",
      "train loss:0.00022914339598113605\n",
      "train loss:0.00021427975300831133\n",
      "train loss:0.00025791068785726667\n",
      "train loss:0.004148452438615845\n",
      "train loss:2.992711281784233e-05\n",
      "train loss:0.00025041426917764\n",
      "train loss:0.0007021014222223599\n",
      "train loss:0.002104101896043949\n",
      "=== epoch:18, train acc:1.0, test acc:0.987 ===\n",
      "train loss:3.977548496550583e-05\n",
      "train loss:0.001217354275420838\n",
      "train loss:0.0012971041253185885\n",
      "train loss:0.00036441038489228153\n",
      "train loss:0.0003222622503499381\n",
      "train loss:0.000141214011814733\n",
      "train loss:0.0016245577233581663\n",
      "train loss:0.003383221633405572\n",
      "train loss:0.009916281742260806\n",
      "train loss:0.001262343954933761\n",
      "train loss:0.0027345233447000207\n",
      "train loss:8.747518040160633e-05\n",
      "train loss:0.0013769508923182024\n",
      "train loss:0.0065424482054437984\n",
      "train loss:0.000401880912251232\n",
      "train loss:0.0020640773477704016\n",
      "train loss:0.0003862214734781505\n",
      "train loss:0.05265070691089835\n",
      "train loss:0.011376335480379498\n",
      "train loss:0.004255630394831813\n",
      "train loss:0.00026008485173443103\n",
      "train loss:0.0032368339508351456\n",
      "train loss:0.0020707757077409626\n",
      "train loss:0.004291736488108579\n",
      "train loss:0.0003093874129137174\n",
      "train loss:0.0002822947441758697\n",
      "train loss:0.0010918886912444636\n",
      "train loss:0.003195821265124454\n",
      "train loss:0.0037850045248281417\n",
      "train loss:0.0003261268663444352\n",
      "train loss:0.002428218259508836\n",
      "train loss:0.0012041701014503922\n",
      "train loss:0.0029375039150023653\n",
      "train loss:0.00025776636580837\n",
      "train loss:0.0014137616361413973\n",
      "train loss:0.0008691806428731765\n",
      "train loss:0.00029080603711204164\n",
      "train loss:3.7762892621150946e-05\n",
      "train loss:0.0032266335582445526\n",
      "train loss:0.0038450962596130213\n",
      "train loss:0.00016530090462121862\n",
      "train loss:0.00014515630280596625\n",
      "train loss:0.0002966318759715591\n",
      "train loss:0.0037273845617586936\n",
      "train loss:0.002286417193886629\n",
      "train loss:0.0001766211213624471\n",
      "train loss:0.0031285436510924292\n",
      "train loss:0.0003077919339426085\n",
      "train loss:0.00036615804926508425\n",
      "train loss:0.007376046835528676\n",
      "train loss:0.0025714732905000436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002945391905485702\n",
      "train loss:0.003292730930137655\n",
      "train loss:0.0003676474042825991\n",
      "train loss:0.0005761575311243641\n",
      "train loss:0.04073421637451464\n",
      "train loss:0.0004542885632034183\n",
      "train loss:0.032007191371478616\n",
      "train loss:0.0006756044570323869\n",
      "train loss:0.0001439589387935445\n",
      "train loss:0.003137342178938104\n",
      "train loss:0.0007631834351999155\n",
      "train loss:0.005022210422632161\n",
      "train loss:0.000442931661751187\n",
      "train loss:0.00047134787085559575\n",
      "train loss:0.000156266398820365\n",
      "train loss:0.00012443371477065086\n",
      "train loss:0.002182198577354447\n",
      "train loss:0.0009414471382644545\n",
      "train loss:0.0020119827799599125\n",
      "train loss:0.003615216807160867\n",
      "train loss:0.002189802031937962\n",
      "train loss:0.002456090541503292\n",
      "train loss:0.0021526162226582083\n",
      "train loss:0.004629034003255221\n",
      "train loss:0.00037382590325145274\n",
      "train loss:0.0003909847018576721\n",
      "train loss:0.00020999941212862218\n",
      "train loss:0.0014272872788047399\n",
      "train loss:0.0005879308254653268\n",
      "train loss:0.015863848211379584\n",
      "train loss:0.0017898831312625815\n",
      "train loss:0.00530959103756942\n",
      "train loss:0.0001843518162985974\n",
      "train loss:0.0014288058809620782\n",
      "train loss:0.0026822887816117707\n",
      "train loss:0.0001257442988288645\n",
      "train loss:0.0031126850820371184\n",
      "train loss:0.0033443335127504438\n",
      "train loss:0.004308249682825563\n",
      "train loss:0.00020055078514931101\n",
      "train loss:0.00040918414776222324\n",
      "train loss:4.818207169578442e-05\n",
      "train loss:0.0001227119774843803\n",
      "train loss:0.0019925343316932287\n",
      "train loss:0.00138188379456789\n",
      "train loss:0.008415979606385404\n",
      "train loss:0.0004257425576255777\n",
      "train loss:0.002055251669565063\n",
      "train loss:0.0006634490489919281\n",
      "train loss:0.0002276872302950369\n",
      "train loss:0.0030339308574124763\n",
      "train loss:0.0014376029189379755\n",
      "train loss:0.01699174246358829\n",
      "train loss:0.0003724162201279445\n",
      "train loss:0.0008512374629124081\n",
      "train loss:0.0030557841665437534\n",
      "train loss:0.0018895248447153743\n",
      "train loss:0.0019041395379916673\n",
      "train loss:0.0005920255511885273\n",
      "train loss:0.0015035044834679596\n",
      "train loss:0.0005588080750209763\n",
      "train loss:0.0003979254770836499\n",
      "train loss:0.0012268239197911776\n",
      "train loss:2.7281666268329508e-05\n",
      "train loss:0.00021026283893982607\n",
      "train loss:0.0011298000252054324\n",
      "train loss:0.021950206314040228\n",
      "train loss:0.021408563622378755\n",
      "train loss:0.05463793813159435\n",
      "train loss:0.0006369910670161258\n",
      "train loss:0.0014614680833294202\n",
      "train loss:0.002603964897767676\n",
      "train loss:0.00017291031368441\n",
      "train loss:0.00460493765758782\n",
      "train loss:0.00025003088873387283\n",
      "train loss:0.0011428070153077915\n",
      "train loss:0.0029720598681918543\n",
      "train loss:0.002229707472196847\n",
      "train loss:0.0001581397115207467\n",
      "train loss:0.00030727661214253083\n",
      "train loss:0.0013883859078373624\n",
      "train loss:0.0038640833470053133\n",
      "train loss:0.009524882058229784\n",
      "train loss:0.0029510188742099437\n",
      "train loss:0.00011400952124809804\n",
      "train loss:0.0007848844692424989\n",
      "train loss:0.0012069853954300353\n",
      "train loss:0.00021922610139281436\n",
      "train loss:0.00024485380484122953\n",
      "train loss:6.484371227247199e-05\n",
      "train loss:0.0024648516897786492\n",
      "train loss:0.00021969153803538062\n",
      "train loss:0.0008463746203425188\n",
      "train loss:0.0016385969088363414\n",
      "train loss:0.0027609632675204836\n",
      "train loss:0.0003629312219489184\n",
      "train loss:0.00012356680196530192\n",
      "train loss:0.001965456608573478\n",
      "train loss:0.0037013459998510526\n",
      "train loss:0.0007865105253613343\n",
      "train loss:0.004817742875964593\n",
      "train loss:0.0015422615959231045\n",
      "train loss:0.010417716949259111\n",
      "train loss:0.0007301665212711502\n",
      "train loss:0.0010912259761239008\n",
      "train loss:0.0018925634370635074\n",
      "train loss:0.009025344699606846\n",
      "train loss:0.006159892540151765\n",
      "train loss:0.001475564914413244\n",
      "train loss:0.0008626332337814373\n",
      "train loss:0.0016410759531970184\n",
      "train loss:0.0013360900981068014\n",
      "train loss:0.0016384671399536602\n",
      "train loss:0.00042090099556178214\n",
      "train loss:0.0002930355296495792\n",
      "train loss:0.004133245860515817\n",
      "train loss:0.0030292986425753876\n",
      "train loss:0.0012237784411287392\n",
      "train loss:0.002524627786549403\n",
      "train loss:0.0048549218368617655\n",
      "train loss:0.0009419467513942798\n",
      "train loss:8.119174466784284e-05\n",
      "train loss:0.00131647766809668\n",
      "train loss:0.0067592054918787095\n",
      "train loss:0.00012148626031102514\n",
      "train loss:0.013650816973935519\n",
      "train loss:0.008318445588796042\n",
      "train loss:0.0011355718752173824\n",
      "train loss:0.0006756577161774147\n",
      "train loss:0.000877291202561329\n",
      "train loss:0.00010615501650363174\n",
      "train loss:0.00012536729162876747\n",
      "train loss:0.004529719205987383\n",
      "train loss:0.00014593740577555653\n",
      "train loss:0.0003739670587262814\n",
      "train loss:0.00037025663087378736\n",
      "train loss:0.0014226312490484296\n",
      "train loss:0.001673400601013991\n",
      "train loss:0.003033097927681854\n",
      "train loss:0.0010502472335526148\n",
      "train loss:0.0010112516637734708\n",
      "train loss:0.006521502920428035\n",
      "train loss:0.0004769772904752161\n",
      "train loss:0.004864485597328822\n",
      "train loss:0.004151178238107916\n",
      "train loss:0.0005347072288981556\n",
      "train loss:0.00245417506431016\n",
      "train loss:0.00046657940416824586\n",
      "train loss:0.000986482593473555\n",
      "train loss:0.0008839078740586423\n",
      "train loss:0.00035547433113333526\n",
      "train loss:0.0009093403683904118\n",
      "train loss:0.0006019511260330519\n",
      "train loss:0.0008638604533834106\n",
      "train loss:0.002246471186165459\n",
      "train loss:0.00017010709387869932\n",
      "train loss:0.0016528754571760583\n",
      "train loss:0.0009402037561865415\n",
      "train loss:0.001540064909151635\n",
      "train loss:0.0015374365947718033\n",
      "train loss:0.0023227972972164625\n",
      "train loss:0.0006435786704332459\n",
      "train loss:6.348786290972575e-05\n",
      "train loss:0.001667483015789579\n",
      "train loss:0.0003485553190403271\n",
      "train loss:0.0012502116776642292\n",
      "train loss:0.00328881957126547\n",
      "train loss:0.0006560563193690639\n",
      "train loss:0.0016021274514004793\n",
      "train loss:0.0013666919487193585\n",
      "train loss:0.0007193855751219051\n",
      "train loss:0.00022583206236912002\n",
      "train loss:0.00498944414205828\n",
      "train loss:0.001741275242623938\n",
      "train loss:0.002214633339390048\n",
      "train loss:0.011286325748398121\n",
      "train loss:0.0008560162162658122\n",
      "train loss:0.00035763002263362496\n",
      "train loss:8.86179030923936e-05\n",
      "train loss:0.015477950600485459\n",
      "train loss:0.0014385824878286404\n",
      "train loss:0.0009274944263030213\n",
      "train loss:0.00045001390847095144\n",
      "train loss:0.00017353224091053775\n",
      "train loss:0.0005445927937738483\n",
      "train loss:0.00322485263230322\n",
      "train loss:0.0040287504020218\n",
      "train loss:0.002083996906284757\n",
      "train loss:0.002606601395055581\n",
      "train loss:4.0812485409220944e-05\n",
      "train loss:0.0025040661279100186\n",
      "train loss:0.001999227530102832\n",
      "train loss:0.0015842152270907199\n",
      "train loss:4.748305375632021e-05\n",
      "train loss:0.0013435669445236846\n",
      "train loss:0.00017856736643958492\n",
      "train loss:0.000494295629153276\n",
      "train loss:0.0005317801460177857\n",
      "train loss:0.00016994166227745223\n",
      "train loss:0.0001075675231161749\n",
      "train loss:0.0009805868835198145\n",
      "train loss:0.002675535611361441\n",
      "train loss:5.286168876322837e-05\n",
      "train loss:0.000954048148851715\n",
      "train loss:0.0009388242704378648\n",
      "train loss:0.0008978374994890722\n",
      "train loss:0.0004898730631281065\n",
      "train loss:0.0024940714868987844\n",
      "train loss:0.013695311297684573\n",
      "train loss:0.00022450062803364764\n",
      "train loss:0.0001537081261135766\n",
      "train loss:0.00019518288176255136\n",
      "train loss:0.002616223617961018\n",
      "train loss:0.0001364545976136199\n",
      "train loss:0.0009386061745429024\n",
      "train loss:0.000555330634274239\n",
      "train loss:0.0020566787789414462\n",
      "train loss:0.00313082187278519\n",
      "train loss:0.0032429593587165475\n",
      "train loss:0.017159663539220448\n",
      "train loss:0.004901992552196119\n",
      "train loss:0.015704289332235805\n",
      "train loss:7.619450370210444e-05\n",
      "train loss:0.0005610994031041497\n",
      "train loss:0.0009386050026174923\n",
      "train loss:0.003912762847948621\n",
      "train loss:9.35240356137977e-05\n",
      "train loss:0.0024516980794740692\n",
      "train loss:0.0034273682317343466\n",
      "train loss:0.0016689309293184294\n",
      "train loss:0.00690495598842892\n",
      "train loss:0.0033172151517366355\n",
      "train loss:0.0006118638477720698\n",
      "train loss:0.0014919637503169295\n",
      "train loss:0.0015932968893708121\n",
      "train loss:0.0033753823338940874\n",
      "train loss:0.00010447928283619876\n",
      "train loss:0.0008529519970435665\n",
      "train loss:0.014520512083575403\n",
      "train loss:0.0034288466782825943\n",
      "train loss:0.001134799628165282\n",
      "train loss:0.000967205200941315\n",
      "train loss:0.002020848447005612\n",
      "train loss:0.006520748131534133\n",
      "train loss:0.0002617826932908025\n",
      "train loss:0.0036486250504979023\n",
      "train loss:0.0007353153687579086\n",
      "train loss:0.00032039367908575104\n",
      "train loss:0.0020664391666461984\n",
      "train loss:0.0009013827081369763\n",
      "train loss:0.0021712146204668093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016207343369247802\n",
      "train loss:0.00019897023662678747\n",
      "train loss:0.0008310217371673021\n",
      "train loss:0.0009387034762297942\n",
      "train loss:0.0024028333530154602\n",
      "train loss:0.0024593554556380623\n",
      "train loss:0.00029988043737171635\n",
      "train loss:0.0006023860869229953\n",
      "train loss:0.0014024419168664063\n",
      "train loss:0.003509920547888809\n",
      "train loss:0.01080466426823837\n",
      "train loss:0.0005748234912189141\n",
      "train loss:0.0010222656968429029\n",
      "train loss:0.0030154810966271247\n",
      "train loss:0.0014694850666028547\n",
      "train loss:0.0015211217113805828\n",
      "train loss:0.01563176576532761\n",
      "train loss:0.001359531900483974\n",
      "train loss:0.002778540188618714\n",
      "train loss:0.0011015703559001861\n",
      "train loss:0.0006240253167986706\n",
      "train loss:0.0025597727114301315\n",
      "train loss:0.0009199923368652681\n",
      "train loss:0.00010334461733677812\n",
      "train loss:0.0006266143113230636\n",
      "train loss:0.0021870069771779237\n",
      "train loss:0.000673195144944973\n",
      "train loss:0.01736602978368252\n",
      "train loss:0.004572160849262716\n",
      "train loss:0.0043638593611501665\n",
      "train loss:0.00013604265780264244\n",
      "train loss:0.0019844469838933678\n",
      "train loss:0.001910661445697713\n",
      "train loss:0.0012974857460843969\n",
      "train loss:0.0015903539211578124\n",
      "train loss:0.003563079371224245\n",
      "train loss:0.0010113465577018946\n",
      "train loss:0.0003651531221142709\n",
      "train loss:0.000601866423798962\n",
      "train loss:0.0027774601932726195\n",
      "train loss:0.0016125903807320057\n",
      "train loss:0.0007441471504281188\n",
      "train loss:0.0017872276928294062\n",
      "train loss:0.0027164454381441595\n",
      "train loss:0.004675776509936594\n",
      "train loss:0.001335602353837089\n",
      "train loss:0.000461028006717565\n",
      "train loss:0.01554435890498428\n",
      "train loss:0.0006062436518332637\n",
      "train loss:0.0005747389433555867\n",
      "train loss:0.0015262584792676906\n",
      "train loss:0.006170377099821966\n",
      "train loss:0.00025652157184821793\n",
      "train loss:5.833271764555563e-05\n",
      "train loss:0.0003421938255601892\n",
      "train loss:0.001700791129886887\n",
      "train loss:0.005515683041637023\n",
      "train loss:6.103205631756299e-05\n",
      "train loss:0.0006479583720308909\n",
      "train loss:0.0002002563125193276\n",
      "train loss:0.028002409726814118\n",
      "train loss:0.0009705604822478465\n",
      "train loss:0.003668675344939607\n",
      "train loss:0.000835672073749354\n",
      "train loss:0.0005330116835820092\n",
      "train loss:0.0028967539488090077\n",
      "train loss:0.0018972155754532474\n",
      "train loss:0.0005721946575106591\n",
      "train loss:0.00019143979693315397\n",
      "train loss:0.002587395541792969\n",
      "train loss:0.016281834028250165\n",
      "train loss:0.0036644958639664425\n",
      "train loss:0.0007117917996082054\n",
      "train loss:0.0003965140676012046\n",
      "train loss:4.961038075448213e-05\n",
      "train loss:0.002012721097430922\n",
      "train loss:0.004596486479196186\n",
      "train loss:7.831149035260871e-05\n",
      "train loss:0.0027032429108316464\n",
      "train loss:5.866941744700005e-05\n",
      "train loss:0.0010557023646220944\n",
      "train loss:0.003484983494904714\n",
      "train loss:0.0006007044336393999\n",
      "train loss:0.004434385447158084\n",
      "train loss:7.306118689924811e-05\n",
      "train loss:0.00026840370670978505\n",
      "train loss:0.0020571943973568415\n",
      "train loss:0.001176452771727331\n",
      "train loss:0.00028267970799476056\n",
      "train loss:0.0010378363787426927\n",
      "train loss:0.013070185357100684\n",
      "train loss:0.0008383628167106968\n",
      "train loss:0.0024077641559178465\n",
      "train loss:0.0007796454485846917\n",
      "train loss:0.0008442716946058633\n",
      "train loss:0.00023817191256541464\n",
      "train loss:0.0009401112113799334\n",
      "train loss:0.0175595882086658\n",
      "train loss:0.0015996189449091131\n",
      "train loss:0.0001652693997602372\n",
      "train loss:0.00038455193215190244\n",
      "train loss:0.0010005937482987948\n",
      "train loss:0.0007132531887015285\n",
      "train loss:0.008713093978025081\n",
      "train loss:0.01123645064422944\n",
      "train loss:0.0009337759520724857\n",
      "train loss:0.001519050296800284\n",
      "train loss:0.0007848045833327587\n",
      "train loss:0.0003582836122956085\n",
      "train loss:0.0015844887696006065\n",
      "train loss:0.013690400434024775\n",
      "train loss:0.0028045709984816703\n",
      "train loss:0.0025213467621123743\n",
      "train loss:0.0004321026192725042\n",
      "train loss:0.006678943000995893\n",
      "train loss:0.0016212211277188858\n",
      "train loss:0.003313562255855028\n",
      "train loss:0.0004127030048776166\n",
      "train loss:6.648951432439676e-05\n",
      "train loss:0.0015601678126473339\n",
      "train loss:0.0007612244096774103\n",
      "train loss:8.795429003591258e-05\n",
      "train loss:0.0009140417605265418\n",
      "train loss:0.00018156317995378983\n",
      "train loss:0.0004000566563037855\n",
      "train loss:0.0033325481143764296\n",
      "train loss:0.0013302769818877274\n",
      "train loss:0.0018583512625854359\n",
      "train loss:9.327158386407901e-05\n",
      "train loss:0.0034201157550976975\n",
      "train loss:0.001252936933355532\n",
      "train loss:0.0012960060762669714\n",
      "train loss:0.00043138891536174706\n",
      "train loss:0.0015611594345508158\n",
      "train loss:0.0002941176726855343\n",
      "train loss:0.00029164270647306516\n",
      "train loss:0.0012164135993439082\n",
      "train loss:0.0015836752076007362\n",
      "train loss:0.002325274260703418\n",
      "train loss:0.0035408680648548845\n",
      "train loss:0.004670967669642884\n",
      "train loss:0.0009748158236726084\n",
      "train loss:0.00020106345628636516\n",
      "train loss:0.00020196588584775826\n",
      "train loss:0.0011311052351654666\n",
      "train loss:0.0006358124353762723\n",
      "train loss:0.0009237884758988738\n",
      "train loss:0.0002161059692939201\n",
      "train loss:0.00015010150471093375\n",
      "train loss:0.0018808346342727433\n",
      "train loss:0.007016733519416073\n",
      "train loss:0.0009756292911732176\n",
      "train loss:0.0007609469227654806\n",
      "train loss:0.0005949270593389836\n",
      "train loss:0.0018327889039800654\n",
      "train loss:0.0031968221981531647\n",
      "train loss:0.0010618991752836008\n",
      "train loss:0.001806488109402683\n",
      "train loss:0.00048693982346276427\n",
      "train loss:0.0012054149717049317\n",
      "train loss:0.00042949729755023135\n",
      "train loss:0.0019756554318043963\n",
      "train loss:0.0014005161512051097\n",
      "train loss:0.00013747724505561547\n",
      "train loss:0.052361263754500904\n",
      "train loss:0.0007114553618379206\n",
      "train loss:0.0038307577557928664\n",
      "train loss:0.0038996023111551475\n",
      "train loss:0.0005515168189617015\n",
      "train loss:0.00018745243694196734\n",
      "train loss:0.00024283985953624164\n",
      "train loss:0.00035357046505212706\n",
      "train loss:0.00026705763517262214\n",
      "train loss:0.002114327796723342\n",
      "train loss:0.003886301587628838\n",
      "train loss:0.0007494433078232561\n",
      "train loss:0.00037614443942464416\n",
      "train loss:0.0003802775808204571\n",
      "train loss:0.0017196149318656285\n",
      "train loss:0.0006428096923080746\n",
      "train loss:0.0009125375412255624\n",
      "train loss:0.00011454439309330085\n",
      "train loss:0.0009575063434236049\n",
      "train loss:0.0006290236199680176\n",
      "train loss:0.0012641724129983923\n",
      "train loss:0.004806350662847062\n",
      "train loss:0.0019857456160191065\n",
      "train loss:0.000194488429929639\n",
      "train loss:0.0007154002819833201\n",
      "train loss:0.0010027921736054399\n",
      "train loss:0.0006164070209363069\n",
      "train loss:0.00417853348261534\n",
      "train loss:0.002653474207493083\n",
      "train loss:0.0005514764799587297\n",
      "train loss:0.0027047555404006605\n",
      "train loss:0.0034360563771038467\n",
      "train loss:0.005010571267512881\n",
      "train loss:0.00027886896430007917\n",
      "train loss:0.0033993592527133375\n",
      "train loss:0.00035978831395832157\n",
      "train loss:0.0008225048945815018\n",
      "train loss:0.0003269826266661358\n",
      "train loss:0.002181542379022385\n",
      "train loss:0.005567992915450753\n",
      "train loss:0.0018804541616932807\n",
      "train loss:0.00015155938265217208\n",
      "train loss:0.0007198290838467873\n",
      "train loss:0.0024664627263153624\n",
      "train loss:0.001099435781058489\n",
      "train loss:0.0013967179325840456\n",
      "train loss:0.0012581311808126654\n",
      "train loss:0.02238469389168698\n",
      "train loss:0.0013602058378804033\n",
      "train loss:0.0019852609123636195\n",
      "train loss:0.0029748907491496134\n",
      "train loss:0.0016864305664404653\n",
      "train loss:0.00016594842703045333\n",
      "train loss:0.0012433567056884132\n",
      "train loss:0.0002727002191830237\n",
      "train loss:0.0012056361843482176\n",
      "train loss:0.00015840242084269387\n",
      "train loss:0.00025650265434390575\n",
      "train loss:0.0005035015720862577\n",
      "train loss:0.0015518837033909624\n",
      "train loss:0.0026068379036842102\n",
      "train loss:0.0003140992645378014\n",
      "train loss:0.0007585422187847807\n",
      "train loss:0.0006792986559554265\n",
      "train loss:0.0007597824194904494\n",
      "train loss:0.001908502483712881\n",
      "train loss:0.0004963702697993302\n",
      "train loss:0.007021385250425135\n",
      "train loss:0.0005420004285565723\n",
      "train loss:0.0004338526981523716\n",
      "train loss:0.001124886141059417\n",
      "train loss:0.0017642476906188612\n",
      "train loss:0.011337203547619539\n",
      "train loss:0.0001568052760429814\n",
      "train loss:0.0029903029038612023\n",
      "train loss:0.0005740329477930351\n",
      "train loss:0.0015839028547737835\n",
      "train loss:0.006421938700363452\n",
      "train loss:0.0005000360556167835\n",
      "train loss:0.002927336455291317\n",
      "train loss:0.025687519039449578\n",
      "train loss:0.0007406747656302007\n",
      "train loss:0.0002601725847809669\n",
      "train loss:0.0013203610418267473\n",
      "train loss:0.0020592998402737205\n",
      "train loss:0.0025234569526998885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016119545776289547\n",
      "train loss:0.0010385863144304413\n",
      "train loss:0.0036855180380654345\n",
      "train loss:0.0013107493408039078\n",
      "train loss:0.0010033206972165124\n",
      "train loss:0.0014284918720597764\n",
      "train loss:0.0005123496767798546\n",
      "train loss:0.003505157579492833\n",
      "train loss:0.0006941642728087236\n",
      "train loss:0.00018121111692953048\n",
      "train loss:0.0016531064068494197\n",
      "train loss:0.0005359361310807946\n",
      "train loss:0.0012075235555252363\n",
      "train loss:0.000621250230900669\n",
      "train loss:0.002629009794002043\n",
      "train loss:0.0012166034926011735\n",
      "train loss:0.002039415623739252\n",
      "train loss:0.0010195469400003684\n",
      "train loss:0.008183801543146445\n",
      "train loss:0.0006268532290145911\n",
      "train loss:0.0027999451225438022\n",
      "train loss:0.0006706884446229647\n",
      "train loss:0.0015233826241476468\n",
      "train loss:0.00011652027699777228\n",
      "train loss:0.0031690485112033906\n",
      "train loss:0.00025449517357814414\n",
      "train loss:0.0020071977326410325\n",
      "train loss:0.0009711281113327384\n",
      "train loss:0.0004251093134181802\n",
      "train loss:0.00024814112005772175\n",
      "train loss:0.0033235490470880074\n",
      "train loss:0.0008141789762138341\n",
      "train loss:0.011210736399589557\n",
      "train loss:5.575966786654704e-05\n",
      "train loss:0.0005229134531094866\n",
      "train loss:0.000112101572812238\n",
      "train loss:0.000662342143633227\n",
      "train loss:0.0007818438491623502\n",
      "train loss:0.00015353481331930252\n",
      "train loss:0.0020372128794305475\n",
      "train loss:0.0020984706105394474\n",
      "train loss:0.001996506976887368\n",
      "train loss:0.0008475495149680508\n",
      "train loss:0.003064249630825433\n",
      "train loss:0.0008450336345330659\n",
      "train loss:0.001680179417331248\n",
      "train loss:0.0006289683429909447\n",
      "train loss:0.002691667142441502\n",
      "=== epoch:19, train acc:0.997, test acc:0.982 ===\n",
      "train loss:0.0012504048521206309\n",
      "train loss:5.680539845831232e-05\n",
      "train loss:0.0005404771471171274\n",
      "train loss:0.0014967050473892421\n",
      "train loss:0.0008784476932282491\n",
      "train loss:0.0003942383080983466\n",
      "train loss:0.0022310959914317234\n",
      "train loss:0.0005711647165691164\n",
      "train loss:0.00037482396531778186\n",
      "train loss:0.0007499506538602327\n",
      "train loss:0.0003523754597899423\n",
      "train loss:0.002631222203842809\n",
      "train loss:0.0008775258886726131\n",
      "train loss:0.003111019623463513\n",
      "train loss:0.0005330665741416389\n",
      "train loss:0.0012787516195409798\n",
      "train loss:0.0009910108558797799\n",
      "train loss:0.0022519648864529583\n",
      "train loss:0.0006648247404328388\n",
      "train loss:0.0004170821571221622\n",
      "train loss:0.0020366785392018512\n",
      "train loss:0.0012470571448462485\n",
      "train loss:0.00010618234665974363\n",
      "train loss:0.0005121136101194895\n",
      "train loss:0.008790994198605939\n",
      "train loss:0.000350865230063026\n",
      "train loss:0.0006630646368456992\n",
      "train loss:0.008837766515071323\n",
      "train loss:0.0002477859567873402\n",
      "train loss:0.0025295862271146373\n",
      "train loss:0.0007246280331548717\n",
      "train loss:0.0022813708358911207\n",
      "train loss:0.0016707814455643563\n",
      "train loss:0.0026304358347862904\n",
      "train loss:0.00044414610860825105\n",
      "train loss:0.0018097651272307369\n",
      "train loss:0.004029526775081184\n",
      "train loss:0.0019699257416846676\n",
      "train loss:0.0009426274787898457\n",
      "train loss:0.001575541364547142\n",
      "train loss:0.0020782306684910532\n",
      "train loss:0.0024096754795881943\n",
      "train loss:0.00025694011226340315\n",
      "train loss:0.0008645195763347968\n",
      "train loss:0.0002608704772603611\n",
      "train loss:0.00025448294631171496\n",
      "train loss:0.0003665050332635069\n",
      "train loss:0.0024406117318191765\n",
      "train loss:0.00043177716573040243\n",
      "train loss:0.0002591287293218359\n",
      "train loss:0.0013911912049976625\n",
      "train loss:0.0004718056754604079\n",
      "train loss:0.0004619458761910515\n",
      "train loss:0.0015187089633169786\n",
      "train loss:0.0005237232490356969\n",
      "train loss:0.0008886707642440124\n",
      "train loss:5.818560893229729e-05\n",
      "train loss:0.0004761708818661205\n",
      "train loss:0.0010253006445581942\n",
      "train loss:0.0002866018163902592\n",
      "train loss:6.542346622417133e-05\n",
      "train loss:0.002078770999994734\n",
      "train loss:0.00024472546902341684\n",
      "train loss:0.00497812894248773\n",
      "train loss:0.00021693965199764192\n",
      "train loss:0.0005697610411446567\n",
      "train loss:0.0022080259961488055\n",
      "train loss:0.00012155868627320397\n",
      "train loss:0.0005219388154475656\n",
      "train loss:0.0037304960833180302\n",
      "train loss:0.001548648220155905\n",
      "train loss:0.0003885377754073908\n",
      "train loss:0.000347529227091561\n",
      "train loss:0.0016913927666944615\n",
      "train loss:0.0037549865351017646\n",
      "train loss:0.005825424482937796\n",
      "train loss:0.016971357147121138\n",
      "train loss:0.0034586560021690397\n",
      "train loss:0.008778935994450437\n",
      "train loss:0.00021261412000656962\n",
      "train loss:0.005000566104467071\n",
      "train loss:0.0027853079999252215\n",
      "train loss:0.00014200724310403146\n",
      "train loss:0.004453358356540901\n",
      "train loss:0.0004061026821124934\n",
      "train loss:0.00848272460339545\n",
      "train loss:0.0025994657830556824\n",
      "train loss:0.002493086178010348\n",
      "train loss:0.001047366380480719\n",
      "train loss:0.0024206666472606623\n",
      "train loss:0.0010476794194872298\n",
      "train loss:0.0005506187739652447\n",
      "train loss:0.000965737146144762\n",
      "train loss:0.0030521635064480255\n",
      "train loss:0.002390802568035612\n",
      "train loss:0.002331555083885587\n",
      "train loss:0.0005642251324521564\n",
      "train loss:0.00044871867943494236\n",
      "train loss:0.0012044276486636869\n",
      "train loss:0.00043896937423857236\n",
      "train loss:0.0009177095155649895\n",
      "train loss:0.004772497185836723\n",
      "train loss:0.0006250228454768535\n",
      "train loss:0.003606040429629579\n",
      "train loss:0.000823340580297939\n",
      "train loss:0.0002896250930568881\n",
      "train loss:0.004407723897557275\n",
      "train loss:0.004008777458900343\n",
      "train loss:0.0002804378135451417\n",
      "train loss:0.000479469935931202\n",
      "train loss:9.598545369903796e-05\n",
      "train loss:0.00027471665133917665\n",
      "train loss:0.0016469091047182902\n",
      "train loss:3.7681086352768917e-05\n",
      "train loss:0.0002658974781397707\n",
      "train loss:0.0008076661471501567\n",
      "train loss:0.0018587132527485351\n",
      "train loss:0.00030320398902401827\n",
      "train loss:0.0018800172898537687\n",
      "train loss:1.6621408465253407e-05\n",
      "train loss:0.001404426569632678\n",
      "train loss:0.000716361109209742\n",
      "train loss:0.004825303457495005\n",
      "train loss:0.0003587472198110635\n",
      "train loss:0.0017571850087899216\n",
      "train loss:0.00025273782046695\n",
      "train loss:0.00037078028649835116\n",
      "train loss:0.00027640463444549387\n",
      "train loss:0.002704204787355635\n",
      "train loss:0.007431215873790637\n",
      "train loss:0.0008449873277660881\n",
      "train loss:0.004334384095548194\n",
      "train loss:0.0013607870383111236\n",
      "train loss:0.0018465418579863262\n",
      "train loss:0.00028895640590032154\n",
      "train loss:9.023349754348516e-05\n",
      "train loss:0.00024340031075152383\n",
      "train loss:0.0022661782346593304\n",
      "train loss:0.0007372127894772775\n",
      "train loss:0.00526165232761461\n",
      "train loss:0.0005623059024909211\n",
      "train loss:1.692673160367386e-05\n",
      "train loss:9.95583352647826e-05\n",
      "train loss:0.024112610800341078\n",
      "train loss:7.772507971029879e-05\n",
      "train loss:0.0009744690133403255\n",
      "train loss:0.0003596718733679614\n",
      "train loss:8.043105736296077e-05\n",
      "train loss:0.004552811989675313\n",
      "train loss:0.002100214032050074\n",
      "train loss:0.00195555089658945\n",
      "train loss:0.0006914892887360184\n",
      "train loss:9.670581701054077e-05\n",
      "train loss:0.00018134567156824282\n",
      "train loss:3.745883210834556e-05\n",
      "train loss:0.0017436919512574334\n",
      "train loss:0.008682488132865068\n",
      "train loss:0.00019123371531920132\n",
      "train loss:0.0014040059559838674\n",
      "train loss:0.0029568998041480683\n",
      "train loss:0.0001390751254192848\n",
      "train loss:0.0002959660906844617\n",
      "train loss:0.0031853743659030214\n",
      "train loss:0.0017031919488908192\n",
      "train loss:0.0005873984047801519\n",
      "train loss:4.38227695487718e-05\n",
      "train loss:0.001992725371764796\n",
      "train loss:0.000985955069445848\n",
      "train loss:0.007699358642416169\n",
      "train loss:0.001680243416793023\n",
      "train loss:0.0030137045314433245\n",
      "train loss:0.0009295683367472557\n",
      "train loss:0.00138649834027846\n",
      "train loss:0.002500063935186937\n",
      "train loss:0.0019531449381530834\n",
      "train loss:0.0001830757631892953\n",
      "train loss:0.002009822170340535\n",
      "train loss:0.001042883131987364\n",
      "train loss:0.00010886968926717704\n",
      "train loss:0.00020221551690345347\n",
      "train loss:0.0005700606789293439\n",
      "train loss:0.0008818276659134554\n",
      "train loss:0.000312475423323787\n",
      "train loss:0.012393339444768328\n",
      "train loss:0.0017476894313609148\n",
      "train loss:0.004283156225041429\n",
      "train loss:0.004241850932475682\n",
      "train loss:0.0003472366222785234\n",
      "train loss:0.031100441011528604\n",
      "train loss:0.002106535740479219\n",
      "train loss:0.00029055600479332153\n",
      "train loss:0.00031460270487410687\n",
      "train loss:0.001981578845947724\n",
      "train loss:0.0002896173966370891\n",
      "train loss:0.00035171466290889226\n",
      "train loss:0.0005260716907906656\n",
      "train loss:0.00518819765059665\n",
      "train loss:0.00028693396872304504\n",
      "train loss:0.0004785335741050847\n",
      "train loss:0.0009525848912537142\n",
      "train loss:0.0013944211154384564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002373582051339011\n",
      "train loss:0.0012470143643887176\n",
      "train loss:0.0023516013086946437\n",
      "train loss:0.0006309867090793764\n",
      "train loss:0.007225526378527248\n",
      "train loss:0.001991634732648621\n",
      "train loss:0.0035213097971991776\n",
      "train loss:0.00040038500958510523\n",
      "train loss:0.00041056632225468286\n",
      "train loss:0.005705065547388367\n",
      "train loss:0.006189996273413262\n",
      "train loss:0.0009051955419508789\n",
      "train loss:0.0035714051735767356\n",
      "train loss:0.0003231828202360212\n",
      "train loss:0.0010951347951223065\n",
      "train loss:0.001270340825088075\n",
      "train loss:0.0005220496264770225\n",
      "train loss:0.0012396473510728635\n",
      "train loss:0.0006872935107103197\n",
      "train loss:0.0040332736045237015\n",
      "train loss:0.0017737544848141016\n",
      "train loss:0.000511068247699913\n",
      "train loss:8.782203154488822e-05\n",
      "train loss:6.305923582072308e-05\n",
      "train loss:0.007758546250543698\n",
      "train loss:0.0014217657345723875\n",
      "train loss:0.0024279627927546567\n",
      "train loss:0.0017243073632267172\n",
      "train loss:0.000306595306705047\n",
      "train loss:0.0004655509886172657\n",
      "train loss:0.0005082818697825406\n",
      "train loss:0.00013281138891729354\n",
      "train loss:0.003012955378664415\n",
      "train loss:0.000166433764549876\n",
      "train loss:0.0017211746041727646\n",
      "train loss:0.0007354557139970775\n",
      "train loss:9.66747130814546e-05\n",
      "train loss:5.690146476889371e-05\n",
      "train loss:0.0005514491546119604\n",
      "train loss:8.980703144456928e-05\n",
      "train loss:0.00018444958676798565\n",
      "train loss:0.00035127912553629487\n",
      "train loss:0.002147683410250388\n",
      "train loss:0.0015817443077957819\n",
      "train loss:0.0012981708380009871\n",
      "train loss:0.0004830853781454382\n",
      "train loss:0.003043101354434928\n",
      "train loss:0.0006100797451441054\n",
      "train loss:0.00019092165469069452\n",
      "train loss:0.0007336376186912587\n",
      "train loss:0.0023418103472065163\n",
      "train loss:0.00029773350838804597\n",
      "train loss:0.0011102329594637479\n",
      "train loss:0.00014866165703122952\n",
      "train loss:9.393450824755147e-05\n",
      "train loss:0.0024790195745196934\n",
      "train loss:0.0003569269955236005\n",
      "train loss:0.0016536109084397108\n",
      "train loss:0.010190061280720888\n",
      "train loss:0.000935192683758164\n",
      "train loss:0.003155230776732493\n",
      "train loss:0.0026430672491748685\n",
      "train loss:0.0014117972185323702\n",
      "train loss:0.0001646789871369587\n",
      "train loss:0.0009350153048157518\n",
      "train loss:0.0009371284958452045\n",
      "train loss:0.007307656490684543\n",
      "train loss:0.00025243042265982906\n",
      "train loss:0.0005589561771727751\n",
      "train loss:0.0007401837435711725\n",
      "train loss:0.0035062434542165065\n",
      "train loss:0.0004337912864475859\n",
      "train loss:0.0012137754045504832\n",
      "train loss:0.000529148995383621\n",
      "train loss:0.0008686237576476151\n",
      "train loss:0.002010747072680839\n",
      "train loss:0.0006477083839162434\n",
      "train loss:0.010288198514820022\n",
      "train loss:0.000901393079845931\n",
      "train loss:0.0002461488469613445\n",
      "train loss:0.0019869711894921933\n",
      "train loss:0.0005838423899088153\n",
      "train loss:0.0007896011468670438\n",
      "train loss:0.001127640835140973\n",
      "train loss:0.0004800931378949144\n",
      "train loss:0.0001292160258125425\n",
      "train loss:0.0011853827171222212\n",
      "train loss:0.0009956696886768933\n",
      "train loss:0.006257601833539474\n",
      "train loss:0.0006144849278688845\n",
      "train loss:0.0003021170748781363\n",
      "train loss:0.0006320887409645035\n",
      "train loss:0.0005520831932496416\n",
      "train loss:0.0021399168697671537\n",
      "train loss:0.003244506419470649\n",
      "train loss:0.004712349405965805\n",
      "train loss:0.003526385136575696\n",
      "train loss:0.00037309167311405384\n",
      "train loss:0.0001489310098678101\n",
      "train loss:0.0011506520543338777\n",
      "train loss:0.00452217495629116\n",
      "train loss:0.0009862177831414945\n",
      "train loss:0.0014003269059980835\n",
      "train loss:0.00013360957804404533\n",
      "train loss:6.930918627292751e-05\n",
      "train loss:9.612668605162256e-05\n",
      "train loss:8.250919252131377e-05\n",
      "train loss:1.1357761338670655e-05\n",
      "train loss:0.0015690598504073563\n",
      "train loss:0.000211264249311742\n",
      "train loss:0.0007631848185690098\n",
      "train loss:7.439115050768948e-05\n",
      "train loss:2.56549368345641e-05\n",
      "train loss:0.0017435298699824218\n",
      "train loss:0.000754915941107149\n",
      "train loss:0.0016314033608320572\n",
      "train loss:0.0008151443709698753\n",
      "train loss:0.0007912114057281123\n",
      "train loss:0.0006995285945326661\n",
      "train loss:0.0005733110336316911\n",
      "train loss:0.00010932770299169165\n",
      "train loss:0.001009049796696736\n",
      "train loss:1.8225985895325542e-05\n",
      "train loss:0.003072641763446452\n",
      "train loss:0.00031651903054819746\n",
      "train loss:0.0002856011397084987\n",
      "train loss:0.0006788777578280214\n",
      "train loss:0.0005598529622410005\n",
      "train loss:0.0012640430575766067\n",
      "train loss:0.0009124749979658041\n",
      "train loss:0.0001576266247037053\n",
      "train loss:0.00018788070059277438\n",
      "train loss:0.0004443889516785525\n",
      "train loss:0.0030692700559914175\n",
      "train loss:0.0008196229549370338\n",
      "train loss:4.5553646554447265e-05\n",
      "train loss:0.0010609308650768108\n",
      "train loss:0.0003443926081386794\n",
      "train loss:0.0027685507468651555\n",
      "train loss:0.0012243427563903833\n",
      "train loss:0.003553004462324824\n",
      "train loss:0.002290299737376745\n",
      "train loss:9.198971826967108e-06\n",
      "train loss:0.0011314881621673299\n",
      "train loss:0.0004356001715799608\n",
      "train loss:0.0032413243963949684\n",
      "train loss:5.9578228423726885e-05\n",
      "train loss:0.0005295460713909724\n",
      "train loss:0.0003206939407949069\n",
      "train loss:0.00037395786191305564\n",
      "train loss:0.0002414032345631662\n",
      "train loss:0.0008291337024835803\n",
      "train loss:0.002414881457533581\n",
      "train loss:0.00013607821783020188\n",
      "train loss:7.081280331402692e-05\n",
      "train loss:0.0016556973327150474\n",
      "train loss:0.0007021159590119023\n",
      "train loss:0.00033690765781020567\n",
      "train loss:0.0006748337841278759\n",
      "train loss:0.003576401391639653\n",
      "train loss:0.00019527501399822927\n",
      "train loss:0.0005630788006351455\n",
      "train loss:0.0011894091398952159\n",
      "train loss:0.00047828445277418765\n",
      "train loss:6.615583225092266e-05\n",
      "train loss:0.03404377031563857\n",
      "train loss:7.404996440399986e-05\n",
      "train loss:0.0003015068943407247\n",
      "train loss:0.0005579570030747535\n",
      "train loss:0.0002249795409496534\n",
      "train loss:0.0002648544130843841\n",
      "train loss:0.0048918097036509175\n",
      "train loss:0.00135621140525253\n",
      "train loss:0.0008455785619441075\n",
      "train loss:0.0001687324024652902\n",
      "train loss:0.0004372758611748186\n",
      "train loss:0.001515670313800777\n",
      "train loss:0.0012851149143388268\n",
      "train loss:0.00010045173320931242\n",
      "train loss:0.00021493588873617837\n",
      "train loss:0.003532972220525293\n",
      "train loss:0.0021738554878071564\n",
      "train loss:0.002994824471303785\n",
      "train loss:0.0013166722314796129\n",
      "train loss:0.0017437551570231478\n",
      "train loss:0.00039767180837059274\n",
      "train loss:0.002427808647055117\n",
      "train loss:0.00011352876027523479\n",
      "train loss:0.00023283115307944145\n",
      "train loss:0.0022155245934516983\n",
      "train loss:0.00040794684072801283\n",
      "train loss:0.0003065378501492858\n",
      "train loss:0.006910757637975034\n",
      "train loss:0.0033597601146455676\n",
      "train loss:8.300397089883642e-05\n",
      "train loss:0.00042272611201544635\n",
      "train loss:0.0025141095446131554\n",
      "train loss:0.005403102873525667\n",
      "train loss:0.00036179644536330066\n",
      "train loss:0.001007007199475333\n",
      "train loss:0.00036396904463640895\n",
      "train loss:0.00042644437863572233\n",
      "train loss:0.0011230863033323433\n",
      "train loss:0.00022634600670921374\n",
      "train loss:0.0005016507160050117\n",
      "train loss:0.00034283314425171654\n",
      "train loss:0.0010133367381014516\n",
      "train loss:0.001001068195818171\n",
      "train loss:0.010282346179484467\n",
      "train loss:0.0009736883968346974\n",
      "train loss:0.0026334229403679795\n",
      "train loss:0.0009528118586260168\n",
      "train loss:0.00030892449424129223\n",
      "train loss:0.0023065537684719938\n",
      "train loss:0.0008842024695919751\n",
      "train loss:0.0010418143439070461\n",
      "train loss:0.0002922916257966279\n",
      "train loss:0.005791102153188358\n",
      "train loss:0.0005562658712250476\n",
      "train loss:3.110027499634263e-05\n",
      "train loss:0.00017593155743296076\n",
      "train loss:0.0001765432725106342\n",
      "train loss:0.009392481488053921\n",
      "train loss:0.0005994911599058389\n",
      "train loss:1.894235532528357e-05\n",
      "train loss:0.0010414440681670086\n",
      "train loss:0.00015056763732742293\n",
      "train loss:0.0004553282700555666\n",
      "train loss:0.0012475074620198153\n",
      "train loss:0.015715637910184273\n",
      "train loss:0.0024835352344480615\n",
      "train loss:0.0017364775345616887\n",
      "train loss:0.0010593256716090996\n",
      "train loss:0.0007543477138314245\n",
      "train loss:0.01279557319113898\n",
      "train loss:5.850555780216097e-05\n",
      "train loss:4.505291443905432e-05\n",
      "train loss:0.00038133428104717744\n",
      "train loss:0.0002186042687073644\n",
      "train loss:0.00028741533730047353\n",
      "train loss:0.0006457811429216656\n",
      "train loss:0.0010844001306081386\n",
      "train loss:0.001604031974837735\n",
      "train loss:0.004775452383792268\n",
      "train loss:5.836782044030308e-06\n",
      "train loss:0.00047004365935110476\n",
      "train loss:0.0003122729605801859\n",
      "train loss:0.000528457043306591\n",
      "train loss:0.00027409284030229826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010227784554064495\n",
      "train loss:0.0007553209390498128\n",
      "train loss:0.0009732715088626124\n",
      "train loss:0.0006263904192114944\n",
      "train loss:0.013323986021637592\n",
      "train loss:0.0015647900141864692\n",
      "train loss:6.757631558189202e-05\n",
      "train loss:0.0167298458988513\n",
      "train loss:0.001023717299278226\n",
      "train loss:9.573038848522213e-05\n",
      "train loss:0.0007292439378923491\n",
      "train loss:0.00033944533610592956\n",
      "train loss:0.0021294395515841554\n",
      "train loss:0.00013394239601013697\n",
      "train loss:0.004147986332696477\n",
      "train loss:0.0033731943585480566\n",
      "train loss:0.0006716580688043269\n",
      "train loss:0.0013889819527660105\n",
      "train loss:0.0015163473875323922\n",
      "train loss:8.928163628110953e-05\n",
      "train loss:0.0018973821663754282\n",
      "train loss:0.0009092372417248779\n",
      "train loss:0.0002373695631452393\n",
      "train loss:0.0036085187132698015\n",
      "train loss:0.0014063634550708368\n",
      "train loss:0.00017044026392579824\n",
      "train loss:0.0010161616559162538\n",
      "train loss:4.746107549453568e-05\n",
      "train loss:0.00022784064345909377\n",
      "train loss:0.0013299884025028074\n",
      "train loss:4.1829066503428993e-05\n",
      "train loss:0.0019348351850229499\n",
      "train loss:0.002615411966004638\n",
      "train loss:0.002257648582803314\n",
      "train loss:0.0023449065972520693\n",
      "train loss:0.0008991683482743943\n",
      "train loss:0.006176356348068934\n",
      "train loss:0.002428398257711483\n",
      "train loss:0.000861447732029531\n",
      "train loss:0.00024845994062500467\n",
      "train loss:0.00020728862839300747\n",
      "train loss:0.0005598520715429174\n",
      "train loss:0.0017193101364334823\n",
      "train loss:0.0007596164790233786\n",
      "train loss:0.0030277820354575637\n",
      "train loss:0.001840840642557867\n",
      "train loss:0.00013698274241086646\n",
      "train loss:0.00033681900324242995\n",
      "train loss:2.784896142464853e-05\n",
      "train loss:0.0011621425611979235\n",
      "train loss:0.001515805374533617\n",
      "train loss:0.000412286356204828\n",
      "train loss:0.0005204518310139593\n",
      "train loss:0.00018025371865485533\n",
      "train loss:0.0008044403813997554\n",
      "train loss:0.000191958453442347\n",
      "train loss:0.00018538978864768424\n",
      "train loss:0.0032139429799658264\n",
      "train loss:7.054731826376181e-05\n",
      "train loss:2.5231035555614737e-05\n",
      "train loss:0.00013148804250996056\n",
      "train loss:0.008454490987585639\n",
      "train loss:0.0013482228174654229\n",
      "train loss:0.0003528615909401442\n",
      "train loss:2.5274243042477364e-05\n",
      "train loss:0.00044661654704963595\n",
      "train loss:0.031022219206562195\n",
      "train loss:0.0009141309396898999\n",
      "train loss:0.0012101726005650153\n",
      "train loss:0.0029862282309405684\n",
      "train loss:0.0010692198938170281\n",
      "train loss:0.00460401193600914\n",
      "train loss:0.0027292853077070483\n",
      "train loss:0.0008479959818119942\n",
      "train loss:7.196377727812434e-05\n",
      "train loss:0.0042070412180535\n",
      "train loss:4.099220702836836e-05\n",
      "train loss:0.0002561690703584968\n",
      "train loss:0.0015941086442017862\n",
      "train loss:0.0002855317009955648\n",
      "train loss:0.0007672345821727551\n",
      "train loss:0.0018547049696614442\n",
      "train loss:0.0005482145027490939\n",
      "train loss:0.001466858156669206\n",
      "train loss:5.273359629603211e-05\n",
      "train loss:0.0007594767353875192\n",
      "train loss:0.0019948859835939325\n",
      "train loss:0.0013289040237719145\n",
      "train loss:0.001014863598706075\n",
      "train loss:0.01658867219918546\n",
      "train loss:0.0007838991042986265\n",
      "train loss:0.0004056758601096406\n",
      "train loss:0.0004230399828983677\n",
      "train loss:0.0007684776234446508\n",
      "train loss:0.001464409668940032\n",
      "train loss:0.00029242420054079367\n",
      "train loss:0.00011751436886670823\n",
      "train loss:0.00022464812142327384\n",
      "train loss:0.0005505162709687908\n",
      "train loss:0.0035754825559605823\n",
      "train loss:0.0001396922503572263\n",
      "train loss:0.0001849716782413422\n",
      "train loss:0.00015098366909523106\n",
      "train loss:0.0007821304665258517\n",
      "train loss:0.00032051684038781236\n",
      "train loss:0.0007882400438220711\n",
      "train loss:0.00037652297394223053\n",
      "train loss:0.0005134939818199183\n",
      "train loss:0.0004620219620967123\n",
      "train loss:0.0004551241457325589\n",
      "train loss:0.001696543137010008\n",
      "train loss:0.0025175638772477037\n",
      "train loss:0.0003269505846048176\n",
      "train loss:0.007948324310733508\n",
      "train loss:0.0012526645761578366\n",
      "train loss:0.00961164571538221\n",
      "train loss:0.00013694809146281667\n",
      "train loss:0.0002831021712971663\n",
      "train loss:0.00042395817801695024\n",
      "train loss:0.0003795011875763917\n",
      "train loss:0.0008784860856543376\n",
      "train loss:0.0010663007615927477\n",
      "train loss:0.00019995853373090704\n",
      "train loss:0.0036871697408917313\n",
      "train loss:0.00015760322643939027\n",
      "train loss:0.00043322778162254073\n",
      "train loss:0.0012993402734305414\n",
      "train loss:0.0006567434588016258\n",
      "train loss:0.0004555695852731555\n",
      "train loss:0.00019536967349719622\n",
      "train loss:7.785553081679879e-05\n",
      "train loss:1.5085278179662565e-05\n",
      "train loss:0.00027632780216361937\n",
      "train loss:0.0006803234402188687\n",
      "train loss:0.00040685853696554154\n",
      "train loss:0.0016090267476930723\n",
      "train loss:0.0020158279626669422\n",
      "train loss:0.0005143832248165673\n",
      "train loss:0.00039406414411958276\n",
      "train loss:0.00024563945095890474\n",
      "train loss:0.0014344966127647477\n",
      "train loss:0.0003599468397464406\n",
      "train loss:0.000293389944222147\n",
      "train loss:6.897041782004635e-05\n",
      "train loss:0.00025638574511769533\n",
      "train loss:0.00033755013690993976\n",
      "train loss:0.00022178384568753964\n",
      "train loss:0.0006990565308528395\n",
      "train loss:0.0005931181217037557\n",
      "train loss:8.074709398571601e-05\n",
      "=== epoch:20, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.00018943209212030724\n",
      "train loss:0.0003718892968446176\n",
      "train loss:0.00978956702023704\n",
      "train loss:0.0012334562775272876\n",
      "train loss:0.0003124269829428167\n",
      "train loss:0.00013004580166747767\n",
      "train loss:0.00031201107118445395\n",
      "train loss:0.00029734609814616896\n",
      "train loss:0.0006124979707878895\n",
      "train loss:0.0007790583934292319\n",
      "train loss:0.00036234190776764335\n",
      "train loss:0.0007840998491359537\n",
      "train loss:8.69433977450716e-05\n",
      "train loss:0.0009930258419838965\n",
      "train loss:0.00020014217518871073\n",
      "train loss:0.0007823658169371578\n",
      "train loss:0.002907608453701644\n",
      "train loss:0.001552911786906967\n",
      "train loss:0.0023395364293365807\n",
      "train loss:0.0002696984858430154\n",
      "train loss:8.293749195995534e-05\n",
      "train loss:0.00020024289457176454\n",
      "train loss:0.0005094517473621741\n",
      "train loss:7.798302657935563e-05\n",
      "train loss:0.00022898424527967014\n",
      "train loss:0.00015174725429579464\n",
      "train loss:0.0008528320888400064\n",
      "train loss:9.285433169013325e-05\n",
      "train loss:0.00033233383947597\n",
      "train loss:0.0014525329316464255\n",
      "train loss:0.0003393033178189554\n",
      "train loss:0.0015769853701645415\n",
      "train loss:0.00034623832967877155\n",
      "train loss:0.00011351301813818159\n",
      "train loss:0.0008502145027772698\n",
      "train loss:0.001195758414839576\n",
      "train loss:0.0022683291179355805\n",
      "train loss:0.00023586589535570755\n",
      "train loss:4.2088475527175295e-05\n",
      "train loss:0.0021215995130673803\n",
      "train loss:0.0002802764151773727\n",
      "train loss:0.001552135759972713\n",
      "train loss:0.0012006457678872273\n",
      "train loss:0.0001779201458727652\n",
      "train loss:0.00027181634484071157\n",
      "train loss:0.0002166876513976776\n",
      "train loss:0.0011560497865031035\n",
      "train loss:0.0010826272413493254\n",
      "train loss:0.0006436222240761577\n",
      "train loss:0.0005571339711899594\n",
      "train loss:0.00027032632819352627\n",
      "train loss:0.00037953842992504095\n",
      "train loss:0.0021283363223515432\n",
      "train loss:0.0001788508086165787\n",
      "train loss:0.00043305954390352537\n",
      "train loss:0.0003102612123874697\n",
      "train loss:0.0010409821990717424\n",
      "train loss:0.0010522403371549711\n",
      "train loss:0.002106756926140895\n",
      "train loss:0.00014264639494898613\n",
      "train loss:0.010817721422858882\n",
      "train loss:0.00039366631053751577\n",
      "train loss:0.0011642959620813678\n",
      "train loss:0.017424158202600872\n",
      "train loss:0.00010409627802020949\n",
      "train loss:0.0034630875421373746\n",
      "train loss:0.00016545240802047105\n",
      "train loss:0.0002711209571302054\n",
      "train loss:0.0005744086024872087\n",
      "train loss:0.0007997110943494215\n",
      "train loss:5.14106231943625e-05\n",
      "train loss:0.0006685483839659717\n",
      "train loss:0.0006033626411274984\n",
      "train loss:0.0013038063109707162\n",
      "train loss:0.0005552284810766506\n",
      "train loss:6.773096299612513e-05\n",
      "train loss:0.0007077423526258444\n",
      "train loss:0.004419191297572551\n",
      "train loss:0.0006247556335535396\n",
      "train loss:0.0028230240415311834\n",
      "train loss:0.0006611555904443065\n",
      "train loss:0.0011063888671286309\n",
      "train loss:0.00046949191340223205\n",
      "train loss:5.3309407482403655e-05\n",
      "train loss:6.124477180524096e-05\n",
      "train loss:8.37639913988544e-06\n",
      "train loss:0.006930014321201825\n",
      "train loss:0.0008530933615065694\n",
      "train loss:0.0002040233633620073\n",
      "train loss:3.755240259820536e-05\n",
      "train loss:0.00040888832709769815\n",
      "train loss:0.00045444786987889273\n",
      "train loss:0.0006778823411324117\n",
      "train loss:0.00024228337767211793\n",
      "train loss:0.0014305703542811948\n",
      "train loss:0.0003898135718023668\n",
      "train loss:0.001976144345839268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007689902939182483\n",
      "train loss:0.0011896143160825693\n",
      "train loss:0.0029791933047353435\n",
      "train loss:0.0017724451004550801\n",
      "train loss:0.00356873513266659\n",
      "train loss:0.0003229157703404244\n",
      "train loss:2.9563514491728217e-05\n",
      "train loss:0.0001887003592655566\n",
      "train loss:0.0016484210891342494\n",
      "train loss:0.0013333463423972722\n",
      "train loss:0.0003292622776815149\n",
      "train loss:0.0008343575364352372\n",
      "train loss:0.001910898437656437\n",
      "train loss:0.005668988736628748\n",
      "train loss:0.008161882239456988\n",
      "train loss:0.012195001033563422\n",
      "train loss:0.00020221286550778692\n",
      "train loss:4.905349590037936e-05\n",
      "train loss:0.0012947913747808058\n",
      "train loss:2.91451016784223e-05\n",
      "train loss:0.001997565079723294\n",
      "train loss:6.484295181669207e-05\n",
      "train loss:0.016853197513482004\n",
      "train loss:0.00026823493997006533\n",
      "train loss:0.0005207751229360601\n",
      "train loss:0.0008767025764806816\n",
      "train loss:0.003668314205757276\n",
      "train loss:0.0009640671656449403\n",
      "train loss:0.0014835046419001043\n",
      "train loss:0.02032422911508534\n",
      "train loss:0.0006477323960236283\n",
      "train loss:0.005101985686940803\n",
      "train loss:0.006046306481220248\n",
      "train loss:4.8818001349021486e-05\n",
      "train loss:0.004643500186308076\n",
      "train loss:0.0002706014741702034\n",
      "train loss:0.0017508007317345812\n",
      "train loss:0.0005511422604828071\n",
      "train loss:0.00016310523578544323\n",
      "train loss:0.0013885323566501556\n",
      "train loss:0.000547697193212363\n",
      "train loss:0.0026170736369464914\n",
      "train loss:0.003025275146118526\n",
      "train loss:0.002210869688399156\n",
      "train loss:0.0012804968505408388\n",
      "train loss:0.0010632409903299875\n",
      "train loss:0.0002964748529969137\n",
      "train loss:0.002839753442243118\n",
      "train loss:0.0005615363958972379\n",
      "train loss:0.0013229042533050377\n",
      "train loss:0.0010670517428359356\n",
      "train loss:0.0004012044447005386\n",
      "train loss:0.003459765810310657\n",
      "train loss:0.00045480246106394166\n",
      "train loss:0.0008452553155887056\n",
      "train loss:0.0001584199949108772\n",
      "train loss:5.454444728447713e-05\n",
      "train loss:0.0019056162650711464\n",
      "train loss:0.0012776137109623614\n",
      "train loss:0.000951253036788931\n",
      "train loss:0.00405132890676414\n",
      "train loss:0.0005095774493070221\n",
      "train loss:0.00018681223309967\n",
      "train loss:0.0010957579417541655\n",
      "train loss:0.0026918642413621685\n",
      "train loss:0.0035225800867168277\n",
      "train loss:0.0024901608733391076\n",
      "train loss:0.0011443724432835239\n",
      "train loss:0.006667245239740077\n",
      "train loss:0.003431845576039542\n",
      "train loss:0.0008312488841164701\n",
      "train loss:0.00032244301058817514\n",
      "train loss:0.0006464846870857708\n",
      "train loss:0.00022538694127611936\n",
      "train loss:0.00192086960009718\n",
      "train loss:0.010101939241009156\n",
      "train loss:0.0004133409965172129\n",
      "train loss:0.00046573764061109616\n",
      "train loss:0.004694197269168343\n",
      "train loss:7.265782448749207e-05\n",
      "train loss:0.00038450368606076453\n",
      "train loss:0.0008054082446257119\n",
      "train loss:9.218085709839993e-05\n",
      "train loss:0.0008210017806365809\n",
      "train loss:0.0005538611812294116\n",
      "train loss:0.0018745578141774058\n",
      "train loss:7.875063148083353e-05\n",
      "train loss:0.0020245855651380355\n",
      "train loss:0.00272179640546244\n",
      "train loss:0.0001549508227825243\n",
      "train loss:0.001903076012028944\n",
      "train loss:0.0013082595720486515\n",
      "train loss:0.00036542301756963956\n",
      "train loss:0.013599288525344195\n",
      "train loss:0.00018888083571037863\n",
      "train loss:0.0004923281957918606\n",
      "train loss:9.72297445913011e-05\n",
      "train loss:0.0013095996328975036\n",
      "train loss:0.0004644905613855612\n",
      "train loss:0.0001600699078917452\n",
      "train loss:0.003506990132982\n",
      "train loss:0.0008416969107581108\n",
      "train loss:0.00033861777617269164\n",
      "train loss:0.0026800786560565682\n",
      "train loss:0.001914021281519511\n",
      "train loss:0.0002225175649568167\n",
      "train loss:0.007539771395867345\n",
      "train loss:0.0007996144033623502\n",
      "train loss:0.0068214355540587735\n",
      "train loss:0.004116103180977867\n",
      "train loss:0.0010246482768697684\n",
      "train loss:0.00010562991192216997\n",
      "train loss:0.0022199779157769705\n",
      "train loss:0.0013264276200230902\n",
      "train loss:0.0031185641164962257\n",
      "train loss:0.0011615173390527595\n",
      "train loss:3.685554745113391e-05\n",
      "train loss:0.0010109071489330728\n",
      "train loss:0.0014951221309098988\n",
      "train loss:0.0003417698775811344\n",
      "train loss:7.137621368080004e-05\n",
      "train loss:0.003284911183755868\n",
      "train loss:0.0010038572844752467\n",
      "train loss:0.00015342988202697594\n",
      "train loss:0.00019157519713005567\n",
      "train loss:8.459193348809766e-05\n",
      "train loss:0.0005997659094081119\n",
      "train loss:0.0001892468664874271\n",
      "train loss:0.00013846083477975959\n",
      "train loss:0.0012395143271119408\n",
      "train loss:0.0022146883791629903\n",
      "train loss:2.3463944679517875e-05\n",
      "train loss:4.5338702863796535e-05\n",
      "train loss:0.0005753203396737438\n",
      "train loss:0.0005116423539510223\n",
      "train loss:0.00017991364991651646\n",
      "train loss:0.0050403951299345705\n",
      "train loss:0.000128889353015255\n",
      "train loss:0.0033189657453733218\n",
      "train loss:3.678943538080612e-05\n",
      "train loss:0.00012062684090658233\n",
      "train loss:0.008393141583855191\n",
      "train loss:0.000440405354188731\n",
      "train loss:0.0022579640128935034\n",
      "train loss:0.003922497634931379\n",
      "train loss:0.0013581704896750008\n",
      "train loss:0.001527311326545995\n",
      "train loss:0.004394704998349475\n",
      "train loss:0.0015769227104812486\n",
      "train loss:0.0003871734302237851\n",
      "train loss:0.0002130471315575216\n",
      "train loss:0.00022208175210660798\n",
      "train loss:0.00010846659417411817\n",
      "train loss:0.00010593105576574014\n",
      "train loss:0.0018790772276666865\n",
      "train loss:0.00022536954031531737\n",
      "train loss:0.0002531485162818925\n",
      "train loss:0.006065050247956697\n",
      "train loss:0.0003890949943168546\n",
      "train loss:0.0023955677476744106\n",
      "train loss:0.00021181786993545968\n",
      "train loss:0.0010570335963849\n",
      "train loss:0.00038379248588134724\n",
      "train loss:0.0026394738425550863\n",
      "train loss:0.0008597126918670063\n",
      "train loss:2.7985612653387326e-05\n",
      "train loss:0.0003171228776905348\n",
      "train loss:0.0009351038821592432\n",
      "train loss:8.840117507854985e-05\n",
      "train loss:0.00043795931600805374\n",
      "train loss:0.0005326922144733002\n",
      "train loss:0.015514364005828125\n",
      "train loss:0.0026388715993457368\n",
      "train loss:0.0012268133876732023\n",
      "train loss:0.0006811287162044193\n",
      "train loss:0.0001020079113733071\n",
      "train loss:0.005389751420191329\n",
      "train loss:0.0019834511108355215\n",
      "train loss:0.002596388274742464\n",
      "train loss:0.00029840200212876496\n",
      "train loss:0.00031092250799069843\n",
      "train loss:0.00020881877481767372\n",
      "train loss:0.0008848459086418588\n",
      "train loss:0.0012580165529367498\n",
      "train loss:0.0004812990227267594\n",
      "train loss:0.003093156915818207\n",
      "train loss:0.001144379470709582\n",
      "train loss:0.011969736560025684\n",
      "train loss:0.0005360070919815599\n",
      "train loss:0.004172209568480107\n",
      "train loss:0.0003701350277602635\n",
      "train loss:0.0008311683595804935\n",
      "train loss:0.0004907791796043997\n",
      "train loss:0.0026860707428655556\n",
      "train loss:0.010249277222354955\n",
      "train loss:0.0009587985338018194\n",
      "train loss:0.0026386963256452567\n",
      "train loss:0.00020707884212233684\n",
      "train loss:0.001219350929701648\n",
      "train loss:0.0003850116738126116\n",
      "train loss:0.0016126869692346909\n",
      "train loss:0.0005368846284522618\n",
      "train loss:0.005999419545375026\n",
      "train loss:7.599937942105175e-05\n",
      "train loss:0.003816667998859538\n",
      "train loss:0.001753670929964152\n",
      "train loss:0.0003533971845300691\n",
      "train loss:0.001180995947498994\n",
      "train loss:0.000700996708021327\n",
      "train loss:0.0016178415145799833\n",
      "train loss:0.0002979481804557626\n",
      "train loss:0.0004003407471981866\n",
      "train loss:0.001687702535959637\n",
      "train loss:0.005910972049730533\n",
      "train loss:0.0025093370286488415\n",
      "train loss:0.0007250152594722616\n",
      "train loss:0.0013007903993549944\n",
      "train loss:0.00040733630594363935\n",
      "train loss:0.0014668715424927953\n",
      "train loss:0.00030718260470718426\n",
      "train loss:0.0005917716879299576\n",
      "train loss:0.0017753947477394\n",
      "train loss:0.0008073669483052919\n",
      "train loss:0.0012616495126968024\n",
      "train loss:0.0065874134446758425\n",
      "train loss:0.0018209484279987584\n",
      "train loss:0.000681828895772856\n",
      "train loss:0.0018195817430029062\n",
      "train loss:0.0014227386156862\n",
      "train loss:0.00489069317889445\n",
      "train loss:0.007735095075430145\n",
      "train loss:0.004561150371491892\n",
      "train loss:0.0018396895829093712\n",
      "train loss:0.0006517415948507583\n",
      "train loss:0.00043538883484209903\n",
      "train loss:0.00010745134207008551\n",
      "train loss:0.011685217347984007\n",
      "train loss:0.005814140367090699\n",
      "train loss:0.0001806572514676638\n",
      "train loss:0.0006705731207162969\n",
      "train loss:0.0013063892089392932\n",
      "train loss:0.0006776183978476514\n",
      "train loss:0.00017147332548835646\n",
      "train loss:0.0032608573075116293\n",
      "train loss:0.003472571616855822\n",
      "train loss:0.00256799465928469\n",
      "train loss:0.0023618990476323865\n",
      "train loss:0.0016742648138510132\n",
      "train loss:0.0051008899368918115\n",
      "train loss:8.562612598586877e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00028816616738635875\n",
      "train loss:5.567662689486119e-05\n",
      "train loss:0.0003481943167634468\n",
      "train loss:0.0011608223715882957\n",
      "train loss:0.0006776039196392361\n",
      "train loss:0.001143523109572073\n",
      "train loss:0.0026590254082711705\n",
      "train loss:0.0009671142111676392\n",
      "train loss:0.003851891257880413\n",
      "train loss:0.000783858312467735\n",
      "train loss:0.004029037245215801\n",
      "train loss:0.0014179745594994138\n",
      "train loss:0.00031160184809169464\n",
      "train loss:0.01932738175650587\n",
      "train loss:0.00806894478182254\n",
      "train loss:0.0016275106758225342\n",
      "train loss:0.003057990919555841\n",
      "train loss:0.0002211330170701203\n",
      "train loss:0.0017584582827022677\n",
      "train loss:0.0001820731533045993\n",
      "train loss:0.00011104429387856354\n",
      "train loss:0.0012455355343131901\n",
      "train loss:0.0027052462115503707\n",
      "train loss:0.0007960327893317497\n",
      "train loss:0.0006021382440937365\n",
      "train loss:0.003497681258994211\n",
      "train loss:0.0009111772319801768\n",
      "train loss:0.0025084129579018132\n",
      "train loss:0.0030252802865564942\n",
      "train loss:0.0014998093346673504\n",
      "train loss:0.001346412562144325\n",
      "train loss:0.0011772587400544917\n",
      "train loss:0.00018960613078344377\n",
      "train loss:0.0012150168511945642\n",
      "train loss:0.0035036991263642566\n",
      "train loss:0.006840684685484056\n",
      "train loss:0.0010058894089688666\n",
      "train loss:0.0008677517562508129\n",
      "train loss:0.0007807600748943822\n",
      "train loss:0.0016291921241150978\n",
      "train loss:0.00040804597559343715\n",
      "train loss:0.005483201033420232\n",
      "train loss:0.002783733818133782\n",
      "train loss:0.001131968451980951\n",
      "train loss:5.76152595042049e-05\n",
      "train loss:0.001396615317882442\n",
      "train loss:0.009409636999279129\n",
      "train loss:0.00020125460401275729\n",
      "train loss:0.0007202049733104134\n",
      "train loss:0.007779832625284575\n",
      "train loss:0.0001994043441251455\n",
      "train loss:0.0027609042752033183\n",
      "train loss:0.0073041130705975114\n",
      "train loss:0.0007241107518212792\n",
      "train loss:0.0006469068590031184\n",
      "train loss:0.00034410533136039446\n",
      "train loss:0.0020175026622802593\n",
      "train loss:0.0014777544714713485\n",
      "train loss:0.00132102372588186\n",
      "train loss:0.0003314188837258675\n",
      "train loss:0.0002930782787305536\n",
      "train loss:0.0008861672870701551\n",
      "train loss:0.011915247918884405\n",
      "train loss:0.004729304898815787\n",
      "train loss:0.001044042382926893\n",
      "train loss:0.00016739470661061167\n",
      "train loss:0.013569850673899793\n",
      "train loss:0.0031504433535763216\n",
      "train loss:0.0002237167233970047\n",
      "train loss:0.00044445655533293423\n",
      "train loss:0.0002306969127805791\n",
      "train loss:0.0013620754778582691\n",
      "train loss:0.0004886806426519344\n",
      "train loss:0.0023417653244229906\n",
      "train loss:0.001115764568476234\n",
      "train loss:0.00011476442664043285\n",
      "train loss:0.004649635565728113\n",
      "train loss:0.0001222877700085131\n",
      "train loss:0.002173201363374134\n",
      "train loss:0.0018939133913298128\n",
      "train loss:0.001260091105211155\n",
      "train loss:0.002684756465250273\n",
      "train loss:0.0027913692341420436\n",
      "train loss:0.001736520683924561\n",
      "train loss:0.0032245516828660055\n",
      "train loss:0.004228984534095816\n",
      "train loss:0.0006989063563021263\n",
      "train loss:0.005463638695292231\n",
      "train loss:0.0016210976555580126\n",
      "train loss:0.0021189926136380367\n",
      "train loss:0.0012311585554178018\n",
      "train loss:0.00017376747682346251\n",
      "train loss:0.0017718972621244662\n",
      "train loss:0.0010649199769366814\n",
      "train loss:0.0002656236291349506\n",
      "train loss:0.0016507190784578404\n",
      "train loss:0.003246998268189778\n",
      "train loss:0.0012666264082860357\n",
      "train loss:0.00280547632439075\n",
      "train loss:0.0008588691750615178\n",
      "train loss:0.0003150101620896892\n",
      "train loss:0.0017806943012882112\n",
      "train loss:0.002454058972484822\n",
      "train loss:0.0009330808393131593\n",
      "train loss:0.00011761870687433963\n",
      "train loss:9.139293394532773e-05\n",
      "train loss:0.0014607307904661486\n",
      "train loss:0.000182124347803027\n",
      "train loss:0.0016091104797625177\n",
      "train loss:0.0007075671011861761\n",
      "train loss:0.0012787594395787798\n",
      "train loss:0.0004823230026868076\n",
      "train loss:0.00014529978498750373\n",
      "train loss:0.000423324829113366\n",
      "train loss:0.001143077487767523\n",
      "train loss:0.0010745411226556678\n",
      "train loss:1.1537748610116498e-05\n",
      "train loss:8.882696655405072e-05\n",
      "train loss:0.00018261731425634674\n",
      "train loss:0.0015929895896402446\n",
      "train loss:0.0014193731454792296\n",
      "train loss:0.001618774944749884\n",
      "train loss:0.0027774227726305705\n",
      "train loss:0.0014048219279938518\n",
      "train loss:0.005101567240380491\n",
      "train loss:0.001784540561287623\n",
      "train loss:4.600484895934738e-05\n",
      "train loss:0.001650265449793531\n",
      "train loss:4.880283283913798e-05\n",
      "train loss:3.5114462684750156e-05\n",
      "train loss:0.0011621499368140039\n",
      "train loss:0.0007368746742769657\n",
      "train loss:0.006468234291990349\n",
      "train loss:5.030584275959247e-06\n",
      "train loss:0.002500069220793012\n",
      "train loss:0.00016981946673221414\n",
      "train loss:0.0003322039485988505\n",
      "train loss:0.0025437649280390284\n",
      "train loss:0.00043870526865778624\n",
      "train loss:0.00037004567563863\n",
      "train loss:0.0006853408623438777\n",
      "train loss:0.0054232885786512875\n",
      "train loss:0.0007361373446368899\n",
      "train loss:0.00019731825801862804\n",
      "train loss:0.0007658665713007414\n",
      "train loss:0.005170531511323966\n",
      "train loss:0.001739651653417684\n",
      "train loss:0.003865468435465581\n",
      "train loss:0.001097598483476134\n",
      "train loss:0.002907717818228549\n",
      "train loss:0.0005505924714750695\n",
      "train loss:0.004833550274752826\n",
      "train loss:1.629203703235447e-05\n",
      "train loss:0.005413792287996545\n",
      "train loss:0.006034573123673677\n",
      "train loss:0.0005655549434160706\n",
      "train loss:0.0010727955595715324\n",
      "train loss:0.001294845724180529\n",
      "train loss:0.0010287939203517961\n",
      "train loss:0.0007480410099626572\n",
      "train loss:0.0031357060831339184\n",
      "train loss:0.0023612906290722594\n",
      "train loss:0.0012993505857987414\n",
      "train loss:0.0001674352056259114\n",
      "train loss:0.0005116015276175621\n",
      "train loss:0.0012109841572614543\n",
      "train loss:0.005136975150043252\n",
      "train loss:0.00018933128256095957\n",
      "train loss:0.006976994240579914\n",
      "train loss:0.00028624192555041383\n",
      "train loss:0.0003684055613662811\n",
      "train loss:0.0020347503123779643\n",
      "train loss:0.00034637372008486324\n",
      "train loss:0.0006049707113741941\n",
      "train loss:4.1922588983506094e-05\n",
      "train loss:0.0012362058668493768\n",
      "train loss:0.0008608474525922612\n",
      "train loss:0.0006356047195917849\n",
      "train loss:0.0015055193568816385\n",
      "train loss:0.00026261413799273767\n",
      "train loss:0.0020149827637793894\n",
      "train loss:0.0022444045428170506\n",
      "train loss:0.0029550132746807923\n",
      "train loss:0.0002980710891140196\n",
      "train loss:0.00041183836912293603\n",
      "train loss:1.1416585432915613e-05\n",
      "train loss:0.00396765869250392\n",
      "train loss:0.0003107839935444451\n",
      "train loss:9.374365880911204e-05\n",
      "train loss:0.0009017900551530923\n",
      "train loss:8.694101261402546e-05\n",
      "train loss:0.0025878817660363045\n",
      "train loss:0.005509681586245002\n",
      "train loss:9.704062536904964e-05\n",
      "train loss:8.412250794198576e-05\n",
      "train loss:9.753334240885793e-05\n",
      "train loss:0.00602960656221476\n",
      "train loss:9.239788647334882e-05\n",
      "train loss:0.0002853263983051416\n",
      "train loss:0.0017318083161074105\n",
      "train loss:7.394180682961987e-05\n",
      "train loss:0.0006143709631208092\n",
      "train loss:0.0036436181119750746\n",
      "train loss:0.00045664755475380883\n",
      "train loss:0.00014908952577097627\n",
      "train loss:0.001725440450490347\n",
      "train loss:0.0012600509267958182\n",
      "train loss:0.003488732462953816\n",
      "train loss:0.00017904306718366565\n",
      "train loss:0.00024124416418551484\n",
      "train loss:0.002633657364957374\n",
      "train loss:0.0010895378303680244\n",
      "train loss:0.0014584984075183053\n",
      "train loss:0.00038166795454528063\n",
      "train loss:0.0009110506300797434\n",
      "train loss:0.0013865007790806669\n",
      "train loss:6.049089407721895e-06\n",
      "train loss:0.0013453429962596076\n",
      "train loss:0.0026335692781213295\n",
      "train loss:0.0035304401420753915\n",
      "train loss:0.002289494000376564\n",
      "train loss:0.00279880599350904\n",
      "train loss:0.0005787231940554209\n",
      "train loss:0.0005678542455417126\n",
      "train loss:0.0019256777071495507\n",
      "train loss:0.0007656706659116444\n",
      "train loss:0.0005957633439384085\n",
      "train loss:0.0007084562970229575\n",
      "train loss:0.0001961393702309059\n",
      "train loss:0.0006295919506738147\n",
      "train loss:0.005707365534094948\n",
      "train loss:0.0002929810991341961\n",
      "train loss:0.0003264916911402318\n",
      "train loss:3.144623386084936e-05\n",
      "train loss:0.0007368515177041471\n",
      "train loss:0.0004339404889110403\n",
      "train loss:0.00297923587597192\n",
      "train loss:0.00043174818666024344\n",
      "train loss:2.5512176058332757e-05\n",
      "train loss:0.013788673626161629\n",
      "train loss:0.00021049155802916974\n",
      "train loss:0.0013114520112620684\n",
      "train loss:0.0015783160482770757\n",
      "train loss:0.0040921126145963506\n",
      "train loss:0.01163910499181672\n",
      "train loss:0.0021213670019587304\n",
      "train loss:0.0017405237542977275\n",
      "train loss:7.436091715315555e-05\n",
      "train loss:0.00015988808373533327\n",
      "train loss:0.003268279866541433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002113696349307682\n",
      "train loss:0.00013112223291044252\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9891\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XucZGV95/HPr6qru/o2fZ37IAxI0MEQBkbUAEbXCwwxXLKuAcUQ4zoaJdFNmJWJCaC7USIbzZJVCTEYxRtEFIiOgijqK1GEGRgvDOCMBJ2ea9MzfZ2u7q6q3/5xTtfUVFd1V/fMqerp+r5fXa+qes5z6vzqdNX51bk8z2PujoiICECs2gGIiMj8oaQgIiI5SgoiIpKjpCAiIjlKCiIikqOkICIiOZElBTO7w8wOmNnPS0w3M7vVzHaa2U/N7JyoYhERkfJEuafwL8DF00xfD5we3jYAn4owFhERKUNkScHdfwAcnKbKZcDnPPAI0G5my6OKR0REZlZXxWWvBHblPe8Jy/YWVjSzDQR7EzQ3N5/7ohe9qCIBLhT9hyfYN5hiIpMlEY+xbFGS9qZETSzf9/0My6anlsfqsGW/ObfXBDJZn3rzqWVDqQlK9RlQFzMMI/zL3R9VBpgFZTY53cLHBrHJcjt6emyyDFg08DR1ZKYsP02cw50vntUbzzq4B+/VHbLuZHP3YVn26LKxdLbkS8bMSk4rXh/iMaMuZsRjRixm1MVixC14Xuw2lJpgT3+KbF7vDQYsbm0gmYgzkcmSzjjprOc9zpLOzr23h1j4P4iZMZHJFv0MGNCQiIODhzXcydWd7G0iv2x5W5LO5vo5xbR169bn3X3xTPWqmRSKfRqK/hfc/XbgdoB169b5li1booxrQUl95FSSY31Tyxu6SG569oRefibrjIynGU6lGR5LMxTeD6fSjIylGRpL8/aHzi45/9tO/iTpbLDhSmfC+6yTDTfwhWUTGWdwdIKhsalJZlIMaKmP09aYoK0xwZ2HrmaxDUyp1+ttfOy3vh4mD8hks2Q8vD8q0RwpS2eCjdZYOst4Jst4OryFjycyWSYyR75CHt62Jd9cMt5TUh8uZ1UXZUCdQWMiTlN9nGR435jIe1wf54O/uKLkOvinlz1Q9vKyWWd4LE3/4QkGRo++DY+lcSAd3vI91vAnJZf/0rHgqHVj3Fjc0sDi1vxbMrhvaWDJoga6muvJZJ3RiQypiQyHxzOMjmcYnThyf3g8mDY6nuHwRIbUeIZN2y8tufxNp96TS14xC5JdLC/pxWMWJrwY8Rhc/JLlnHtyR9nrLJ+Z/aqcetVMCj3ASXnPVwF7qhRLdG45HUYOTC1vXgIbd8zpJbNZJ5UOP3jjeR/QibwPaPihfGuRDTJAcqyPD/7bk3Na/mzcOM3yr7t7G/HMKA0TgzSkB0mmh2hID9KUGSSZGaIpvDVnh2jKDpHMHmbCY4xm68JbnHESjHtdcE8dY+H9uAf3TLND8ju9X6SeCeotHdwzeT9BgjQJnyDBBHXh47hlSbe1kGlow5PtWGM78eZOEs2dNLR20biom+a2LhItndDYAYlGuGnqxgBgsQ3wkd8/K3iSHoexIRgbDO/D2/hwQdkwpFOQGYf0GGTGgnnz7j0d3EiP45PlqdLr4BeL30823oDH6vH4kVs2Vo/HG46UxerJxuuJ1zcTTzZR19BCItlMXbIZq2+CRDMkGqC+CRJNwXtPNAf3Hy69Dv7y/FYYPwwTh2FiFCZGgvtcWf60FCTroTtvGfXBMtLxJCPZBoayCQYz9fSn6xiYSNA3Hmfxd0ov/7vveCFd9RlaY2PE0qlw+YeOjungCOwPl1/fDI3twf832Q4teY8bl0AiOXVB03wGPn3NS48UZCYgNQCjh2C0H1L9Rx6PHgqe2+XAy0r/Q4+DaiaF+4FrzezLBO9ywN2nHDo64RVLCJPlv/xu7gvvqUHGRgYYGTrE2MgAEyMDZFLBtPjEEPXpEep8jAmPM5a3EQw2inmPCTaUaU8AddP+h9u33jqrt2JAnAxxssTIUkeGGFniuVsmdz9ZPp0Pb38N9VN+1x2RIcaItTISa2Ek3kqqromkZWmzNPWMkGCChE9QF97i2XFi2XEsM46VPGhzxB8d/syRd1bXAPEGqKsvcd8EFgv+X6kd8Pyh4Avs07zHeMP0AXz0tOD1MmMzxgoGDa1T44wnjpQl27B4A1YY+5Z/Lvmq9ae8IkgyuUQT3qeHIDVekHjGgo1kdqKMeMv08TPLq2fxIAlMxlqgDmgLb7Nx6p3nzW754yOUOKARBpIME0THkeQxndsuCDf6/TA+NH3d+lZYsgZecIImBTP7EvAqoNvMeoAbCX+3ufttwGbgEmAncBh4W1SxVMVIH+x5Yvo6d16Re2hAEnCvJ0sjKW9kmEbG482kE0vw5lbi9Y0kY5ngF61N0EywMZzcMMZ9lLiPBxvHzASx7DiMll78e/ny3N9frC64WTx8HCv+fJpLDeov+NOjv0AFj+MNrSwyY9FsY3OHbDrYiH1kZel6m3YHG9RYXXCAfray2eCXfKr/6F9z+b/0/uP/lp5/zWXQ0BJs7BsWhff5t0VQH06vb55bjDBtUuC//tPsXy8zceRX9Hj4y/6oX/kFZQ/dVPq1Lv2H8Ff/5N5FU97eRt7eQDxvly+TnroXUbhnMT65d3EYHrqx9PJ/79bc3kZumfUF8SSaggQL4f98oOD/XeJ/P9oP/btKLxtg0SpY+pK8vY2Oo/dEco/bjl4HEYosKbj7VTNMd+A9US3/eEtNZPj3Hc/TPzrByFj+MewJMiOH6Bp6iuUjT3Ny6hlOS+9guZfYQ8jzrvoP09jSTktbB4vaOuns6GRpRwvL25Isa2vkpNYGEvFjvEDspml+O/1V7+xfb3KDfzyW/9qbZr/8cpgFX6CZvkQNLce2nFgs/NK2Q6kfhNMlhTd87NiWXy3xBMTbgg1VOaZLCuf84RyWXwfxRZAs8+fCdEnh3Gtmt+xYLNxwdwCry5tnuu/Am4/hh1lEqnn46IRy12O7uPH+J2lmlDPtOc6KPcvZ8Wc5K/afvIB9uXoH6pbT03Im21reyMG2M3nL06Xz3m1/WeWcWDe3qxhOKM1LSp/TqRVaBzILSgplyvz6MR5quInTbPeR49WLVsGKdbDyHFixFpafzZKmTo76qt1U5Q1/tTcI1V7+HE/mHzfVfv+gdVDry58lJYUyLTvwA0613dirrocV58CKs6Fl5n9qqqGr9CWZUQRaqNobhGovv9pq/f1D9ddBrS9/lpQUytQwup+BWDsdr7p+VvMlNz3LvU/s5pYHnmFP/ygr2hvZeNEZXL52mhOgIiJVoqRQppaxAwzWLyl5PnE6l69dqSQgIicEdZ1dBnenI9NLqnFZtUMREYmUkkIZBkfTLOUg6WYlBRFZ2JQUyrC/r482O0xskQ4BicjCpqRQhoH9QT9SDV2rqhyJiEi0lBTKMPL8rwFo7j65ypGIiERLSaEME4d6AGhfpqQgIgubkkI5BoMevRs6dfhIRBY2JYUy1I3sY9Bag14TRUQWMCWFMjSn9tFfN+ModiIiJzwlhTIsmniekYb52XmViMjxpKQwg0zW6c4+z3iTGq6JyMKnpDCDvv5Bum0QX7Si2qGIiEROSWEGfWHDtbp2tWYWkYVPSWEGwweCMVabuk+qciQiItFTUphB6mCQFBYtUcM1EVn4lBRmkO3fDUD7UiUFEVn4lBRmEBvewwhJ6praqx2KiEjklBRm0HB4P4fi3WBW7VBERCKnpDCD1vFgGE4RkVqgpDCDjszzpJJLqx2GiEhFKClMIzU2TrcfItOyvNqhiIhUhJLCNPr291BnWWJtas0sIrVBSWEag/ufA6ChUw3XRKQ2KClMIzcM55IXVDkSEZHKUFKYxsShYMS1zmWnVDcQEZEKUVKYztBuxr2ORZ3qNltEaoOSwjQSI/t4PtaFxbSaRKQ2aGs3jabUfg3DKSI1RUlhGm0TvYwk1ZpZRGqHkkIJns3Sne1jQsNwikgNiTQpmNnFZvaMme00s+uLTH+BmT1sZk+Y2U/N7JIo45mNkf4DNNgEaBhOEakhkSUFM4sDnwDWA2uAq8xsTUG1vwLudve1wJXAJ6OKZ7YO7nsOgLr2VdUNRESkgqLcUzgP2Onuz7r7OPBl4LKCOg4sCh+3AXsijGdWjgzDqYZrIlI7okwKK4Fdec97wrJ8NwFXm1kPsBn402IvZGYbzGyLmW3p7e2NItYpUn3hMJxLlRREpHZEmRSKjUrjBc+vAv7F3VcBlwB3mtmUmNz9dndf5+7rFi+uzCWi2cEeMm50L1O/RyJSO6JMCj1A/hZ1FVMPD70duBvA3X8EJIHuCGMqW3xoL89bB03JZLVDERGpmCiTwmPA6Wa22szqCU4k319Q59fAawDM7MUESaEyx4dm0DC6n4OxeZGfREQqJrKk4O5p4FrgAeApgquMnjSzD5nZpWG1vwDeYWY/Ab4E/JG7Fx5iqorW8QMMNajhmojUlrooX9zdNxOcQM4vuyHv8Xbg/ChjmKvOzPP8Z+N51Q5DRKSi1KK5iOzoAM2MahhOEak5SgpFDBwIBteJtxVeQSsisrApKRTRH7ZmbuhUa2YRqS1KCkVMNlxrWXxylSMREaksJYUiJvp3A9CxTK2ZRaS2KCkUM7CHPm9lcUdbtSMREakoJYUi6g/v5XnrJhHX6hGR2qKtXhFNqQP0J9SaWURqj5JCEW3pXg4nl1Y7DBGRilNSKDSRos0HNQyniNQkJYUC44eCK480DKeI1CIlhQIDB54DINGhhmsiUnuUFAoM92oYThGpXUoKBcYmh+FcoqQgIrVHSaFAdmA3g97Ikm5dkioitUdJoUB8eC/76aSjqb7aoYiIVJySQoHk6H4OxhcTi1m1QxERqTglhQKt4wcYrl9c7TBERKpCSSFfZoL27EFSjWq4JiK1SUkh3/B+YjjZVg3DKSK1SUkhz2h4OWpMw3CKSI1SUsgzuP9XACQ1DKeI1CglhTyHwz2F1iUahlNEapOSQp50/25SnqCzWyeaRaQ2KSnkscE97PNOlrU3VjsUEZGqUFLIU394Hwesi5aGumqHIiJSFUoKeZpS+xlIqOGaiNQuJYVJ2Sxt6ec1DKeI1DQlhUmH+0iQJq1hOEWkhikphHywJ3igYThFpIYpKYRGwhHXNAyniNQyJYXQUO+vAQ3DKSK1TUkhNH6wh7TH6Fiiw0ciUruUFEI+sJv9dLCkrbnaoYiIVE2kScHMLjazZ8xsp5ldX6LOm8xsu5k9aWZfjDKe6cSH97LPO1myqKFaIYiIVF1kTXfNLA58Angd0AM8Zmb3u/v2vDqnA5uA8939kJktiSqemSRT++mLr6ShLl6tEEREqi7KPYXzgJ3u/qy7jwNfBi4rqPMO4BPufgjA3Q9EGE9p7hqGU0SEaJPCSmBX3vOesCzfbwC/YWb/YWaPmNnFxV7IzDaY2RYz29Lb23v8I00NkPQUYxqGU0RqXJRJwYqUecHzOuB04FXAVcCnzax9ykzut7v7Ondft3hxBL/mB/cAkG3VlUciUtvKSgpmdo+Z/a6ZzSaJ9AAn5T1fBewpUuc+d59w9/8EniFIEhWVGdgNQFzDcIpIjSt3I/8p4M3ADjO72cxeVMY8jwGnm9lqM6sHrgTuL6hzL/BqADPrJjic9GyZMR03w2HDtWSXWjOLSG0rKym4+0Pu/hbgHOA54Ntm9kMze5uZJUrMkwauBR4AngLudvcnzexDZnZpWO0BoM/MtgMPAxvdve/Y3tLsjT4fDsPZfdIMNUVEFrayL0k1sy7gauCtwBPAF4ALgGsIzglM4e6bgc0FZTfkPXbgz8Nb1aT7e+j1NpZ0LKpmGCIiVVdWUjCzrwIvAu4Efs/d94aT7jKzLVEFVyk2tJd93sHSNjVcE5HaVu6ewv9z9+8Wm+Du645jPFVRf3gf++hiTbOSgojUtnJPNL84/1JRM+sws3dHFFPFNY/tZ7BuMfFYsatoRURqR7lJ4R3u3j/5JGyB/I5oQqqw8cM0ZYYYadQwnCIi5SaFmJnlfkaH/RrVRxNShQ0Fp0c0DKeISPnnFB4A7jaz2whaJb8L+FZkUVXSYNBwzdRwTUSk7KTwfuCdwJ8QdF/xIPDpqIKqpPFDPdSjYThFRKDMpODuWYJWzZ+KNpzKG+n9NfVAk1ozi4iU3U7hdOAjwBogOVnu7qdGFFfFjB/sYcCbWNzVWe1QRESqrtwTzZ8h2EtIE/RV9DmChmwnvOzgHvZ6F0sXJWeuLCKywJWbFBrd/TuAufuv3P0m4L9EF1bl1A3vYZ93KimIiFD+ieZU2G32DjO7FtgNVG3ozOOpMXWAA/ZbLEpGNjKpiMgJo9w9hfcBTcCfAecSdIx3TVRBVUx6nKaJg4w0LCavGYaISM2a8edx2FDtTe6+ERgG3hZ5VJUyvI8YzpgaromIAGXsKbh7BjjXFuJPaQ3DKSJylHIPpD8B3Gdm/wqMTBa6+1cjiapCfHAPhobhFBGZVG5S6AT6OPqKIwdO6KSQ6ttFI9DYpRHXRESg/BbNC+c8Qp5U3y7cG2jvXFztUERE5oVyWzR/hmDP4Cju/sfHPaIKSvf3cNA7WdbWWO1QRETmhXIPH30973ESuALYc/zDqaxgGM5OVi3SiGsiIlD+4aN78p+b2ZeAhyKJqIIaDu9jHy/kXLVmFhEBym+8Vuh04AXHM5CKy2ZpGuvlUHwxyUS82tGIiMwL5Z5TGOLocwr7CMZYOHGN9BInw2hSw3CKiEwq9/BRa9SBVFw44lq6Ra2ZRUQmlXX4yMyuMLO2vOftZnZ5dGFVQNiamUVquCYiMqnccwo3uvvA5BN37wdujCakysgOBHsK9R1KCiIik8q9JLVY8jih+5oePbiLhMdZ1LW82qGIiMwb5e4pbDGzj5nZaWZ2qpl9HNgaZWBRmzjYwwE6WNLWVO1QRETmjXKTwp8C48BdwN3AKPCeqIKqhOzAHvZqxDURkaOUe/XRCHB9xLFUVN3IXvb5Cl6qpCAiklPu1UffNrP2vOcdZvZAdGFFzJ3G1H72eRfdLfXVjkZEZN4o9/BRd3jFEQDufogTeYzm0UMksmMM1y+mLj7XRt0iIgtPuVvErJnlurUws1Mo0mvqCSNso6BhOEVEjlbuZaUfAP7dzL4fPn8lsCGakCpAw3CKiBRV7onmb5nZOoJEsA24j+AKpBPTUJAU6trVcE1EJF+5J5r/O/Ad4C/C253ATWXMd7GZPWNmO82s5NVLZvZGM/Mw8UQu3d9D1o2mTiUFEZF85Z5TeC/wUuBX7v5qYC3QO90MZhYHPgGsB9YAV5nZmiL1WoE/A348i7iPSaqvh17aWNzeXKlFioicEMpNCil3TwGYWYO7Pw2cMcM85wE73f1Zdx8HvgxcVqTe/wI+CqTKjOWYZfp71HBNRKSIcpNCT9hO4V7g22Z2HzMPx7kS2JX/GmFZjpmtBU5y9/zhPqcwsw1mtsXMtvT2TruDUpbY8D72eZeSgohIgXJPNF8RPrzJzB4G2oBvzTCbFXup3ESzGPBx4I/KWP7twO0A69atO+ZLYesP72Wfr+ZlSgoiIkeZdU+n7v79mWsBwZ7BSXnPV3H03kUr8BLge2YGsAy438wudfcts42rbGNDNKSH6bUu2psSkS1GROREFGVz3seA081stZnVA1cC909OdPcBd+9291Pc/RTgESDahAAwuBeAw8mlhMlIRERCkSUFd08D1wIPAE8Bd7v7k2b2ITO7NKrlzihso5Bp0TgKIiKFIh0ox903A5sLym4oUfdVUcaSE7ZmjmkYThGRKWqvN7jBYBjOhBquiYhMcUIPqTkXE4d2M+QtdLe3VTsUEZF5p+b2FMYP9bBfDddERIqquaTgGoZTRKSkmksKiZG97PNOli5qqHYoIiLzTm0lhfQYDeMHtacgIlJCbSWFoaDhWn9dN80NNXeOXURkRrWVFDQMp4jItGoyKbiG4RQRKaomk0Jd+6oqByIiMj/V1IF1H9zNiCdp6+iqdigiIvNSTe0pjB/sYZ93skyXo4qIFFVTSSEzsFuXo4qITKOmkkJsKGi4tkRJQUSkqNpJCpk09ale9tHJsjYlBRGRYmonKYwcIOYZ9nkni1t0TkFEpBhz92rHMCvr1q3zLVtmMWLnLafDyIGp5c1LYOOO4xeYiMg8ZmZb3X3dTPUW/p5CsYQwXbmISA1b+ElBRETKpqQgIiI5SgoiIpKjpCAiIjkLPyk0L5lduYhIDVvwHeLd+9rvsemrP2N0IpMra0zE+chrf5PLqxiXiMh8tOD3FG554JmjEgLA6ESGWx54pkoRiYjMXws+KezpH51VuYhILVvwSWFFe+OsykVEatmCTwobLzqDxkT8qLLGRJyNF51RpYhEROavBX+i+fK1K4Hg3MKe/lFWtDey8aIzcuUiInLEgk8KECQGJQERkZkt+MNHIiJSPiUFERHJUVIQEZEcJQUREcmJNCmY2cVm9oyZ7TSz64tM/3Mz225mPzWz75jZyVHGIyIi04ssKZhZHPgEsB5YA1xlZmsKqj0BrHP3s4CvAB+NKh4REZlZlHsK5wE73f1Zdx8Hvgxcll/B3R9298Ph00eAVRHGIyIiM4gyKawEduU97wnLSnk78M1iE8xsg5ltMbMtvb29xzFEERHJF2VSsCJlXrSi2dXAOuCWYtPd/XZ3X+fu6xYvXnwcQxQRkXxRtmjuAU7Ke74K2FNYycxeC3wA+B13H4swHhERmUGUewqPAaeb2WozqweuBO7Pr2Bma4F/BC519wMRxiIiImWILCm4exq4FngAeAq4292fNLMPmdmlYbVbgBbgX81sm5ndX+LlRESkAiLtEM/dNwObC8puyHv82iiXLyIis1MTvaSKiExMTNDT00Mqlap2KJFKJpOsWrWKRCIxp/mVFESkJvT09NDa2sopp5yCWbGLI0987k5fXx89PT2sXr16Tq+hvo9EpCakUim6uroWbEIAMDO6urqOaW9ISUFEasZCTgiTjvU9KimIiEiOkoKISBH3PrGb82/+Lquv/wbn3/xd7n1i9zG9Xn9/P5/85CdnPd8ll1xCf3//MS17NpQUREQK3PvEbjZ99Wfs7h/Fgd39o2z66s+OKTGUSgqZTGba+TZv3kx7e/uclztbuvpIRGrOB//tSbbvGSw5/Ylf9zOeyR5VNjqR4X9+5ad86dFfF51nzYpF3Ph7Z5Z8zeuvv55f/vKXnH322SQSCVpaWli+fDnbtm1j+/btXH755ezatYtUKsV73/teNmzYAMApp5zCli1bGB4eZv369VxwwQX88Ic/ZOXKldx33300NjbOYQ2Upj0FEZEChQlhpvJy3HzzzZx22mls27aNW265hUcffZS/+Zu/Yfv27QDccccdbN26lS1btnDrrbfS19c35TV27NjBe97zHp588kna29u555575hxPKdpTEJGaM90veoDzb/4uu/tHp5SvbG/krne+4rjEcN555x3VluDWW2/la1/7GgC7du1ix44ddHV1HTXP6tWrOfvsswE499xzee65545LLPm0pyAiUmDjRWfQmIgfVdaYiLPxojOO2zKam5tzj7/3ve/x0EMP8aMf/Yif/OQnrF27tmhbg4aGhtzjeDxOOp0+bvFM0p6CiEiBy9cG44Hd8sAz7OkfZUV7IxsvOiNXPhetra0MDQ0VnTYwMEBHRwdNTU08/fTTPPLII3NezrFSUhARKeLytSuPKQkU6urq4vzzz+clL3kJjY2NLF26NDft4osv5rbbbuOss87ijDPO4OUvf/lxW+5smXvRwdDmrXXr1vmWLVuqHYaInGCeeuopXvziF1c7jIoo9l7NbKu7r5tpXp1TEBGRHCUFERHJUVIQEZEcJQUREclRUhARkRwlBRERyVE7BRGRQrecDiMHppY3L4GNO+b0kv39/Xzxi1/k3e9+96zn/fu//3s2bNhAU1PTnJY9G9pTEBEpVCwhTFdehrmOpwBBUjh8+PCclz0b2lMQkdrzzeth38/mNu9nfrd4+bLfhPU3l5wtv+vs173udSxZsoS7776bsbExrrjiCj74wQ8yMjLCm970Jnp6eshkMvz1X/81+/fvZ8+ePbz61a+mu7ubhx9+eG5xl0lJQUSkAm6++WZ+/vOfs23bNh588EG+8pWv8Oijj+LuXHrppfzgBz+gt7eXFStW8I1vfAMI+kRqa2vjYx/7GA8//DDd3d2Rx6mkICK1Z5pf9ADc1FZ62tu+ccyLf/DBB3nwwQdZu3YtAMPDw+zYsYMLL7yQ6667jve///284Q1v4MILLzzmZc2WkoKISIW5O5s2beKd73znlGlbt25l8+bNbNq0ide//vXccMMNFY1NJ5pFRAo1L5ldeRnyu86+6KKLuOOOOxgeHgZg9+7dHDhwgD179tDU1MTVV1/Nddddx+OPPz5l3qhpT0FEpNAcLzudTn7X2evXr+fNb34zr3hFMIpbS0sLn//859m5cycbN24kFouRSCT41Kc+BcCGDRtYv349y5cvj/xEs7rOFpGaoK6z1XW2iIjMkpKCiIjkKCmISM040Q6Xz8WxvkclBRGpCclkkr6+vgWdGNydvr4+ksnknF9DVx+JSE1YtWoVPT099Pb2VjuUSCWTSVatWjXn+ZUURKQmJBIJVq9eXe0w5r1IDx+Z2cVm9oyZ7TSz64tMbzCzu8LpPzazU6KMR0REphdZUjCzOPAJYD2wBrjKzNYUVHs7cMjdXwh8HPjbqOIREZGZRbmncB6w092fdfdx4MvAZQV1LgM+Gz7+CvAaM7MIYxIRkWlEeU5hJbAr73kP8LJSddw9bWYDQBfwfH4lM9sAbAifDpvZM3OMqbvwtecZxXdsFN+xm+8xKr65O7mcSlEmhWK/+AuvBSunDu5+O3D7MQdktqWcZt7VoviOjeI7dvM9RsUXvSgPH/UAJ+U9XwXsKVXHzOqANuBghDGJiMg0okwKjwGnm9lqM6sHrgTuL6hzP3BN+PiNwHd9IbcsERGZ5yI7fBSeI7gWeACIA3e4+5Nm9iFgi7vfD/wzcKeZ7STYQ7gyqnhCx3wIKmKK79govmM332NUfBE74brOFhGR6KjFsK+sAAAGRElEQVTvIxERyVFSEBGRnAWZFOZz9xpmdpKZPWxmT5nZk2b23iJ1XmVmA2a2LbxVdORuM3vOzH4WLnvKMHcWuDVcfz81s3MqGNsZeetlm5kNmtn7CupUfP2Z2R1mdsDMfp5X1mlm3zazHeF9R4l5rwnr7DCza4rViSC2W8zs6fD/9zUzay8x77SfhYhjvMnMduf9Hy8pMe+03/cI47srL7bnzGxbiXkrsg6PG3dfUDeCk9q/BE4F6oGfAGsK6rwbuC18fCVwVwXjWw6cEz5uBX5RJL5XAV+v4jp8DuieZvolwDcJ2pm8HPhxFf/X+4CTq73+gFcC5wA/zyv7KHB9+Ph64G+LzNcJPBved4SPOyoQ2+uBuvDx3xaLrZzPQsQx3gRcV8ZnYNrve1TxFUz/O+CGaq7D43VbiHsK87p7DXff6+6Ph4+HgKcIWnafSC4DPueBR4B2M1tehTheA/zS3X9VhWUfxd1/wNQ2Nvmfs88ClxeZ9SLg2+5+0N0PAd8GLo46Nnd/0N3T4dNHCNoRVU2J9VeOcr7vx2y6+MJtx5uALx3v5VbDQkwKxbrXKNzoHtW9BjDZvUZFhYet1gI/LjL5FWb2EzP7ppmdWdHAglblD5rZ1rCLkULlrONKuJLSX8Rqrr9JS919LwQ/BoAlRerMh3X5xwR7fsXM9FmI2rXhIa47Shx+mw/r70Jgv7vvKDG92utwVhZiUjhu3WtEycxagHuA97n7YMHkxwkOifwW8A/AvZWMDTjf3c8h6OH2PWb2yoLp82H91QOXAv9aZHK1199sVHVdmtkHgDTwhRJVZvosROlTwGnA2cBegkM0har+WQSuYvq9hGquw1lbiElh3nevYWYJgoTwBXf/auF0dx909+Hw8WYgYWbdlYrP3feE9weArxHsoucrZx1HbT3wuLvvL5xQ7fWXZ//kYbXw/kCROlVbl+FJ7TcAb/Hw4HehMj4LkXH3/e6ecfcs8E8lll3Vz2K4/fh94K5Sdaq5DudiISaFed29Rnj88Z+Bp9z9YyXqLJs8x2Fm5xH8n/oqFF+zmbVOPiY4Ifnzgmr3A38YXoX0cmBg8jBJBZX8dVbN9Vcg/3N2DXBfkToPAK83s47w8Mjrw7JImdnFwPuBS939cIk65XwWoowx/zzVFSWWXc73PUqvBZ52955iE6u9Duek2me6o7gRXB3zC4KrEj4Qln2I4AsAkCQ47LATeBQ4tYKxXUCwe/tTYFt4uwR4F/CusM61wJMEV1I8Avx2BeM7NVzuT8IYJtdffnxGMIDSL4GfAesq/P9tItjIt+WVVXX9ESSovcAEwa/XtxOcp/oOsCO87wzrrgM+nTfvH4efxZ3A2yoU206CY/GTn8HJq/FWAJun+yxUcP3dGX6+fkqwoV9eGGP4fMr3vRLxheX/Mvm5y6tblXV4vG7q5kJERHIW4uEjERGZIyUFERHJUVIQEZEcJQUREclRUhARkRwlBZGIhb22fr3acYiUQ0lBRERylBREQmZ2tZk9GvZ7/49mFjezYTP7OzN73My+Y2aLw7pnm9kjeeMRdITlLzSzh8LO+B43s9PCl28xs6+EYxh8Ia/F9c1mtj18nf9TpbcukqOkIAKY2YuBPyDovOxsIAO8BWgm6GPpHOD7wI3hLJ8D3u/uZxG0up0s/wLwCQ864/ttglawEPSG+z5gDUEr1/PNrJOg+4Yzw9f539G+S5GZKSmIBF4DnAs8Fo6g9RqCjXeWI52dfR64wMzagHZ3/35Y/lnglWEfNyvd/WsA7p7yI/0KPeruPR507rYNOAUYBFLAp83s94GifRCJVJKSgkjAgM+6+9nh7Qx3v6lIven6hZluoKaxvMcZglHP0gQ9Zt5DMADPt2YZs8hxp6QgEvgO8EYzWwK58ZVPJviOvDGs82bg3919ADhkZheG5W8Fvu/BuBg9ZnZ5+BoNZtZUaoHhmBptHnTv/T6CcQNEqqqu2gGIzAfuvt3M/opghKwYQW+Y7wFGgDPNbCvBCH1/EM5yDXBbuNF/FnhbWP5W4B/N7EPha/y3aRbbCtxnZkmCvYz/cZzflsisqZdUkWmY2bC7t1Q7DpFK0eEjERHJ0Z6CiIjkaE9BRERylBRERCRHSUFERHKUFEREJEdJQUREcv4/bdWRGy6e3AwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学習後の重み\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
